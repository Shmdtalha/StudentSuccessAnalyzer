{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Importing Files and Libraries\n"],"metadata":{"id":"0wjsZXR1jkUq"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ut8Zuw_jkpAl","executionInfo":{"status":"ok","timestamp":1715312974058,"user_tz":-300,"elapsed":22185,"user":{"displayName":"Sheikh Muhammad Talha BSSE 2021 FAST NU LHR","userId":"05044819345239191473"}},"outputId":"ea33bb8c-10c7-49c4-8985-55035871cf8e"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["%cd  /content/drive/MyDrive/Succes-O-Meter\n","%ls"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Mf3EYpGZklfO","executionInfo":{"status":"ok","timestamp":1715312976545,"user_tz":-300,"elapsed":381,"user":{"displayName":"Sheikh Muhammad Talha BSSE 2021 FAST NU LHR","userId":"05044819345239191473"}},"outputId":"edd5c3c9-226c-40de-8582-dea01bb0ea4e"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Succes-O-Meter\n","DataEncoding.ipynb                Model_Keras.ipynb                  \u001b[0m\u001b[01;34msaved_models\u001b[0m/\n","DataPlot.ipynb                    OriginalStudentPerformance.gsheet  StudentPertformance.gsheet\n","EncodedStudentPerformance.gsheet  Preprocessing.ipynb\n"]}]},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","import sklearn\n"],"metadata":{"id":"CIo9jH3KkBoV","executionInfo":{"status":"ok","timestamp":1715312980852,"user_tz":-300,"elapsed":968,"user":{"displayName":"Sheikh Muhammad Talha BSSE 2021 FAST NU LHR","userId":"05044819345239191473"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["id = \"1AvWvUMrHl5QlDig9N9uomu7OPsTk1dQs9-TjqjXRaFw\"\n","name = \"EncodedStudentPerformance\"\n","url = f\"https://docs.google.com/spreadsheets/d/{id}/gviz/tq?tqx=out:csv&sheet={name}\"\n","table = pd.read_csv(url)\n","table = pd.DataFrame(table)\n","table"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":443},"id":"qim1WJG0kJ5X","executionInfo":{"status":"ok","timestamp":1715313006111,"user_tz":-300,"elapsed":787,"user":{"displayName":"Sheikh Muhammad Talha BSSE 2021 FAST NU LHR","userId":"05044819345239191473"}},"outputId":"351902c2-0d2b-4145-a050-915ddf2dc4ff"},"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["     Gradeid  Semester  Raisedhands  Visitedresources  Announcementsview  \\\n","0          4         1           15                16                  2   \n","1          4         1           20                20                  3   \n","2          4         1           10                 7                  0   \n","3          4         1           30                25                  5   \n","4          4         1           40                50                 12   \n","..       ...       ...          ...               ...                ...   \n","475        8         2            5                 4                  5   \n","476        8         1           50                77                 14   \n","477        8         2           55                74                 25   \n","478        8         1           30                17                 14   \n","479        8         2           35                14                 23   \n","\n","     Discussion  Parentansweringsurvey  Parentschoolsatisfaction  Gender_F  \\\n","0            20                      1                         1         0   \n","1            25                      1                         1         0   \n","2            30                      0                         0         0   \n","3            35                      0                         0         0   \n","4            50                      0                         0         0   \n","..          ...                    ...                       ...       ...   \n","475           8                      0                         0         1   \n","476          28                      0                         0         1   \n","477          29                      0                         0         1   \n","478          57                      0                         0         1   \n","479          62                      0                         0         1   \n","\n","     Gender_M  ...  Topic_IT  Topic_Math  Topic_Quran  Topic_Science  \\\n","0           1  ...         1           0            0              0   \n","1           1  ...         1           0            0              0   \n","2           1  ...         1           0            0              0   \n","3           1  ...         1           0            0              0   \n","4           1  ...         1           0            0              0   \n","..        ...  ...       ...         ...          ...            ...   \n","475         0  ...         0           0            0              0   \n","476         0  ...         0           0            0              0   \n","477         0  ...         0           0            0              0   \n","478         0  ...         0           0            0              0   \n","479         0  ...         0           0            0              0   \n","\n","     Topic_Spanish  Relation_Father  Relation_Mum  Studentabsencedays_High  \\\n","0                0                1             0                        0   \n","1                0                1             0                        0   \n","2                0                1             0                        1   \n","3                0                1             0                        1   \n","4                0                1             0                        1   \n","..             ...              ...           ...                      ...   \n","475              0                1             0                        1   \n","476              0                1             0                        0   \n","477              0                1             0                        0   \n","478              0                1             0                        1   \n","479              0                1             0                        1   \n","\n","     Studentabsencedays_Low  Marks  \n","0                         1      M  \n","1                         1      M  \n","2                         0      L  \n","3                         0      L  \n","4                         0      M  \n","..                      ...    ...  \n","475                       0      L  \n","476                       1      M  \n","477                       1      M  \n","478                       0      L  \n","479                       0      L  \n","\n","[480 rows x 61 columns]"],"text/html":["\n","  <div id=\"df-fc21a792-41fc-4423-937a-a57fa408f295\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Gradeid</th>\n","      <th>Semester</th>\n","      <th>Raisedhands</th>\n","      <th>Visitedresources</th>\n","      <th>Announcementsview</th>\n","      <th>Discussion</th>\n","      <th>Parentansweringsurvey</th>\n","      <th>Parentschoolsatisfaction</th>\n","      <th>Gender_F</th>\n","      <th>Gender_M</th>\n","      <th>...</th>\n","      <th>Topic_IT</th>\n","      <th>Topic_Math</th>\n","      <th>Topic_Quran</th>\n","      <th>Topic_Science</th>\n","      <th>Topic_Spanish</th>\n","      <th>Relation_Father</th>\n","      <th>Relation_Mum</th>\n","      <th>Studentabsencedays_High</th>\n","      <th>Studentabsencedays_Low</th>\n","      <th>Marks</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>4</td>\n","      <td>1</td>\n","      <td>15</td>\n","      <td>16</td>\n","      <td>2</td>\n","      <td>20</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>M</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>4</td>\n","      <td>1</td>\n","      <td>20</td>\n","      <td>20</td>\n","      <td>3</td>\n","      <td>25</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>M</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>4</td>\n","      <td>1</td>\n","      <td>10</td>\n","      <td>7</td>\n","      <td>0</td>\n","      <td>30</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>L</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>1</td>\n","      <td>30</td>\n","      <td>25</td>\n","      <td>5</td>\n","      <td>35</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>L</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>1</td>\n","      <td>40</td>\n","      <td>50</td>\n","      <td>12</td>\n","      <td>50</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>M</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>475</th>\n","      <td>8</td>\n","      <td>2</td>\n","      <td>5</td>\n","      <td>4</td>\n","      <td>5</td>\n","      <td>8</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>L</td>\n","    </tr>\n","    <tr>\n","      <th>476</th>\n","      <td>8</td>\n","      <td>1</td>\n","      <td>50</td>\n","      <td>77</td>\n","      <td>14</td>\n","      <td>28</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>M</td>\n","    </tr>\n","    <tr>\n","      <th>477</th>\n","      <td>8</td>\n","      <td>2</td>\n","      <td>55</td>\n","      <td>74</td>\n","      <td>25</td>\n","      <td>29</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>M</td>\n","    </tr>\n","    <tr>\n","      <th>478</th>\n","      <td>8</td>\n","      <td>1</td>\n","      <td>30</td>\n","      <td>17</td>\n","      <td>14</td>\n","      <td>57</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>L</td>\n","    </tr>\n","    <tr>\n","      <th>479</th>\n","      <td>8</td>\n","      <td>2</td>\n","      <td>35</td>\n","      <td>14</td>\n","      <td>23</td>\n","      <td>62</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>L</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>480 rows × 61 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fc21a792-41fc-4423-937a-a57fa408f295')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-fc21a792-41fc-4423-937a-a57fa408f295 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-fc21a792-41fc-4423-937a-a57fa408f295');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-583b4c19-f799-4db4-bfc4-df5fcc84cbc9\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-583b4c19-f799-4db4-bfc4-df5fcc84cbc9')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-583b4c19-f799-4db4-bfc4-df5fcc84cbc9 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"table"}},"metadata":{},"execution_count":6}]},{"cell_type":"markdown","source":["# Kera Implementation\n"],"metadata":{"id":"xmitk2zqRMJX"}},{"cell_type":"code","source":["!pip install keras scikeras tensorflow\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"bb44sg0-VvFR","executionInfo":{"status":"ok","timestamp":1715270513376,"user_tz":-300,"elapsed":99059,"user":{"displayName":"Sheikh Muhammad Talha BSSE 2021 FAST NU LHR","userId":"05044819345239191473"}},"outputId":"45886a5d-5171-496d-83b2-736d5817b20c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (2.15.0)\n","Collecting scikeras\n","  Downloading scikeras-0.13.0-py3-none-any.whl (26 kB)\n","Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n","Collecting keras\n","  Downloading keras-3.3.3-py3-none-any.whl (1.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting scikit-learn>=1.4.2 (from scikeras)\n","  Downloading scikit_learn-1.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m33.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from keras) (1.4.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras) (1.25.2)\n","Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras) (13.7.1)\n","Collecting namex (from keras)\n","  Downloading namex-0.0.8-py3-none-any.whl (5.8 kB)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras) (3.9.0)\n","Collecting optree (from keras)\n","  Downloading optree-0.11.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (311 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.2/311.2 kB\u001b[0m \u001b[31m31.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: ml-dtypes in /usr/local/lib/python3.10/dist-packages (from keras) (0.2.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n","Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n","Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.0)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.11.0)\n","Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.63.0)\n","Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.2)\n","Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n","INFO: pip is looking at multiple versions of tensorflow to determine which version is compatible with other requirements. This could take a while.\n","Collecting tensorflow\n","  Downloading tensorflow-2.16.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (589.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m589.8/589.8 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting h5py (from keras)\n","  Downloading h5py-3.11.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m60.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting ml-dtypes (from keras)\n","  Downloading ml_dtypes-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m48.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.31.0)\n","Collecting tensorboard<2.17,>=2.16 (from tensorflow)\n","  Downloading tensorboard-2.16.2-py3-none-any.whl (5.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m61.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.2.2)\n","Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.4.2->scikeras) (1.11.4)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.4.2->scikeras) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.4.2->scikeras) (3.5.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.17,>=2.16->tensorflow) (3.6)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.17,>=2.16->tensorflow) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.17,>=2.16->tensorflow) (3.0.2)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras) (2.16.1)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow) (2.1.5)\n","Installing collected packages: namex, optree, ml-dtypes, h5py, tensorboard, scikit-learn, keras, tensorflow, scikeras\n","  Attempting uninstall: ml-dtypes\n","    Found existing installation: ml-dtypes 0.2.0\n","    Uninstalling ml-dtypes-0.2.0:\n","      Successfully uninstalled ml-dtypes-0.2.0\n","  Attempting uninstall: h5py\n","    Found existing installation: h5py 3.9.0\n","    Uninstalling h5py-3.9.0:\n","      Successfully uninstalled h5py-3.9.0\n","  Attempting uninstall: tensorboard\n","    Found existing installation: tensorboard 2.15.2\n","    Uninstalling tensorboard-2.15.2:\n","      Successfully uninstalled tensorboard-2.15.2\n","  Attempting uninstall: scikit-learn\n","    Found existing installation: scikit-learn 1.2.2\n","    Uninstalling scikit-learn-1.2.2:\n","      Successfully uninstalled scikit-learn-1.2.2\n","  Attempting uninstall: keras\n","    Found existing installation: keras 2.15.0\n","    Uninstalling keras-2.15.0:\n","      Successfully uninstalled keras-2.15.0\n","  Attempting uninstall: tensorflow\n","    Found existing installation: tensorflow 2.15.0\n","    Uninstalling tensorflow-2.15.0:\n","      Successfully uninstalled tensorflow-2.15.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","tf-keras 2.15.1 requires tensorflow<2.16,>=2.15, but you have tensorflow 2.16.1 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed h5py-3.11.0 keras-3.3.3 ml-dtypes-0.3.2 namex-0.0.8 optree-0.11.0 scikeras-0.13.0 scikit-learn-1.4.2 tensorboard-2.16.2 tensorflow-2.16.1\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["h5py","keras","ml_dtypes","sklearn","tensorboard","tensorflow"]},"id":"e633f3692d714aecae152c6e35ead95a"}},"metadata":{}}]},{"cell_type":"code","source":["table.dtypes\n","table[\"Marks\"]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jQX-hTXuWvi0","executionInfo":{"status":"ok","timestamp":1715313010138,"user_tz":-300,"elapsed":381,"user":{"displayName":"Sheikh Muhammad Talha BSSE 2021 FAST NU LHR","userId":"05044819345239191473"}},"outputId":"749667af-60c5-4b0a-e689-e2a4502e355d"},"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0      M\n","1      M\n","2      L\n","3      L\n","4      M\n","      ..\n","475    L\n","476    M\n","477    M\n","478    L\n","479    L\n","Name: Marks, Length: 480, dtype: object"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":[],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"07UPr0Z0cNZR","executionInfo":{"status":"ok","timestamp":1715259633641,"user_tz":-300,"elapsed":362,"user":{"displayName":"Sheikh Muhammad Talha BSSE 2021 FAST NU LHR","userId":"05044819345239191473"}},"outputId":"42514e7d-653c-4637-c97c-fe176c8ee065"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Gradeid                     int64\n","Semester                    int64\n","Raisedhands                 int64\n","Visitedresources            int64\n","Announcementsview           int64\n","                            ...  \n","Relation_Father             int64\n","Relation_Mum                int64\n","Studentabsencedays_High     int64\n","Studentabsencedays_Low      int64\n","Marks                      object\n","Length: 61, dtype: object"]},"metadata":{},"execution_count":18}]},{"cell_type":"code","source":["# from keras.models import Sequential\n","# from keras.layers import Dense\n","# from sklearn.model_selection import train_test_split, KFold, cross_val_score\n","# from scikeras.wrappers import KerasClassifier\n","# from sklearn.preprocessing import LabelEncoder\n","# from keras.utils import np_utils\n","# from sklearn.metrics import confusion_matrix\n","\n","# from keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\n","\n","\n","# X = table.drop(\"Marks\", axis=1)\n","# y = table[\"Marks\"]\n","\n","# # Encoding target variable\n","# encoder = LabelEncoder()\n","# encoded_Y = encoder.fit_transform(y)\n","# y_encoded = np_utils.to_categorical(encoded_Y)\n","\n","# # Your baseline model function\n","# def baseline_model():\n","#     # create model\n","#     model = Sequential()\n","#     model.add(Dense(60, input_dim=60, activation='relu'))\n","#     model.add(Dense(3, activation='softmax'))\n","#     # Compile model\n","#     model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","#     return model\n","\n","# # Splitting data into training and testing sets\n","# X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2)\n","\n","# for i in range (1, 200, 5):\n","#   estimator = KerasClassifier(model=baseline_model, epochs=i, batch_size=5, verbose=0)\n","\n","#   # Cross-validation\n","#   kfold = KFold(n_splits=10, shuffle=True)\n","\n","#   # Training\n","#   results = cross_val_score(estimator, X_train, y_train, cv=kfold)\n","#   print(f\"Training Score with {i} epochs: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n","\n","#   # Testing\n","#   estimator.fit(X_train, y_train)\n","#   test_accuracy = estimator.score(X_test, y_test)\n","#   print(f\"Test Accuracy with {i} epochs: %.2f%%\" % (test_accuracy * 100))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":530},"id":"_uLxAJJCc_m5","executionInfo":{"status":"error","timestamp":1714810105096,"user_tz":-300,"elapsed":142363,"user":{"displayName":"Sheikh Muhammad Talha BSSE 2021 FAST NU LHR","userId":"05044819345239191473"}},"outputId":"ffd42563-0981-4984-b71f-2064f3b54e86"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Training Score with 1 epochs: 49.78% (6.20%)\n","Test Accuracy with 1 epochs: 55.21%\n","Training Score with 6 epochs: 65.89% (7.80%)\n","Test Accuracy with 6 epochs: 71.88%\n","Training Score with 11 epochs: 66.17% (9.98%)\n","Test Accuracy with 11 epochs: 63.54%\n","Training Score with 16 epochs: 71.36% (9.23%)\n","Test Accuracy with 16 epochs: 65.62%\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-52-13363d061897>\u001b[0m in \u001b[0;36m<cell line: 33>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m   \u001b[0;31m# Training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m   \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkfold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Training Score with {i} epochs: %.2f%% (%.2f%%)\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    513\u001b[0m     \u001b[0mscorer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_scoring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 515\u001b[0;31m     cv_results = cross_validate(\n\u001b[0m\u001b[1;32m    516\u001b[0m         \u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[0;31m# independent, and that it is pickle-able.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0mparallel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mParallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpre_dispatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpre_dispatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m     results = parallel(\n\u001b[0m\u001b[1;32m    267\u001b[0m         delayed(_fit_and_score)(\n\u001b[1;32m    268\u001b[0m             \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         )\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1916\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_sequential_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1917\u001b[0m             \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1918\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_generator\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1920\u001b[0m         \u001b[0;31m# Let's create an ID that uniquely identifies the current call. If the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1845\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_batches\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1846\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_tasks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1847\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1848\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_completed_tasks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1849\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_progress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    684\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    685\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 686\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, **kwargs)\u001b[0m\n\u001b[1;32m   1489\u001b[0m             \u001b[0msample_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1490\u001b[0m             \u001b[0msample_weight\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mcompute_sample_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1491\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1492\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1493\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, **kwargs)\u001b[0m\n\u001b[1;32m    758\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"initial_epoch\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"initial_epoch\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    759\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 760\u001b[0;31m         self._fit(\n\u001b[0m\u001b[1;32m    761\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    762\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, sample_weight, warm_start, epochs, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m    926\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_model_compatibility\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    927\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 928\u001b[0;31m         self._fit_keras_model(\n\u001b[0m\u001b[1;32m    929\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    930\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py\u001b[0m in \u001b[0;36m_fit_keras_model\u001b[0;34m(self, X, y, sample_weight, warm_start, epochs, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m    522\u001b[0m                 \u001b[0mhist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 524\u001b[0;31m             \u001b[0mhist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    525\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    526\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mwarm_start\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"history_\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0minitial_epoch\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1670\u001b[0m             )\n\u001b[1;32m   1671\u001b[0m             \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1672\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menumerate_epochs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1673\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1674\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36menumerate_epochs\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1303\u001b[0m         \u001b[0;34m\"\"\"Yields `(epoch, tf.data.Iterator)`.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_truncate_execution_to_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1305\u001b[0;31m             \u001b[0mdata_iterator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1306\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initial_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1307\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_insufficient_data\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Set by `catch_stop_iteration`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    498\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minside_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    499\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolocate_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variant_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 500\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0miterator_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOwnedIterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    501\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    502\u001b[0m       raise RuntimeError(\"`tf.data.Dataset` only supports Python-style \"\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dataset, components, element_spec)\u001b[0m\n\u001b[1;32m    704\u001b[0m             \u001b[0;34m\"When `dataset` is provided, `element_spec` and `components` must \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m             \"not be specified.\")\n\u001b[0;32m--> 706\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    708\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_next_call_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m_create_iterator\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    743\u001b[0m             self._flat_output_types)\n\u001b[1;32m    744\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator_resource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_set_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfulltype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 745\u001b[0;31m       \u001b[0mgen_dataset_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_variant\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator_resource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    746\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    747\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/gen_dataset_ops.py\u001b[0m in \u001b[0;36mmake_iterator\u001b[0;34m(dataset, iterator, name)\u001b[0m\n\u001b[1;32m   3419\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3420\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3421\u001b[0;31m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[1;32m   3422\u001b[0m         _ctx, \"MakeIterator\", name, dataset, iterator)\n\u001b[1;32m   3423\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","from tensorflow.keras.utils import to_categorical\n","from sklearn.metrics import confusion_matrix\n","import tensorflow.keras as keras\n","import os\n","\n","from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n","\n","X = table.drop(\"Marks\", axis=1)\n","y = table[\"Marks\"]\n","\n","# Encoding target variable\n","encoder = LabelEncoder()\n","encoded_Y = encoder.fit_transform(y)\n","y_encoded = to_categorical(encoded_Y)\n","\n","# Baseline model\n","def baseline_model():\n","    # create model\n","    model = Sequential()\n","    model.add(Dense(120, input_dim=60, activation='relu'))\n","    model.add(Dense(3, activation='softmax'))\n","    # Compile model\n","    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","    return model\n","\n","\n","# CONFIGURATION\n","BATCH_SIZE = 10\n","EPOCHS = 200\n","evaluate_every = 20\n","PATIENCE = 30\n","\n","# Directory for best model\n","save_dir = \"./saved_models/\"\n","os.makedirs(save_dir, exist_ok=True)  # Create directory if it doesn't exist\n","filepath = os.path.join(save_dir, \"best_model.keras\")\n","\n","# Splitting data into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2)\n","best_accuracy = 0\n","best_model = None\n","\n","checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n","\n","# EarlyStopping callback if no improvement found\n","early_stopping = EarlyStopping(monitor='val_loss', patience=PATIENCE, verbose=1)\n","\n","# Callback to evaluate the model after every evaluate_every epochs\n","class EvaluateEveryEpoch(keras.callbacks.Callback):\n","    def on_train_begin(self, logs=None):\n","        print(\"Training has begun\")\n","\n","    def on_epoch_end(self, epoch, logs=None):\n","        if (epoch + 1) % evaluate_every == 0:\n","            test_accuracy = self.model.evaluate(X_test, y_test, verbose=0)[1]\n","            print(f\"Test Accuracy after epoch {epoch + 1}: {test_accuracy * 100:.2f}%\")\n","\n","\n","model = baseline_model()\n","\n","# Fit model with callbacks\n","history = model.fit(X_train, y_train, epochs=EPOCHS, batch_size=BATCH_SIZE, validation_split=0.2, callbacks=[checkpoint, early_stopping, EvaluateEveryEpoch()])\n","\n","# Check if the best model file exists\n","if os.path.exists(filepath + '.keras'):\n","    print(\"Best model saved successfully.\")\n","else:\n","    print(\"No best model file saved.\")  # Check this condition\n","\n","stopped_epoch = early_stopping.stopped_epoch if hasattr(early_stopping, 'stopped_epoch') else None\n","if stopped_epoch is not None:\n","    print(f\"Training stopped early at epoch {stopped_epoch} due to EarlyStopping.\")\n","else:\n","    print(\"Training completed all epochs.\")\n","\n","# DO evaluation using best model\n","test_accuracy = model.evaluate(X_test, y_test)[1]\n","if test_accuracy > best_accuracy:\n","    best_accuracy = test_accuracy\n","    best_model = model\n","    print(f\"Test Accuracy: %.2f%%\\n\" % (test_accuracy * 100))\n","\n","# Load the best saved model\n","if best_model is not None:\n","    best_model.save(filepath)  # Save the model\n","    print(\"Best model saved successfully.\")\n","else:\n","    print(\"No best model found.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hNKxUSo1pXNh","executionInfo":{"status":"ok","timestamp":1715313024886,"user_tz":-300,"elapsed":8073,"user":{"displayName":"Sheikh Muhammad Talha BSSE 2021 FAST NU LHR","userId":"05044819345239191473"}},"outputId":"50004379-f5f5-463d-94f7-4e7497c0a4ef"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Training has begun\n","Epoch 1/200\n","25/31 [=======================>......] - ETA: 0s - loss: 3.2071 - accuracy: 0.4280 \n","Epoch 1: val_accuracy improved from -inf to 0.41558, saving model to ./saved_models/best_model.keras\n","31/31 [==============================] - 1s 13ms/step - loss: 2.9035 - accuracy: 0.4332 - val_loss: 2.1824 - val_accuracy: 0.4156\n","Epoch 2/200\n","27/31 [=========================>....] - ETA: 0s - loss: 1.2966 - accuracy: 0.4926\n","Epoch 2: val_accuracy improved from 0.41558 to 0.50649, saving model to ./saved_models/best_model.keras\n","31/31 [==============================] - 0s 5ms/step - loss: 1.2497 - accuracy: 0.5147 - val_loss: 1.3706 - val_accuracy: 0.5065\n","Epoch 3/200\n","26/31 [========================>.....] - ETA: 0s - loss: 1.1084 - accuracy: 0.5577\n","Epoch 3: val_accuracy improved from 0.50649 to 0.55844, saving model to ./saved_models/best_model.keras\n","31/31 [==============================] - 0s 5ms/step - loss: 1.0808 - accuracy: 0.5570 - val_loss: 1.1164 - val_accuracy: 0.5584\n","Epoch 4/200\n","29/31 [===========================>..] - ETA: 0s - loss: 0.8206 - accuracy: 0.6414\n","Epoch 4: val_accuracy improved from 0.55844 to 0.63636, saving model to ./saved_models/best_model.keras\n","31/31 [==============================] - 0s 5ms/step - loss: 0.8248 - accuracy: 0.6417 - val_loss: 0.9622 - val_accuracy: 0.6364\n","Epoch 5/200\n","26/31 [========================>.....] - ETA: 0s - loss: 0.7994 - accuracy: 0.6808\n","Epoch 5: val_accuracy did not improve from 0.63636\n","31/31 [==============================] - 0s 4ms/step - loss: 0.7951 - accuracy: 0.6906 - val_loss: 0.9465 - val_accuracy: 0.6104\n","Epoch 6/200\n","25/31 [=======================>......] - ETA: 0s - loss: 0.6886 - accuracy: 0.7040\n","Epoch 6: val_accuracy improved from 0.63636 to 0.67532, saving model to ./saved_models/best_model.keras\n","31/31 [==============================] - 0s 5ms/step - loss: 0.6613 - accuracy: 0.7036 - val_loss: 0.8048 - val_accuracy: 0.6753\n","Epoch 7/200\n","30/31 [============================>.] - ETA: 0s - loss: 0.6057 - accuracy: 0.7500\n","Epoch 7: val_accuracy did not improve from 0.67532\n","31/31 [==============================] - 0s 4ms/step - loss: 0.6050 - accuracy: 0.7492 - val_loss: 1.0802 - val_accuracy: 0.5195\n","Epoch 8/200\n","19/31 [=================>............] - ETA: 0s - loss: 0.6184 - accuracy: 0.7421\n","Epoch 8: val_accuracy did not improve from 0.67532\n","31/31 [==============================] - 0s 4ms/step - loss: 0.6909 - accuracy: 0.6906 - val_loss: 0.8384 - val_accuracy: 0.6234\n","Epoch 9/200\n","25/31 [=======================>......] - ETA: 0s - loss: 0.5532 - accuracy: 0.7520\n","Epoch 9: val_accuracy did not improve from 0.67532\n","31/31 [==============================] - 0s 4ms/step - loss: 0.5515 - accuracy: 0.7394 - val_loss: 0.8008 - val_accuracy: 0.6234\n","Epoch 10/200\n","28/31 [==========================>...] - ETA: 0s - loss: 0.6073 - accuracy: 0.7500\n","Epoch 10: val_accuracy did not improve from 0.67532\n","31/31 [==============================] - 0s 4ms/step - loss: 0.6123 - accuracy: 0.7492 - val_loss: 0.7496 - val_accuracy: 0.6234\n","Epoch 11/200\n","26/31 [========================>.....] - ETA: 0s - loss: 0.5338 - accuracy: 0.7231\n","Epoch 11: val_accuracy did not improve from 0.67532\n","31/31 [==============================] - 0s 4ms/step - loss: 0.5261 - accuracy: 0.7296 - val_loss: 0.7500 - val_accuracy: 0.6623\n","Epoch 12/200\n","23/31 [=====================>........] - ETA: 0s - loss: 0.5062 - accuracy: 0.7739\n","Epoch 12: val_accuracy did not improve from 0.67532\n","31/31 [==============================] - 0s 4ms/step - loss: 0.4965 - accuracy: 0.7850 - val_loss: 0.8636 - val_accuracy: 0.6104\n","Epoch 13/200\n","29/31 [===========================>..] - ETA: 0s - loss: 0.4499 - accuracy: 0.8000\n","Epoch 13: val_accuracy did not improve from 0.67532\n","31/31 [==============================] - 0s 4ms/step - loss: 0.4597 - accuracy: 0.7980 - val_loss: 0.7115 - val_accuracy: 0.6623\n","Epoch 14/200\n","28/31 [==========================>...] - ETA: 0s - loss: 0.4449 - accuracy: 0.8071\n","Epoch 14: val_accuracy did not improve from 0.67532\n","31/31 [==============================] - 0s 4ms/step - loss: 0.4485 - accuracy: 0.7980 - val_loss: 0.7633 - val_accuracy: 0.6623\n","Epoch 15/200\n","25/31 [=======================>......] - ETA: 0s - loss: 0.4602 - accuracy: 0.8120\n","Epoch 15: val_accuracy did not improve from 0.67532\n","31/31 [==============================] - 0s 4ms/step - loss: 0.4384 - accuracy: 0.8208 - val_loss: 0.9528 - val_accuracy: 0.5974\n","Epoch 16/200\n","23/31 [=====================>........] - ETA: 0s - loss: 0.4938 - accuracy: 0.7609\n","Epoch 16: val_accuracy did not improve from 0.67532\n","31/31 [==============================] - 0s 4ms/step - loss: 0.4926 - accuracy: 0.7687 - val_loss: 1.0716 - val_accuracy: 0.5584\n","Epoch 17/200\n","23/31 [=====================>........] - ETA: 0s - loss: 0.4345 - accuracy: 0.8043\n","Epoch 17: val_accuracy did not improve from 0.67532\n","31/31 [==============================] - 0s 4ms/step - loss: 0.4445 - accuracy: 0.8078 - val_loss: 0.7655 - val_accuracy: 0.6364\n","Epoch 18/200\n","21/31 [===================>..........] - ETA: 0s - loss: 0.4056 - accuracy: 0.8619\n","Epoch 18: val_accuracy did not improve from 0.67532\n","31/31 [==============================] - 0s 4ms/step - loss: 0.4761 - accuracy: 0.8176 - val_loss: 0.7228 - val_accuracy: 0.6494\n","Epoch 19/200\n","28/31 [==========================>...] - ETA: 0s - loss: 0.3756 - accuracy: 0.8357\n","Epoch 19: val_accuracy did not improve from 0.67532\n","31/31 [==============================] - 0s 3ms/step - loss: 0.3901 - accuracy: 0.8371 - val_loss: 0.7934 - val_accuracy: 0.6364\n","Epoch 20/200\n","27/31 [=========================>....] - ETA: 0s - loss: 0.3741 - accuracy: 0.8556\n","Epoch 20: val_accuracy did not improve from 0.67532\n","Test Accuracy after epoch 20: 73.96%\n","31/31 [==============================] - 0s 7ms/step - loss: 0.3698 - accuracy: 0.8567 - val_loss: 0.7378 - val_accuracy: 0.6234\n","Epoch 21/200\n","28/31 [==========================>...] - ETA: 0s - loss: 0.3789 - accuracy: 0.8357\n","Epoch 21: val_accuracy did not improve from 0.67532\n","31/31 [==============================] - 0s 4ms/step - loss: 0.3790 - accuracy: 0.8339 - val_loss: 0.7723 - val_accuracy: 0.6753\n","Epoch 22/200\n","26/31 [========================>.....] - ETA: 0s - loss: 0.3883 - accuracy: 0.8538\n","Epoch 22: val_accuracy did not improve from 0.67532\n","31/31 [==============================] - 0s 4ms/step - loss: 0.3924 - accuracy: 0.8469 - val_loss: 1.0181 - val_accuracy: 0.6104\n","Epoch 23/200\n","26/31 [========================>.....] - ETA: 0s - loss: 0.4551 - accuracy: 0.7885\n","Epoch 23: val_accuracy did not improve from 0.67532\n","31/31 [==============================] - 0s 4ms/step - loss: 0.4312 - accuracy: 0.8013 - val_loss: 0.8226 - val_accuracy: 0.6234\n","Epoch 24/200\n","27/31 [=========================>....] - ETA: 0s - loss: 0.3619 - accuracy: 0.8519\n","Epoch 24: val_accuracy did not improve from 0.67532\n","31/31 [==============================] - 0s 4ms/step - loss: 0.3599 - accuracy: 0.8502 - val_loss: 0.8042 - val_accuracy: 0.6494\n","Epoch 25/200\n","22/31 [====================>.........] - ETA: 0s - loss: 0.4214 - accuracy: 0.8318\n","Epoch 25: val_accuracy did not improve from 0.67532\n","31/31 [==============================] - 0s 4ms/step - loss: 0.3977 - accuracy: 0.8371 - val_loss: 0.7419 - val_accuracy: 0.6623\n","Epoch 26/200\n","25/31 [=======================>......] - ETA: 0s - loss: 0.3122 - accuracy: 0.8600\n","Epoch 26: val_accuracy improved from 0.67532 to 0.68831, saving model to ./saved_models/best_model.keras\n","31/31 [==============================] - 0s 5ms/step - loss: 0.3169 - accuracy: 0.8697 - val_loss: 0.7917 - val_accuracy: 0.6883\n","Epoch 27/200\n","26/31 [========================>.....] - ETA: 0s - loss: 0.3598 - accuracy: 0.8462\n","Epoch 27: val_accuracy did not improve from 0.68831\n","31/31 [==============================] - 0s 3ms/step - loss: 0.3630 - accuracy: 0.8436 - val_loss: 0.7801 - val_accuracy: 0.6364\n","Epoch 28/200\n","27/31 [=========================>....] - ETA: 0s - loss: 0.3204 - accuracy: 0.8852\n","Epoch 28: val_accuracy did not improve from 0.68831\n","31/31 [==============================] - 0s 4ms/step - loss: 0.3220 - accuracy: 0.8795 - val_loss: 0.8623 - val_accuracy: 0.6623\n","Epoch 29/200\n","31/31 [==============================] - ETA: 0s - loss: 0.3909 - accuracy: 0.8339\n","Epoch 29: val_accuracy did not improve from 0.68831\n","31/31 [==============================] - 0s 3ms/step - loss: 0.3909 - accuracy: 0.8339 - val_loss: 0.8200 - val_accuracy: 0.6364\n","Epoch 30/200\n","30/31 [============================>.] - ETA: 0s - loss: 0.3089 - accuracy: 0.8933\n","Epoch 30: val_accuracy did not improve from 0.68831\n","31/31 [==============================] - 0s 3ms/step - loss: 0.3071 - accuracy: 0.8958 - val_loss: 0.7691 - val_accuracy: 0.6883\n","Epoch 31/200\n","26/31 [========================>.....] - ETA: 0s - loss: 0.3019 - accuracy: 0.9038\n","Epoch 31: val_accuracy improved from 0.68831 to 0.70130, saving model to ./saved_models/best_model.keras\n","31/31 [==============================] - 0s 5ms/step - loss: 0.3098 - accuracy: 0.8958 - val_loss: 0.7370 - val_accuracy: 0.7013\n","Epoch 32/200\n","27/31 [=========================>....] - ETA: 0s - loss: 0.2783 - accuracy: 0.9185\n","Epoch 32: val_accuracy did not improve from 0.70130\n","31/31 [==============================] - 0s 4ms/step - loss: 0.2787 - accuracy: 0.9153 - val_loss: 0.8130 - val_accuracy: 0.6494\n","Epoch 33/200\n","29/31 [===========================>..] - ETA: 0s - loss: 0.2756 - accuracy: 0.9000\n","Epoch 33: val_accuracy did not improve from 0.70130\n","31/31 [==============================] - 0s 3ms/step - loss: 0.2795 - accuracy: 0.9023 - val_loss: 0.8980 - val_accuracy: 0.6104\n","Epoch 34/200\n","24/31 [======================>.......] - ETA: 0s - loss: 0.3278 - accuracy: 0.8625\n","Epoch 34: val_accuracy did not improve from 0.70130\n","31/31 [==============================] - 0s 4ms/step - loss: 0.3144 - accuracy: 0.8762 - val_loss: 0.8002 - val_accuracy: 0.6364\n","Epoch 35/200\n","29/31 [===========================>..] - ETA: 0s - loss: 0.3287 - accuracy: 0.8586\n","Epoch 35: val_accuracy did not improve from 0.70130\n","31/31 [==============================] - 0s 4ms/step - loss: 0.3180 - accuracy: 0.8664 - val_loss: 0.7989 - val_accuracy: 0.6364\n","Epoch 36/200\n","28/31 [==========================>...] - ETA: 0s - loss: 0.3558 - accuracy: 0.8571\n","Epoch 36: val_accuracy did not improve from 0.70130\n","31/31 [==============================] - 0s 4ms/step - loss: 0.3747 - accuracy: 0.8404 - val_loss: 1.0526 - val_accuracy: 0.6494\n","Epoch 37/200\n","28/31 [==========================>...] - ETA: 0s - loss: 0.3240 - accuracy: 0.8679\n","Epoch 37: val_accuracy did not improve from 0.70130\n","31/31 [==============================] - 0s 4ms/step - loss: 0.3222 - accuracy: 0.8664 - val_loss: 0.8329 - val_accuracy: 0.6623\n","Epoch 38/200\n","27/31 [=========================>....] - ETA: 0s - loss: 0.2468 - accuracy: 0.9074\n","Epoch 38: val_accuracy did not improve from 0.70130\n","31/31 [==============================] - 0s 4ms/step - loss: 0.2542 - accuracy: 0.8990 - val_loss: 0.8200 - val_accuracy: 0.6364\n","Epoch 39/200\n","28/31 [==========================>...] - ETA: 0s - loss: 0.2278 - accuracy: 0.9179\n","Epoch 39: val_accuracy did not improve from 0.70130\n","31/31 [==============================] - 0s 4ms/step - loss: 0.2472 - accuracy: 0.9121 - val_loss: 0.9637 - val_accuracy: 0.5974\n","Epoch 40/200\n","31/31 [==============================] - ETA: 0s - loss: 0.2576 - accuracy: 0.8990\n","Epoch 40: val_accuracy did not improve from 0.70130\n","Test Accuracy after epoch 40: 76.04%\n","31/31 [==============================] - 0s 7ms/step - loss: 0.2576 - accuracy: 0.8990 - val_loss: 0.8424 - val_accuracy: 0.6494\n","Epoch 41/200\n","20/31 [==================>...........] - ETA: 0s - loss: 0.2462 - accuracy: 0.9100\n","Epoch 41: val_accuracy did not improve from 0.70130\n","31/31 [==============================] - 0s 6ms/step - loss: 0.2716 - accuracy: 0.8990 - val_loss: 0.8185 - val_accuracy: 0.6623\n","Epoch 42/200\n","18/31 [================>.............] - ETA: 0s - loss: 0.2771 - accuracy: 0.8722\n","Epoch 42: val_accuracy did not improve from 0.70130\n","31/31 [==============================] - 0s 5ms/step - loss: 0.2753 - accuracy: 0.8893 - val_loss: 0.8962 - val_accuracy: 0.6623\n","Epoch 43/200\n","19/31 [=================>............] - ETA: 0s - loss: 0.2280 - accuracy: 0.9158\n","Epoch 43: val_accuracy did not improve from 0.70130\n","31/31 [==============================] - 0s 5ms/step - loss: 0.2607 - accuracy: 0.9088 - val_loss: 1.0633 - val_accuracy: 0.6234\n","Epoch 43: early stopping\n","Best model saved successfully.\n","Training stopped early at epoch 42 due to EarlyStopping.\n","3/3 [==============================] - 0s 7ms/step - loss: 0.6860 - accuracy: 0.7396\n","Test Accuracy: 73.96%\n","\n","Best model saved successfully.\n"]}]},{"cell_type":"code","source":["# Weights"],"metadata":{"id":"WaWwdRRx8JbR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from keras.models import load_model\n","import os\n","filepath = \"./saved_models/best_model.keras\"\n","# Load the saved model\n","loaded_model = load_model(filepath)\n","\n","# Display the model's architecture\n","print(\"Model Summary:\")\n","loaded_model.summary()\n","\n","# Display the model's weights\n","print(\"\\nModel Weights:\")\n","for layer in loaded_model.layers:\n","    print(f\"Layer: {layer.name}\")\n","    weights, biases = layer.get_weights()\n","    print(f\"Weights:\\n{weights}\\nBiases:\\n{biases}\\n\")\n","\n","input_layer_weights = loaded_model.layers[0].get_weights()[0]\n","\n","# Print the weights\n","print(\"Input Layer Weights:\")\n","print(input_layer_weights)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3_Qh6EXI8LsE","executionInfo":{"status":"ok","timestamp":1715313033737,"user_tz":-300,"elapsed":403,"user":{"displayName":"Sheikh Muhammad Talha BSSE 2021 FAST NU LHR","userId":"05044819345239191473"}},"outputId":"c6e0b467-2d7b-43ce-e40e-b7232d900bbd"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Model Summary:\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense (Dense)               (None, 120)               7320      \n","                                                                 \n"," dense_1 (Dense)             (None, 3)                 363       \n","                                                                 \n","=================================================================\n","Total params: 7683 (30.01 KB)\n","Trainable params: 7683 (30.01 KB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","\n","Model Weights:\n","Layer: dense\n","Weights:\n","[[-0.02964146  0.08450705  0.02588058 ... -0.03197151  0.12134841\n","  -0.07497624]\n"," [-0.12006228 -0.1249656   0.2237588  ... -0.12070968  0.1862867\n","   0.00489551]\n"," [ 0.05940237 -0.18207702 -0.12747112 ...  0.15000093 -0.07355876\n","   0.04458492]\n"," ...\n"," [ 0.05135934  0.06444705  0.22980136 ... -0.03104367  0.09307854\n","  -0.2820721 ]\n"," [-0.34426093 -0.02911746  0.43763223 ...  0.05728138  0.29366913\n","   0.27388066]\n"," [ 0.2170654   0.11666892 -0.2336212  ... -0.02449156 -0.04715126\n","  -0.02908881]]\n","Biases:\n","[-1.03536427e-01 -1.76967047e-02  1.01124138e-01 -5.82600608e-02\n"," -3.88682522e-02 -5.21667227e-02  3.17597017e-02  3.81421559e-02\n"," -7.68668875e-02 -2.53437199e-02 -2.79600993e-02 -1.38533814e-02\n","  2.31998637e-02 -3.68252099e-02 -1.15218409e-03  1.39597105e-03\n","  3.49816866e-02  0.00000000e+00  3.66288163e-02 -3.54928449e-02\n","  1.54281082e-02  7.51639530e-02  6.78298399e-02  8.03478658e-02\n"," -2.71014720e-02 -9.14610282e-05 -4.02958244e-02  8.98125768e-02\n"," -5.31621687e-02  3.31870131e-02  7.80090392e-02  7.85550550e-02\n"," -4.50029038e-02  1.02379866e-01  4.35133427e-02 -4.51670913e-03\n"," -1.07838083e-02 -3.90720405e-02 -5.96189126e-03  8.19391664e-03\n"," -1.72117185e-02 -5.48803667e-03 -1.99535191e-02 -2.49667447e-02\n"," -3.89597453e-02  4.50743362e-02 -5.12433127e-02  1.85893193e-01\n"," -5.41636869e-02  7.07774460e-02  1.97128626e-03  6.42677397e-02\n","  7.00302497e-02  2.88286600e-02  3.88805680e-02  3.77617478e-02\n","  9.02162194e-02 -3.17636766e-02 -5.41081503e-02  3.29835601e-02\n"," -6.00451557e-03  5.62793687e-02 -7.05103343e-03 -2.52533667e-02\n","  3.16865998e-03  4.02373495e-03 -2.08026432e-02  0.00000000e+00\n"," -5.11218533e-02  1.25710610e-02  4.12800089e-02  0.00000000e+00\n","  2.86520049e-02  2.13784575e-02  0.00000000e+00 -3.71021852e-02\n"," -8.06989521e-03 -4.44143452e-02  5.74211478e-02 -2.07094941e-02\n"," -9.36520770e-02  6.30055070e-02  3.29256877e-02  0.00000000e+00\n","  1.00816362e-01  4.43302654e-02 -8.09449609e-03  2.69197300e-02\n","  4.65218462e-02  2.65045408e-02 -4.05579582e-02  0.00000000e+00\n"," -1.50848851e-02 -3.12957428e-02  4.22286689e-02 -3.23354900e-02\n"," -6.52562901e-02 -3.23301591e-02 -2.55579986e-02  8.66304990e-03\n","  5.85266873e-02  7.34716281e-03 -8.69228244e-02  2.36317818e-03\n","  5.48681058e-02  6.30885810e-02  1.86376683e-02 -4.49460708e-02\n","  1.22909240e-01 -3.77027243e-02  2.61683483e-02  9.10007060e-02\n","  2.17436459e-02 -7.67750153e-03  1.37553766e-01 -6.56308010e-02\n","  6.07829355e-03  3.98683064e-02  5.63138053e-02  4.36802097e-02]\n","\n","Layer: dense_1\n","Weights:\n","[[ 0.09877978 -0.21253332 -0.08308555]\n"," [ 0.06322894  0.09288861 -0.05862248]\n"," [ 0.1780378   0.16867276 -0.3556666 ]\n"," [ 0.14807512  0.01603657 -0.09896041]\n"," [-0.00949408 -0.1102498   0.1746756 ]\n"," [ 0.00583268  0.06955896 -0.12755783]\n"," [-0.1128298   0.11997034 -0.09334397]\n"," [-0.03935065  0.1153363  -0.05882057]\n"," [ 0.03259419 -0.14029677 -0.16186069]\n"," [ 0.1622759  -0.14492197 -0.18820095]\n"," [ 0.00226703  0.00928781 -0.07553716]\n"," [ 0.24534474  0.01118588  0.00467819]\n"," [-0.05874484  0.09518592 -0.08284528]\n"," [ 0.16630772  0.19454572 -0.12821668]\n"," [ 0.06846675  0.21741676 -0.14934956]\n"," [-0.06757268 -0.18287334  0.06737038]\n"," [ 0.06461691  0.07974231  0.13315178]\n"," [-0.14694339  0.08288859  0.03507219]\n"," [-0.22820055  0.06470217 -0.01773779]\n"," [ 0.05254732 -0.13214517  0.12744817]\n"," [-0.18032497  0.00371082  0.10592204]\n"," [-0.3997312  -0.03992856  0.22456655]\n"," [-0.17710078 -0.04836869 -0.1707094 ]\n"," [-0.2069925   0.07542809 -0.13517594]\n"," [ 0.06363666 -0.12411495  0.10195399]\n"," [-0.08553112 -0.1280956   0.2509762 ]\n"," [ 0.16418454 -0.04055335 -0.23807648]\n"," [-0.14129849  0.06144518  0.01027411]\n"," [ 0.23116976 -0.17684455  0.05053356]\n"," [-0.0466052  -0.00394592  0.20459421]\n"," [-0.2017824   0.06900277  0.1310357 ]\n"," [-0.13751562  0.05510911  0.12153345]\n"," [-0.05577089 -0.22518156  0.16702826]\n"," [-0.21393673  0.6208781  -0.41673052]\n"," [ 0.0073214  -0.07218084  0.14553963]\n"," [-0.02358603 -0.17814161  0.2502741 ]\n"," [-0.15390687 -0.12422393  0.13833266]\n"," [ 0.19649878  0.12229197 -0.19348207]\n"," [ 0.0438603   0.13521431 -0.20815246]\n"," [ 0.04322604 -0.06453667  0.17112914]\n"," [-0.5075589  -0.17782606  0.15718548]\n"," [-0.02644989 -0.26142442  0.19169636]\n"," [ 0.1678984   0.09201309 -0.16416979]\n"," [ 0.21349695 -0.31242153 -0.10693504]\n"," [-0.04937652 -0.07467265  0.03127375]\n"," [-0.16573547 -0.08126244  0.01443101]\n"," [ 0.13817897 -0.01215856  0.19151253]\n"," [-0.20137416  0.11278038 -0.05665009]\n"," [ 0.24406262  0.14255705  0.00610801]\n"," [-0.01850093  0.15694916 -0.02017596]\n"," [-0.10442678  0.01455362 -0.22036801]\n"," [-0.1793268   0.09984735  0.17179286]\n"," [-0.01345515  0.02183389  0.08050002]\n"," [-0.2758714  -0.00487432 -0.01544956]\n"," [-0.12644067  0.07983698 -0.23991677]\n"," [ 0.2638923  -0.0046404  -0.13603535]\n"," [ 0.10361884  0.26477414 -0.01868208]\n"," [ 0.17465445 -0.20120354  0.19110781]\n"," [ 0.15278395 -0.08901002  0.04931809]\n"," [ 0.16903718  0.20374086 -0.1660146 ]\n"," [-0.06320328 -0.15627758  0.14932519]\n"," [-0.13985121  0.19091643  0.04481573]\n"," [ 0.27017054  0.04915798 -0.21551934]\n"," [-0.17090736 -0.13394573 -0.2128202 ]\n"," [-0.1286649   0.14093453 -0.11477975]\n"," [ 0.09603291  0.06943308  0.15886557]\n"," [-0.04782275 -0.04637621 -0.11586712]\n"," [ 0.19720013  0.1588362   0.11268814]\n"," [ 0.09999648 -0.19184957 -0.04009603]\n"," [-0.14795983  0.01661693 -0.11595908]\n"," [ 0.01211999  0.35066766 -0.12139395]\n"," [-0.22014244 -0.16463205  0.04404698]\n"," [-0.06219612 -0.12942778  0.10060763]\n"," [-0.0498585   0.17989656 -0.16675362]\n"," [ 0.11682113  0.11631079  0.21382113]\n"," [-0.18995443 -0.06507334  0.1994057 ]\n"," [-0.06084235  0.09427223 -0.13746497]\n"," [ 0.03658384 -0.0683655  -0.30842823]\n"," [-0.06479062  0.14110798 -0.08601905]\n"," [-0.1311264  -0.16695878 -0.05260886]\n"," [ 0.1820288  -0.09995334 -0.04097299]\n"," [-0.1677771   0.02709592  0.03195416]\n"," [ 0.07617934  0.16746143  0.03702626]\n"," [-0.13498099  0.18975239 -0.17425244]\n"," [-0.33541897 -0.06334119 -0.0778848 ]\n"," [ 0.0608898  -0.01630554 -0.08779714]\n"," [-0.14829935  0.15236306  0.16654317]\n"," [-0.17989364 -0.16557299 -0.01493586]\n"," [-0.33023292  0.02077721  0.20392676]\n"," [-0.07066383  0.39814198 -0.28641275]\n"," [ 0.12670873  0.02358323 -0.18890686]\n"," [ 0.20744441  0.153964    0.15661816]\n"," [ 0.07684581 -0.31416622 -0.01185038]\n"," [-0.11501713 -0.18836284 -0.07698077]\n"," [-0.11379778  0.20232391  0.17932512]\n"," [-0.15054148 -0.16234116  0.20224677]\n"," [-0.09394643 -0.07244402  0.1918382 ]\n"," [ 0.00330379  0.23877588 -0.1951283 ]\n"," [-0.09301933 -0.12944157 -0.02990155]\n"," [ 0.17166685  0.20090404 -0.14288703]\n"," [-0.15119438  0.13627203  0.19362257]\n"," [ 0.23402306  0.14986828 -0.05191137]\n"," [ 0.2197538  -0.1506443  -0.09814388]\n"," [-0.06769212  0.04474182  0.04975548]\n"," [-0.12618074  0.1744682  -0.10003652]\n"," [-0.0040665   0.20445745  0.18202507]\n"," [ 0.21497901  0.1551754  -0.4327012 ]\n"," [ 0.1613787  -0.20467374  0.16072005]\n"," [-0.16435726  0.22846058 -0.02700608]\n"," [ 0.19346474  0.0758113   0.03722934]\n"," [-0.09697274 -0.11520775  0.15631263]\n"," [-0.14973696  0.09972367  0.09100361]\n"," [ 0.25097224  0.07579684 -0.10422868]\n"," [ 0.12129174  0.14874506  0.07244272]\n"," [-0.08394976  0.30579776 -0.38838428]\n"," [ 0.12839164 -0.1508937  -0.22566159]\n"," [-0.07104531 -0.19732259  0.20488413]\n"," [-0.18676753 -0.0406097   0.1568313 ]\n"," [-0.16171421  0.0884538   0.16067085]\n"," [-0.21086304  0.12792006  0.24508175]]\n","Biases:\n","[-0.07911614  0.07775134  0.02817028]\n","\n","Input Layer Weights:\n","[[-0.02964146  0.08450705  0.02588058 ... -0.03197151  0.12134841\n","  -0.07497624]\n"," [-0.12006228 -0.1249656   0.2237588  ... -0.12070968  0.1862867\n","   0.00489551]\n"," [ 0.05940237 -0.18207702 -0.12747112 ...  0.15000093 -0.07355876\n","   0.04458492]\n"," ...\n"," [ 0.05135934  0.06444705  0.22980136 ... -0.03104367  0.09307854\n","  -0.2820721 ]\n"," [-0.34426093 -0.02911746  0.43763223 ...  0.05728138  0.29366913\n","   0.27388066]\n"," [ 0.2170654   0.11666892 -0.2336212  ... -0.02449156 -0.04715126\n","  -0.02908881]]\n"]}]},{"cell_type":"code","source":["# Get column names\n","column_names = table.drop(\"Marks\", axis=1).columns\n","\n","# Display the model's weights along with column names\n","print(\"\\nModel Weights:\")\n","for i, layer in enumerate(loaded_model.layers):\n","    print(f\"Layer: {layer.name}\")\n","    if layer.get_weights():  # Check if layer has weights\n","        weights, biases = layer.get_weights()\n","        print(\"Weights:\")\n","        for j, column_weight in enumerate(weights):\n","            print(f\"{column_names[j]}: {column_weight}\")\n","        print(\"Biases:\")\n","        print(biases)\n","    else:\n","        print(\"No weights in this layer\\n\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"wWAvect4C1u0","executionInfo":{"status":"error","timestamp":1715313040202,"user_tz":-300,"elapsed":524,"user":{"displayName":"Sheikh Muhammad Talha BSSE 2021 FAST NU LHR","userId":"05044819345239191473"}},"outputId":"f822a610-ba6d-4e33-8728-cb41a5b17657"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Model Weights:\n","Layer: dense\n","Weights:\n","Gradeid: [-0.02964146  0.08450705  0.02588058 -0.02953018 -0.15378086 -0.0958579\n","  0.04807127  0.09641556 -0.04913118 -0.07645153 -0.06525625  0.11462119\n"," -0.06849965 -0.1490519  -0.08212409 -0.06692954 -0.00314165 -0.1109332\n","  0.07747892  0.01617776 -0.21151334 -0.14819992 -0.13759148  0.07940987\n","  0.00937562  0.15318123 -0.05338179 -0.03367647  0.0564712   0.07105513\n","  0.17391236  0.07594772  0.03740609  0.2793644  -0.06818891 -0.20735903\n"," -0.23670153 -0.12458661  0.19875264 -0.01361942 -0.06719889 -0.02959021\n","  0.0270166  -0.2256084   0.14834669 -0.00976107 -0.19544278  0.20627718\n"," -0.01553446  0.15898052  0.04801355 -0.11732601  0.10234061  0.0598422\n"," -0.14826699  0.04250617  0.21833506 -0.10084663 -0.00092706  0.02537625\n","  0.08092457 -0.01532994  0.07804631  0.02608969  0.09368189  0.05524678\n","  0.05495373 -0.15201338 -0.18042043  0.05493664 -0.1794596  -0.14820968\n"," -0.07489999 -0.06538312 -0.10792682  0.01670357  0.12709484 -0.01702608\n","  0.18934408 -0.02008255 -0.02965012 -0.14411439 -0.13755716 -0.02203564\n","  0.23587607 -0.03095569  0.11768082 -0.02997726  0.10927347 -0.07899588\n","  0.09949976 -0.00091472 -0.04144022  0.02770977  0.03142782 -0.07934159\n"," -0.03316828 -0.16504288 -0.17472474 -0.07991382  0.15963946  0.14630459\n","  0.03542506 -0.05990465  0.11641818  0.04035233  0.01709657 -0.06970464\n","  0.22613269  0.1441943   0.07727766 -0.05023664  0.00670159  0.068287\n","  0.13187455 -0.17800273  0.06906108 -0.03197151  0.12134841 -0.07497624]\n","Semester: [-1.20062284e-01 -1.24965601e-01  2.23758802e-01 -4.88722185e-03\n"," -1.91074744e-01 -1.05893761e-01  4.91327569e-02  1.43625531e-02\n"," -2.62919087e-02 -1.48491878e-02 -6.74095601e-02  1.35876656e-01\n","  1.05203710e-01  1.20677181e-01  1.03851296e-01  6.92804679e-02\n"," -1.47340428e-02  1.42013669e-01 -5.61763998e-03 -1.43836215e-01\n"," -7.22959042e-02 -4.94376160e-02  2.52658129e-01  9.63155776e-02\n"," -7.03411456e-03  1.01655517e-02 -1.98269889e-01  6.78315535e-02\n"," -1.14626162e-01  1.37972534e-01  7.91004822e-02  5.22438698e-02\n"," -1.49659023e-01  8.67757350e-02 -1.89148216e-03  1.26218930e-01\n","  7.20995516e-02  2.08284445e-02  1.77480876e-01 -7.19595775e-02\n","  1.14895493e-01 -3.66026200e-02  1.51847333e-01 -1.86539933e-01\n","  5.94771840e-02  9.78818908e-02  8.17906484e-02  4.52252254e-02\n","  4.43313718e-02  4.50731218e-02 -1.51597843e-01 -3.25102396e-02\n","  8.46001729e-02 -2.82217492e-03  2.04804003e-01  4.12696749e-02\n","  2.89743811e-01 -2.15690926e-01  3.54057960e-02  2.18224838e-01\n"," -8.47117752e-02  3.79375331e-02 -4.79021892e-02  1.43991843e-01\n","  1.51193798e-01  5.36676198e-02 -1.01024471e-01 -4.40142453e-02\n"," -6.36875182e-02 -1.51687898e-02  3.26926969e-02  3.78719121e-02\n","  1.65944979e-01  6.76077753e-02 -1.82430446e-03  2.54079234e-03\n"," -1.22630678e-01  9.53758359e-02  5.68773150e-02  5.82891814e-02\n"," -1.32252470e-01  8.34471658e-02 -9.14253443e-02 -9.64383632e-02\n"," -2.21132655e-02  2.09012657e-01 -6.46665245e-02  1.01866364e-01\n","  1.02286064e-03  2.03727633e-01 -7.17308223e-02 -1.22557819e-01\n"," -2.59518117e-01  1.07905809e-02  3.65875624e-02  1.08262673e-01\n"," -4.45597582e-02  8.24580118e-02 -2.30646685e-01 -1.83167592e-01\n"," -1.01829164e-01  9.04552080e-03  4.47660759e-02 -1.81217104e-01\n","  9.08417404e-02  5.59421629e-02 -2.83163432e-02 -8.12404007e-02\n"," -2.86673866e-02 -6.00883104e-02  7.27813393e-02 -5.96666522e-02\n"," -1.53483167e-01 -1.94085645e-04  2.03629494e-01  1.08364433e-01\n"," -2.56782882e-02 -1.20709680e-01  1.86286703e-01  4.89551248e-03]\n","Raisedhands: [ 0.05940237 -0.18207702 -0.12747112  0.14523771  0.07585468 -0.06146329\n","  0.05529229  0.02119888  0.13746922 -0.00351078 -0.09287204 -0.14614797\n","  0.1549706   0.02204472  0.10052986  0.02500421 -0.03152929 -0.07830098\n","  0.02468522  0.06888665 -0.11823075  0.02328041  0.03471176  0.00140164\n"," -0.14325647  0.05097916  0.11128937  0.16933735  0.11184131  0.07840164\n","  0.14002529 -0.09116551 -0.2001596  -0.01975607  0.152992   -0.00092714\n"," -0.03774043  0.10256885 -0.08292144  0.15695362 -0.13062277  0.08708198\n","  0.14742444 -0.02282508  0.07351637  0.08255444  0.09848263  0.17697665\n"," -0.11088319  0.05329825  0.06327105  0.01339498 -0.11814672 -0.04135656\n","  0.02469538 -0.14454235 -0.15662628  0.10299106 -0.08813038 -0.02246081\n"," -0.0926146  -0.1863864  -0.07083014 -0.09998151 -0.0453011  -0.02693836\n"," -0.00430605 -0.00024246  0.10984214 -0.04590362 -0.08002076 -0.03130873\n","  0.1546051   0.03424223 -0.00723328 -0.03383636 -0.12502596 -0.04790966\n"," -0.06853656  0.02839282 -0.00632614 -0.05381935  0.17914052 -0.07204528\n","  0.10577676 -0.09891758 -0.09663     0.0083955   0.04166355 -0.10951019\n","  0.15951286 -0.17356993 -0.09655559  0.14837496 -0.10084813  0.00073379\n"," -0.08817911  0.13936561 -0.1260423   0.10310575 -0.06315207  0.00871125\n","  0.12305219 -0.15442623 -0.1318094  -0.07517762 -0.03104126 -0.13810138\n","  0.10914578 -0.2167524  -0.06030145  0.15437436 -0.10099051 -0.08679716\n","  0.11571728  0.03455655  0.07982078  0.15000093 -0.07355876  0.04458492]\n","Visitedresources: [ 0.18871002  0.0128679  -0.15511996  0.08334436 -0.16283713 -0.20357938\n","  0.04600532  0.02602058  0.13169135  0.0171898   0.10085028  0.13892625\n"," -0.13338502  0.1446491  -0.04808486  0.15160565 -0.01916447 -0.12569866\n"," -0.08202765  0.1379269   0.12929748 -0.11310183  0.15245748 -0.12195008\n"," -0.18018258 -0.05845694 -0.07769348 -0.02448193 -0.19365096  0.12842032\n","  0.1655495   0.09732863  0.16512045 -0.01266078  0.1022183  -0.08166398\n"," -0.10284267  0.02196364  0.12417546  0.11329387 -0.1878455  -0.05327096\n","  0.02987345  0.14326811 -0.03914903  0.123037   -0.19662021 -0.09130229\n","  0.1629839   0.0861516   0.15336469  0.02111588 -0.04080637 -0.10628751\n","  0.06849687 -0.15630014 -0.116887   -0.03864319  0.17078392  0.07116059\n"," -0.12319472  0.07178976  0.00926388  0.01641054 -0.01080611  0.05639905\n"," -0.15436979 -0.12449791  0.04257753  0.06086522  0.06135159 -0.02770565\n","  0.13813359  0.06398486 -0.05790904 -0.19405726  0.12969998  0.06293015\n","  0.16898824 -0.14813584 -0.02581794  0.1631878  -0.08391756  0.03004651\n"," -0.0168276  -0.20132214 -0.0637374  -0.01083771  0.02190945 -0.15636201\n"," -0.06899697 -0.08165076  0.06604382  0.10004185  0.03285682 -0.11686688\n"," -0.09330481  0.07056979 -0.06899796 -0.1797037   0.15824302  0.00172829\n","  0.17504004 -0.08167409  0.11405906 -0.11733264  0.05435143  0.01911618\n"," -0.16184315 -0.03887457  0.1176343  -0.06136237  0.03690758  0.14900042\n"," -0.08649771  0.15315866  0.05385903  0.0395341   0.05229071  0.0791119 ]\n","Announcementsview: [-0.06789085  0.15186548  0.08625194  0.15998535  0.02731865  0.14552571\n","  0.07527393 -0.01261926  0.03758242  0.06565159  0.1522622  -0.21233018\n"," -0.11708252 -0.01280651  0.07636416 -0.11397973  0.03252087 -0.14218621\n","  0.1392995   0.02870973  0.09540787  0.09266946  0.01804373  0.09274378\n","  0.13320118  0.06456643  0.07067071 -0.06831913  0.13424048  0.09275515\n"," -0.16295816 -0.15676884 -0.14421509 -0.10984337 -0.05567213  0.13462108\n","  0.09971173  0.11402748 -0.02751545 -0.15762068 -0.19335209 -0.06001803\n"," -0.1534207  -0.00797537  0.00278858 -0.13321956  0.041459   -0.04506036\n","  0.00511031 -0.05369392 -0.07887368  0.09355711  0.11931494 -0.1201786\n"," -0.1500973   0.08262631  0.03072377  0.05478258  0.16115394 -0.15651658\n","  0.02160517 -0.0824181   0.05993308  0.16388425  0.12431563 -0.07143798\n","  0.12860116 -0.03832226 -0.06597316  0.10386583 -0.27916005  0.01348683\n","  0.15978119 -0.02222792 -0.08839559 -0.16231845 -0.05239749 -0.07833661\n","  0.00939308 -0.07868263  0.0264219  -0.08874132  0.05738521 -0.09596843\n"," -0.07117933 -0.01521646 -0.15543006  0.0476798  -0.08487078 -0.16835304\n"," -0.1662199   0.02213697  0.08732424  0.14907792  0.16832256  0.09053427\n"," -0.16642612 -0.01155255  0.06480797  0.09702888  0.02447877 -0.25302383\n"," -0.05162917  0.00589865  0.02639717  0.0440858  -0.06892302  0.08835337\n","  0.0635351   0.02056584  0.00279683  0.16995323  0.0961908   0.10500343\n"," -0.09362818  0.06116863  0.16769184 -0.1434822   0.16068968 -0.17559543]\n","Discussion: [ 0.14895149  0.02182332  0.04808106  0.10314167 -0.15706089  0.04884499\n"," -0.17480706 -0.00069762  0.0772763  -0.09518084 -0.17772101 -0.12023976\n","  0.01641012 -0.1431512  -0.11781831 -0.0470536   0.05910389 -0.16678862\n"," -0.10250847  0.02714456 -0.10392691 -0.07324976 -0.03410868 -0.06021725\n"," -0.19634396 -0.14765273 -0.05296863  0.05353289 -0.03155017  0.07902082\n"," -0.00473217  0.16639201  0.12641373 -0.02118549 -0.14941546 -0.15548126\n"," -0.05345188  0.13109979  0.02431074  0.03136181  0.14308406  0.02544223\n"," -0.05221017 -0.18601565 -0.15666844 -0.16733874  0.17898387 -0.04466545\n","  0.18048885 -0.0731921   0.04471618  0.05026643  0.18562634  0.14685519\n","  0.01946519  0.0628178   0.10748579  0.02480128 -0.10283861  0.04764375\n"," -0.05835627  0.14359993 -0.12374112  0.12936383 -0.05680915 -0.0225413\n","  0.12444987 -0.14632687 -0.09580384 -0.1136584   0.02459138 -0.15178981\n"," -0.12718157  0.14132784 -0.1723442   0.090511    0.08661231 -0.19737846\n","  0.11624685  0.19260594  0.1878664   0.11684566  0.14418006 -0.03585751\n"," -0.12879388  0.12416966 -0.01906754  0.02651804 -0.07366543  0.04105411\n","  0.00660296 -0.10825982 -0.0223437  -0.00534854 -0.10769548 -0.14289854\n","  0.18831663 -0.10979752  0.09429944 -0.08819874 -0.01163858  0.09546692\n","  0.05635639  0.07431144 -0.01154826  0.15020604 -0.18683997  0.14339703\n","  0.08656108  0.14422567  0.12258458  0.04375941 -0.14043151  0.0316713\n"," -0.11606359 -0.09759615  0.01715931 -0.01325305 -0.02651375 -0.10629314]\n","Parentansweringsurvey: [-0.00168917 -0.09800982 -0.08522281 -0.08092226 -0.04627281 -0.0287856\n"," -0.2698528  -0.11476959  0.00345548  0.04972656 -0.18390463 -0.09495457\n"," -0.05880452  0.08002023 -0.04306642  0.06019987 -0.15863422  0.02034731\n"," -0.22109981  0.22879338  0.02292516 -0.25196457 -0.07175862  0.01329457\n"," -0.0018159  -0.07565149 -0.09500261 -0.17624542  0.2091529  -0.13675068\n"," -0.13818546 -0.06499536  0.21260454 -0.01358907 -0.02428319 -0.00639674\n"," -0.05656461  0.10002296  0.05754032  0.00803852 -0.17729256  0.11848557\n","  0.06941645  0.05235814  0.22936638 -0.0570891   0.18646987 -0.21696638\n"," -0.12653467 -0.4210003  -0.23741421 -0.2016467  -0.1349852  -0.07308898\n"," -0.28794068  0.06915291 -0.19673966  0.29740426  0.3025454  -0.04698413\n","  0.04213423  0.04362358 -0.05758495 -0.16527018 -0.36337277  0.21531531\n"," -0.00414254  0.01403743  0.27832723 -0.14209609 -0.16867714  0.15735495\n","  0.23978947 -0.12738362 -0.05465755 -0.31608364 -0.05219482 -0.02469364\n"," -0.2776643   0.24826449 -0.03525155  0.02717027 -0.10770837  0.12024707\n"," -0.22289075  0.04822402  0.12991105 -0.01446764  0.14043336  0.33187836\n","  0.01781271  0.15685895  0.18631144  0.11300002 -0.26224205 -0.07726604\n","  0.03589715  0.03853491 -0.13444863 -0.14952715 -0.17782111 -0.00889364\n","  0.19170558 -0.13324198 -0.19668438  0.07008378 -0.01418538  0.11435861\n"," -0.00555177  0.11427785  0.08154938 -0.14250799  0.05702503 -0.14938138\n"," -0.18833242  0.00878411  0.05137838 -0.13163409 -0.07349017  0.12991132]\n","Parentschoolsatisfaction: [ 3.26194406e-01  2.85880014e-05 -3.92249376e-02  1.13101698e-01\n","  7.18688443e-02 -1.25380322e-01 -1.29360765e-01 -8.05076733e-02\n","  1.13713361e-01 -5.63143529e-02 -6.79048970e-02 -2.58097537e-02\n","  2.16224957e-02  7.10208789e-02  2.01589093e-01  3.90506722e-03\n"," -1.19909756e-01  7.89227486e-02 -9.57557186e-02  2.06486166e-01\n"," -2.38464531e-02 -3.86700720e-01 -2.89787173e-01  1.43266529e-01\n"," -1.37766907e-02 -1.49166524e-01 -3.06772571e-02 -2.28188172e-01\n"," -5.37310503e-02  1.60126314e-02 -2.58366436e-01  4.72498452e-03\n","  1.13830008e-01 -1.81990638e-01  2.90412344e-02 -1.44076362e-01\n"," -9.17686000e-02  2.00533979e-02  7.02959821e-02  1.04026459e-01\n","  2.48915315e-01 -6.43754890e-03  5.40163144e-02 -7.40712062e-02\n","  1.85655221e-01  1.01630233e-01  9.62160155e-02 -2.68748581e-01\n","  1.23214565e-01 -1.56318858e-01 -1.06620882e-03 -2.47841120e-01\n"," -2.68370330e-01  3.93956080e-02 -1.93901241e-01  6.65316805e-02\n"," -6.44705519e-02 -3.50799523e-02  2.73022920e-01  6.48711324e-02\n","  1.36670589e-01 -3.31943631e-01  1.85607776e-01 -4.79328334e-02\n","  1.54549628e-01  1.35316044e-01 -1.29622340e-01  1.77861780e-01\n"," -3.08498256e-02 -9.39886495e-02 -1.08139098e-01  1.70656174e-01\n"," -3.29982191e-02 -3.73670482e-03  1.26470983e-01  3.32558155e-01\n","  4.04051179e-03  1.22746557e-01 -2.20360145e-01  4.26589698e-03\n","  7.13460296e-02 -3.01087797e-01  5.77679761e-02  5.21806180e-02\n","  6.27103001e-02 -2.01777577e-01 -3.20363566e-02  7.90432096e-04\n"," -5.45890927e-02  1.59830712e-02  9.99654531e-02  1.51706845e-01\n","  2.03808025e-01  9.37804058e-02 -1.77822605e-01 -2.38946140e-01\n"," -4.79478501e-02  2.10525587e-01  2.11120874e-01  1.16554257e-02\n"," -1.35419682e-01  5.44907004e-02  1.67761907e-01 -1.62286888e-04\n"," -1.55885950e-01 -1.82108544e-02 -2.73155179e-02  2.30357230e-01\n"," -7.92753473e-02  2.62777656e-01  8.73127580e-02  7.43653551e-02\n","  1.15703464e-01 -4.84428778e-02 -8.04259479e-02  2.24850863e-01\n","  8.40928480e-02  9.10100639e-02 -5.26584045e-04 -1.85878471e-01]\n","Gender_F: [ 0.00326826 -0.12483535  0.13658659  0.19425981 -0.03399536  0.1417971\n"," -0.01080654 -0.09224808  0.20978223 -0.08744116 -0.06451689  0.23747964\n"," -0.08507797  0.10340557 -0.01117869 -0.13227797 -0.13244794  0.10956159\n"," -0.2563045  -0.0734947  -0.04662218  0.00516517 -0.14511025  0.0738323\n","  0.073232   -0.01859949  0.00395435 -0.21870309  0.06672429 -0.06685261\n"," -0.07832786 -0.13646694 -0.0119032  -0.00128393 -0.1808031  -0.00900299\n","  0.18051864 -0.13347526 -0.15712978 -0.15069778 -0.01444936  0.20098884\n"," -0.11911348  0.14089972 -0.06913731  0.01742455 -0.13237777 -0.06330551\n"," -0.0805281  -0.07464463 -0.11815324 -0.12712061  0.01293391  0.07175165\n"," -0.0119301  -0.21739084 -0.11926445  0.16126154 -0.01777457 -0.12152195\n","  0.00510575 -0.0982313  -0.17886204 -0.07503974 -0.26054806 -0.07453591\n","  0.07400722  0.11878189  0.01932535 -0.00732605 -0.1859258  -0.10614862\n","  0.1430796  -0.17255194  0.00904447  0.09673712 -0.30820858 -0.0950701\n"," -0.10989112 -0.05506025  0.23470974 -0.04354471  0.00692448 -0.11650953\n","  0.23900999  0.09621937  0.15081936  0.00555698  0.04475218 -0.10486642\n","  0.02084218  0.13735208  0.24716109 -0.04185044  0.01429098  0.02757481\n"," -0.05759453 -0.1101414   0.0496132   0.25095686 -0.11275361  0.03260111\n","  0.03254233  0.16685207  0.06825245  0.01156832  0.00535827  0.18791214\n"," -0.07736958  0.09978294  0.02294934  0.00291793 -0.21359378 -0.16081257\n","  0.03053509  0.05408191  0.17621648 -0.21229337 -0.04812015 -0.14089802]\n","Gender_M: [-0.17131199  0.07380505  0.06516634 -0.0848602  -0.11592517 -0.25129408\n"," -0.04685646  0.14100909 -0.22779953  0.00680802  0.08750544 -0.3887773\n","  0.10109214  0.04513419 -0.09621311 -0.16727631  0.06048577 -0.15767594\n","  0.01115522  0.09073712 -0.1265264  -0.02586279  0.06692257 -0.04165929\n"," -0.18028183  0.02762316 -0.19616807  0.19494298 -0.06405151 -0.02335899\n","  0.31784979 -0.01856201  0.06384025  0.1701602   0.11983961 -0.13620637\n"," -0.03492828  0.07887125  0.11136641 -0.14780268 -0.05833813  0.06219247\n"," -0.22164339  0.10203917  0.12167575  0.07088078  0.07876673  0.36913136\n","  0.04363064  0.19931985 -0.14605126  0.15206961  0.23848544  0.07457701\n","  0.03089737  0.04927505  0.28674996  0.0075023   0.02157866 -0.07309449\n"," -0.02168399  0.29840815 -0.05479353  0.08151702  0.08950294  0.11088005\n"," -0.12632433 -0.06326821  0.09973232  0.06766546  0.10145306  0.0126963\n","  0.05136844  0.24319047  0.08068103  0.14306597  0.16516632 -0.02979897\n","  0.05101981 -0.1539414  -0.22670397  0.12435488  0.16616474  0.06210245\n"," -0.07639178  0.02840189 -0.05014072  0.08279219  0.08728328  0.09469087\n"," -0.2019034   0.16516143 -0.30940962 -0.12165003  0.23045772  0.05395462\n"," -0.02248449  0.02898288 -0.12390101  0.10750192  0.03672379 -0.07571745\n"," -0.05438113  0.14544249  0.22241862  0.10502916  0.17150903 -0.07366685\n","  0.24144918 -0.34812963  0.16805172  0.02319174  0.30504888  0.07273376\n","  0.08654361 -0.00943992 -0.09589022  0.23052952  0.00329146  0.29576555]\n","Nationality_Egypt: [-2.63287604e-01  4.24802229e-02  2.74211794e-01  4.21531759e-02\n","  1.04223281e-01 -4.19668257e-02  2.56180674e-01  6.16650283e-02\n"," -2.87571996e-01 -3.75435129e-02  2.71023422e-01 -6.83770627e-02\n"," -1.01135500e-01 -2.12481674e-02  6.96610436e-02 -2.34209657e-01\n"," -2.84263100e-02 -3.08947116e-02  7.99522996e-02 -2.70560175e-01\n","  7.79467374e-02 -9.14350897e-02  7.57801309e-02  2.18059234e-02\n"," -9.71997306e-02 -1.13223001e-01  9.92413238e-02  3.62818271e-01\n","  7.34170824e-02  6.42287880e-02  2.05743954e-01  2.66642570e-01\n","  1.58408508e-02  2.39930600e-02 -7.78935030e-02  3.94322127e-02\n"," -2.94042379e-02 -1.37488738e-01  1.01549469e-01  3.83163653e-02\n"," -1.43207446e-01  1.06269948e-01  6.74272105e-02 -1.04350388e-01\n"," -1.32926852e-01 -1.02174617e-01 -1.25652468e-02  4.89669442e-02\n","  2.39045974e-02  3.18250597e-01  1.10854479e-02  1.70959905e-01\n"," -2.90389825e-02  4.79103290e-02  2.98753351e-01  2.92507529e-01\n"," -1.69097409e-02 -5.20565994e-02 -3.03370923e-01  1.01666763e-01\n"," -6.93909675e-02  1.84685618e-01  1.17450960e-01  2.15067565e-01\n","  2.90310323e-01 -1.33122727e-01 -1.91736355e-01  6.05272204e-02\n","  5.73014468e-02  2.03517869e-01  7.31280744e-02  1.77563339e-01\n"," -1.05756111e-02  2.81519622e-01 -1.03995577e-01  8.72450173e-02\n","  1.74048617e-01 -1.85603742e-02  1.03870474e-01  1.00756019e-01\n","  2.69719493e-03  2.67875165e-01  2.62565166e-01 -1.12848394e-01\n","  2.13926688e-01 -1.71473660e-02 -7.04621747e-02  5.74825779e-02\n","  2.37687081e-02 -1.52200639e-01 -1.32262498e-01  1.39638782e-04\n"," -3.38482857e-01  1.73180830e-03  9.98436585e-02  3.21488082e-03\n","  2.49200225e-01 -2.23962143e-02 -1.48376346e-01 -1.32552534e-02\n"," -3.57541703e-02 -8.43886882e-02 -2.79840946e-01 -3.45644802e-02\n","  3.34470272e-01 -5.22457995e-02  1.20250218e-01 -3.34104717e-01\n","  2.18376979e-01 -1.01204865e-01  5.73045164e-02  1.33381942e-02\n","  2.78921098e-01  1.87683016e-01 -1.69457734e-01 -2.66257495e-01\n"," -1.17834508e-02  1.60176292e-01  2.78659672e-01  9.59208459e-02]\n","Nationality_Iran: [ 0.01988913  0.03221971  0.21176246 -0.26556018  0.07064202 -0.05064185\n"," -0.16868655 -0.22372063  0.00404028 -0.0715951  -0.06274644  0.15965283\n"," -0.16620693 -0.21972717 -0.20019472  0.27084795  0.2904867  -0.14158942\n"," -0.14636779  0.26299402  0.13364913  0.0323398  -0.08756283  0.12918815\n","  0.00634515  0.09801546  0.00201073 -0.09552438  0.08951253 -0.00388822\n","  0.00875569  0.28363636  0.11673307 -0.16271803  0.03309186 -0.1066845\n"," -0.17447855 -0.06764408  0.01088266  0.28657135 -0.01457401  0.13803563\n"," -0.2767413   0.07552178  0.11253975 -0.02944675  0.0215993  -0.09262396\n"," -0.09214524 -0.15291093 -0.17294934  0.00484492  0.2607079   0.00536687\n"," -0.16691893 -0.13851923  0.14329554  0.2006982   0.08659486 -0.12396301\n"," -0.04390356  0.0710503  -0.16573256 -0.13736703 -0.06229568  0.3889073\n"," -0.1370459   0.10413417  0.09424581 -0.06441704  0.04997479  0.08145344\n","  0.19697754  0.04729181  0.15470251 -0.16547275  0.03771376  0.0015354\n"," -0.2744457  -0.02186415 -0.24239086  0.15169296 -0.05455775  0.02772002\n","  0.07150759 -0.14404234  0.06447937  0.2672311   0.11564407 -0.10861453\n"," -0.02875784 -0.0230083   0.07490962 -0.01781734  0.26603484  0.1532664\n"," -0.14437832 -0.13002847  0.09571264 -0.09955057  0.27380487 -0.171851\n"," -0.06773344  0.16517721 -0.18136743  0.23016272 -0.04041405  0.22757503\n","  0.07169314 -0.27578324  0.00089231  0.17192547 -0.11561144 -0.30547053\n"," -0.06817634 -0.27416605  0.05762029  0.12757234  0.03234014  0.09240061]\n","Nationality_Iraq: [ 0.1487857  -0.08635502  0.07055223  0.04560453 -0.099998    0.15919663\n"," -0.07617956  0.16293272 -0.09173304  0.07197469  0.01476146 -0.21529633\n","  0.04137419  0.02974728  0.10452719  0.07256227 -0.1656759  -0.06515633\n","  0.02408453  0.11004659 -0.18770671 -0.00673831 -0.27819327  0.04997252\n"," -0.0223766  -0.20818569 -0.04025035 -0.11653399  0.18153901  0.05996527\n","  0.01737573  0.13188887 -0.03801235  0.06441607  0.0176166   0.10054308\n","  0.16987932 -0.1135881  -0.12283534  0.08667592 -0.09863606 -0.17706984\n","  0.29231828  0.13570864 -0.1719989   0.11536137  0.02486684 -0.32562995\n"," -0.10080626 -0.13951318 -0.00371773 -0.11367777 -0.10501173  0.03382657\n"," -0.21185605  0.12313497 -0.08394237  0.02414954  0.04372838 -0.10876149\n"," -0.18153262  0.18847589 -0.15140872 -0.01503409  0.13701989 -0.02410811\n","  0.1109448  -0.09499007 -0.03822238 -0.25162837 -0.20497006  0.1209203\n"," -0.05750786  0.08596665  0.18114981 -0.12688085  0.11008239 -0.19883496\n","  0.01615939  0.11219057 -0.050919   -0.10288762  0.0619509  -0.06057446\n"," -0.2340621  -0.0282283  -0.0953581   0.09164648  0.14791375  0.09295553\n","  0.22100064  0.11483872 -0.11126935 -0.09727391  0.10617127  0.10266799\n"," -0.11797725 -0.028921    0.04191779 -0.1523398  -0.08605187  0.05020932\n"," -0.13506718 -0.01321857 -0.00089678  0.05538126 -0.23576693 -0.09307025\n"," -0.2485249   0.13655257  0.05110737  0.0620958  -0.10366673 -0.00955891\n","  0.0408036  -0.02012906  0.00367027  0.06947941  0.02437806  0.21611355]\n","Nationality_Jordan: [-0.20738478 -0.11648566  0.16448465  0.07358657 -0.20238477  0.0405035\n"," -0.08836889  0.16673927  0.0237326  -0.11820891 -0.12173658  0.14231242\n","  0.1737665  -0.07366829 -0.13763891  0.06485252 -0.09478636 -0.08441085\n","  0.2887116  -0.11747672 -0.04204907  0.03029982 -0.06716305  0.08542172\n"," -0.04699379  0.33369753 -0.10226984  0.16084103 -0.42910552  0.10546438\n","  0.04387259 -0.14523412  0.07148474  0.26311275  0.19779265  0.15750664\n","  0.07465735 -0.10220905 -0.18662328  0.04868981 -0.25635898 -0.2696154\n"," -0.23766972 -0.10151977  0.07491798  0.13594839 -0.05751825  0.20357475\n"," -0.21036246 -0.02559829  0.175657    0.05550278  0.04764237  0.34722683\n","  0.19292092  0.07226273  0.15279731 -0.01935821  0.03857262 -0.00615035\n"," -0.13907075  0.01340679  0.09485904 -0.1916106   0.02436638 -0.00547061\n","  0.06313916  0.16242051 -0.09956265 -0.10213976 -0.32573164  0.12990436\n","  0.04056265  0.04605796 -0.01015912 -0.18520868 -0.10648528  0.22828352\n","  0.04431283 -0.0127721  -0.10106006  0.12937275  0.18234089  0.06639551\n","  0.00118984  0.23619078  0.02864796  0.01445047 -0.04313638  0.1441293\n","  0.03700844 -0.13700528  0.07674833 -0.20385657  0.27352053 -0.18910731\n"," -0.23267058  0.16808586 -0.01349241  0.24782181  0.05444131  0.13009179\n"," -0.03118866  0.0355988   0.1122717  -0.02899629  0.38586318 -0.13262999\n","  0.3859653  -0.43554607  0.08350841  0.23576295  0.22954714 -0.03651382\n","  0.16467017 -0.00868184  0.05657849 -0.11820345  0.1747582  -0.23888078]\n","Nationality_Kuwait: [ 0.01460806 -0.01756513  0.19791842  0.09501642 -0.12314979 -0.20499857\n"," -0.05497311  0.14087062 -0.04667743 -0.03404815 -0.0406862  -0.17213666\n"," -0.19877122 -0.08342474  0.14260243 -0.01692993  0.14394657  0.0717361\n"," -0.1054782   0.10531618 -0.25548223  0.07342231  0.04860167 -0.1041279\n"," -0.1966928  -0.02785671  0.20412493 -0.00996626  0.17917687 -0.06901909\n","  0.15764125  0.03593904 -0.14378099 -0.03752838 -0.05259616  0.07125807\n","  0.01120558 -0.1277505   0.1649166  -0.12317222  0.20776488  0.14032708\n","  0.00838419 -0.07075974 -0.06645956  0.13035111 -0.09962432  0.22548096\n","  0.00252307  0.16498359 -0.00838103 -0.11624569 -0.05141639 -0.20939633\n","  0.00277094 -0.06981703 -0.12210161  0.01809166  0.0659529   0.28320664\n"," -0.04431182  0.03156541  0.10256629  0.08755615 -0.13426895  0.04172179\n","  0.07911937 -0.08040278 -0.21041675  0.04319822  0.08462574  0.16343287\n","  0.11709752 -0.01031139 -0.12895024 -0.11811516 -0.13708797  0.08862463\n","  0.05527883 -0.0631392   0.09540176 -0.08029602  0.06953664  0.10972369\n"," -0.07994117  0.15391248  0.03711202 -0.05873515  0.16177444 -0.12647437\n"," -0.34709913  0.01568736  0.09998956 -0.02676925 -0.07765725  0.14361472\n"," -0.22291721 -0.15874857 -0.04587301 -0.2599815   0.02657194  0.02891782\n"," -0.10677194 -0.0014974   0.01404209 -0.22242358  0.14553237 -0.00137782\n","  0.02673035  0.02998511  0.09044985  0.07706995  0.26075962 -0.01471298\n"," -0.012166    0.19340274  0.00334078 -0.08787299  0.06243476  0.34484598]\n","Nationality_Lebanon: [-2.20722500e-02 -1.58370093e-01 -3.13316494e-01  1.71513066e-01\n","  6.87876791e-02 -3.59232724e-01  3.97327244e-02  1.52205061e-02\n"," -1.06141381e-02  2.44566455e-01  5.33844391e-03 -3.01669955e-01\n"," -5.09397425e-02 -7.56266564e-02  9.10781398e-02  6.24461472e-03\n","  5.72876558e-02 -1.51643157e-01 -3.11293136e-02  5.67422956e-02\n","  6.94260672e-02 -2.15758398e-01  1.48097770e-02 -2.08134905e-01\n"," -9.70850363e-02 -9.10809189e-02  6.80845603e-02 -2.05730587e-01\n","  2.10316122e-01 -1.30244717e-01  1.38806095e-02  8.26150402e-02\n","  2.64446735e-01  2.71273315e-01 -1.65721744e-01 -1.57535180e-01\n","  4.03043628e-02  1.43460065e-01  1.62763357e-01 -1.22822903e-01\n","  1.53003305e-01  2.36919552e-01 -7.28205638e-03 -1.17423862e-01\n","  4.21618391e-03  1.76949814e-01 -4.74153496e-02 -7.12241158e-02\n"," -8.54044333e-02  2.89731562e-01 -5.69250062e-02 -3.34532838e-03\n"," -8.51490200e-02  1.22170478e-01 -3.16665381e-01 -1.53221458e-01\n"," -1.08803660e-02 -7.66007453e-02  7.01771304e-02 -2.56466329e-01\n"," -1.77654132e-01 -1.13735504e-01  1.03479348e-01  1.66538253e-01\n","  8.90647769e-02  1.60683632e-01  1.38052240e-01 -1.32483959e-01\n"," -4.83904332e-02 -1.04460977e-01 -1.92314401e-01 -8.75896886e-02\n","  8.36939216e-02  1.77835673e-01  1.13634825e-01  1.26967609e-01\n"," -3.39704342e-02 -1.87944263e-01 -1.45558417e-01 -1.98400673e-02\n","  1.04441017e-01  4.11931463e-02  5.32330945e-02  9.45693254e-02\n"," -7.15515614e-02 -4.32114583e-03  1.42821729e-01  3.89101990e-02\n","  1.06607698e-01  1.76841497e-01  4.79922369e-02  1.43227816e-01\n","  1.32171139e-01 -4.83338162e-02 -3.35767567e-01 -4.06066626e-02\n","  1.71449125e-01  2.43214920e-01  1.11261889e-01  1.86832562e-01\n","  9.77302119e-02 -5.27034253e-02  2.54302227e-04  1.37419000e-01\n"," -8.84722918e-02  5.21234311e-02 -3.20233941e-01 -7.71528780e-02\n","  1.32710963e-01 -8.17250907e-02  1.51192285e-02 -8.16922728e-03\n","  3.14939201e-01  1.58172593e-01 -5.67919910e-02  2.05493972e-01\n"," -1.78284004e-01 -1.57634184e-01  1.11064933e-01  1.92718297e-01]\n","Nationality_Lybia: [-0.08796296 -0.14397837  0.15931669  0.0908388   0.13132258  0.10167363\n","  0.06670357 -0.10599817 -0.00903901 -0.18784082  0.0094719  -0.1713874\n"," -0.11353776  0.02059658 -0.03956378 -0.19859716  0.01496702  0.1628775\n","  0.08161172 -0.1765836   0.12583882 -0.05044409 -0.02681644 -0.03417971\n"," -0.00654277 -0.04458364 -0.00813238 -0.06977521 -0.08558873  0.0362896\n"," -0.0432089  -0.05378513  0.07358518  0.16402085 -0.21884774 -0.13751958\n"," -0.00572246 -0.02622383  0.065042   -0.14787276  0.09705541  0.03416697\n"," -0.02294213  0.0489541  -0.1475656  -0.0222122  -0.20612429  0.14426255\n","  0.18770994  0.17983522 -0.00592339  0.01980998 -0.16194896  0.27086934\n","  0.03532955 -0.09243112  0.16110735  0.03783053 -0.00321557  0.12899938\n"," -0.04815744  0.07061666 -0.12394884 -0.02314974 -0.00619414 -0.16477868\n"," -0.09220924 -0.01774006 -0.20575958  0.0594228  -0.1509809  -0.10425606\n"," -0.01618148 -0.06260144  0.17866689 -0.0567334  -0.14859602 -0.12534694\n"," -0.10730445  0.04431856 -0.14195445 -0.03432427  0.14196075 -0.12663513\n","  0.26872438  0.16042873 -0.08989812  0.03545685  0.1352666   0.02644801\n","  0.12498225  0.13908616  0.02196722 -0.23747285  0.16177477  0.14963384\n","  0.14679393  0.20739803  0.1247915  -0.1046629   0.19521348 -0.14936778\n"," -0.0107296  -0.1819744   0.1408261   0.02474192 -0.05903843  0.02118252\n","  0.05062077 -0.09141981 -0.09401415 -0.04236821  0.10388434  0.01087282\n","  0.22820061  0.06978047  0.10425266 -0.10575919  0.20350431  0.14135954]\n","Nationality_Morocco: [-0.23890306 -0.0853964   0.39013702 -0.08047494  0.03120613  0.41057286\n","  0.00673191 -0.01217272  0.03743558 -0.06480445 -0.10829877 -0.03788236\n","  0.18923175 -0.29696593 -0.22772911  0.17184451  0.12521404  0.04662399\n","  0.2649314  -0.17432833  0.01343818 -0.17730224  0.33192614  0.2872229\n"," -0.0983687   0.30472457 -0.24307391  0.17995661 -0.32555422 -0.03798479\n","  0.12984294 -0.10987662 -0.08264004 -0.09575923  0.23574361 -0.04804805\n","  0.01166067 -0.06692183 -0.07418539 -0.16447274 -0.05599105 -0.02391572\n"," -0.13079967 -0.17552213 -0.06243692  0.12035604  0.05049602  0.10706705\n"," -0.22078952 -0.18967846  0.12089004  0.2208541   0.10928208  0.06309921\n"," -0.03418766  0.23562974  0.03690268  0.02590292 -0.05054403  0.07856289\n","  0.09589583  0.20417444  0.0693972   0.11154715  0.31351277 -0.06191576\n","  0.05316097 -0.02012411 -0.32678103  0.16924429  0.13719481 -0.12191594\n","  0.02427378 -0.11535    -0.11113048 -0.14772406  0.11966812  0.05629455\n"," -0.02446684 -0.20883314 -0.01670714  0.20225883  0.16411506  0.08245996\n","  0.12094647  0.1805675  -0.06837474  0.15471245 -0.04420248 -0.1695051\n"," -0.04814288  0.04712223  0.12692228 -0.08345078  0.29813203 -0.09807419\n","  0.03319219  0.01634089 -0.2306788  -0.16204143  0.26368028 -0.13078354\n","  0.01394912 -0.02484087  0.181369   -0.20866482  0.02445759 -0.06554615\n","  0.16563787  0.09398885 -0.12420999  0.02224106 -0.10281341  0.08067741\n"," -0.01178132 -0.18149315  0.02952451  0.15416905  0.07672532 -0.01499106]\n","Nationality_Palestine: [-0.27666143  0.26720822  0.01013644 -0.21515329  0.07078422 -0.07840301\n"," -0.07513307 -0.18261851  0.01632639 -0.18406352  0.06139021  0.07830221\n"," -0.10067181 -0.1416265  -0.1764421  -0.01219173  0.23258534 -0.13771181\n"," -0.181782    0.319955    0.00506379 -0.18388699 -0.21384859  0.07817928\n"," -0.04073173  0.02249396 -0.03142466 -0.05791065 -0.10294943  0.15356413\n","  0.2204708   0.2315931   0.28367683 -0.00266603  0.25927407  0.10632329\n","  0.16233271 -0.15843932 -0.00863344  0.0352061   0.12300947 -0.06655613\n"," -0.05538467 -0.09305517  0.29541874 -0.08776718  0.20547517  0.14210354\n","  0.01656899 -0.13792259 -0.14618607  0.09365728  0.11539872 -0.03871255\n"," -0.12109222 -0.16827658  0.17057943  0.04544612 -0.28677553 -0.06875373\n","  0.11497173 -0.02752003 -0.0377882  -0.15968518 -0.10890184  0.33635157\n"," -0.10993308  0.15904918 -0.10161888  0.28893194 -0.05824561 -0.02680568\n","  0.22973792 -0.16916394 -0.01068468  0.13347629 -0.08033894 -0.06353855\n"," -0.28960237  0.15965213 -0.07010751  0.14816183 -0.04570844 -0.14622775\n","  0.144435    0.04319917  0.17175394  0.09619357  0.24437335 -0.11682203\n"," -0.23354733 -0.1397255   0.02940062  0.31514388  0.1237506   0.10364321\n","  0.100564   -0.2286349   0.11418932 -0.16892216  0.1866698   0.04325792\n","  0.01851702  0.0287002   0.02989367  0.2693064  -0.20847248  0.11913712\n"," -0.10443807  0.05659525 -0.03152193  0.2899346   0.11151797 -0.30594653\n","  0.12394543 -0.14133446  0.16208002  0.01285067  0.2908328   0.17077228]\n","Nationality_Saudiarabia: [ 0.1940944   0.22643508  0.07596582  0.06637145  0.08306357  0.1369452\n"," -0.39719367 -0.1428364   0.37393934  0.1458955   0.09481304  0.16716196\n"," -0.13220052 -0.03494383  0.03725408 -0.02528602 -0.02188117 -0.1172137\n"," -0.40168375  0.00994087 -0.15393284 -0.0415144   0.08880023 -0.08479962\n"," -0.02261309 -0.28919137  0.04867355 -0.22103786  0.21107218 -0.1400019\n"," -0.28939384 -0.04774838 -0.16412324 -0.13439202 -0.05119396  0.1263474\n","  0.08408647  0.25076726  0.0591869   0.08154386 -0.11963963 -0.31526467\n"," -0.06469466  0.0264372   0.07148924  0.09489689 -0.04759458 -0.3473556\n","  0.05305756  0.00522759  0.20805722 -0.12504405 -0.18599275  0.09455365\n"," -0.19302641 -0.0968027   0.36653408  0.20765403  0.12666728 -0.3769533\n","  0.02486347  0.09809417  0.06308322  0.14817375 -0.10939691  0.4166126\n","  0.18952079 -0.04462762  0.3247994  -0.08270593 -0.03153934 -0.15348557\n"," -0.10699772 -0.00789054  0.08196864  0.10719049  0.1230331  -0.0772937\n","  0.01706033 -0.17280407  0.1821434  -0.20584597 -0.13145073  0.07011691\n"," -0.01981871  0.04137509  0.1781989  -0.19644207  0.13634847  0.16339806\n","  0.24525933  0.15543315 -0.02883969  0.11422177 -0.13125382  0.08328062\n","  0.11019707 -0.16276611 -0.05408527  0.25356    -0.25021088  0.11391029\n","  0.13148159  0.01330614  0.07176946 -0.12559502 -0.16719632  0.08874531\n"," -0.30115327  0.33888492 -0.07466707 -0.32933345 -0.2597518  -0.08463785\n"," -0.23646659  0.08700969 -0.00192369 -0.11874951 -0.20681743  0.0670634 ]\n","Nationality_Syria: [ 0.0356832  -0.22401318  0.22016038  0.07874355 -0.14500171  0.17134926\n"," -0.02786439  0.11321796 -0.04131231 -0.14221604 -0.10058942 -0.06382697\n"," -0.01691485 -0.23281428  0.03191181 -0.04885853 -0.08012256 -0.11073235\n"," -0.05509477  0.15087272  0.19588237 -0.03774306 -0.15932284  0.10297729\n"," -0.118357   -0.12475868  0.05343252  0.1046387   0.01071464 -0.10222631\n"," -0.12672405 -0.1157388   0.15198907 -0.17072275  0.1658004  -0.12878135\n","  0.00676751  0.08559785 -0.1978993  -0.04970498 -0.07520832 -0.10625004\n"," -0.06083375 -0.10787722  0.00472216  0.19434305 -0.21377566  0.09104879\n"," -0.16978894  0.03838885 -0.12253562 -0.10749193  0.09023648  0.00093778\n"," -0.24200433  0.17628866  0.10315369 -0.1857191   0.1613766  -0.07474081\n"," -0.12704645 -0.10870345  0.02937093 -0.06288096  0.11504568  0.23376627\n","  0.13750933  0.03445379 -0.08874995  0.04751147 -0.10094934 -0.04426001\n","  0.12534526 -0.1348411  -0.16793205  0.11986607  0.01402301 -0.12203346\n"," -0.24543169  0.02906666 -0.01470742  0.12320707 -0.1794912  -0.02498108\n"," -0.05766854  0.00980135 -0.15299077  0.05094778  0.16767493  0.14649749\n"," -0.0020418  -0.00725909  0.14064433  0.02494196  0.25920805  0.01389523\n","  0.03184906 -0.00236918 -0.18542545 -0.06753945  0.03028965 -0.26320085\n","  0.11939409 -0.02476391  0.01496777 -0.07756364 -0.13583392 -0.08854122\n","  0.11714673 -0.08946916  0.08819568  0.08710067 -0.08466071 -0.0738782\n"," -0.04160526  0.12687495  0.00241611  0.18655218  0.1073932   0.00530781]\n","Nationality_Tunis: [-1.29709810e-01 -2.14180797e-01  2.39745080e-02 -2.89951921e-01\n","  1.51633173e-02 -1.81497484e-02 -1.48643091e-01 -2.97206193e-01\n"," -1.06333725e-01  3.27031012e-05  5.99880852e-02  1.65198594e-01\n"," -6.10452204e-04 -1.60752274e-02 -2.02217847e-01  2.90728033e-01\n","  3.32483768e-01  1.46680832e-01  6.23230338e-02  1.49565935e-01\n"," -6.42363206e-02 -6.72104657e-02 -2.60516722e-03  5.75421229e-02\n"," -6.18718788e-02 -8.49250257e-02 -5.38707823e-02 -1.26487970e-01\n"," -1.85309410e-01  2.48344690e-02  1.05974197e-01  3.84115934e-01\n","  2.04715654e-01 -1.67922601e-01  2.61255324e-01  1.41469970e-01\n"," -8.78032818e-02 -2.76562601e-01 -1.72160462e-01  2.08729580e-01\n","  1.30220324e-01 -1.41192928e-01  1.53001711e-01  1.18972547e-01\n","  1.89042017e-02  6.77057430e-02 -6.24644123e-02 -4.47637327e-02\n"," -2.41674230e-01 -2.49264091e-01 -2.77007483e-02  2.08123952e-01\n","  3.91401947e-01 -1.58305898e-01  4.95376578e-03 -1.17851451e-01\n","  1.18688494e-02  1.22586966e-01  1.44512013e-01  1.95980668e-02\n"," -1.07778907e-01  1.06596217e-01 -1.72319666e-01 -2.64095813e-01\n","  8.28025416e-02  2.48848811e-01 -2.27999553e-01  9.90167558e-02\n","  1.57329977e-01 -1.06250249e-01 -1.20468855e-01 -1.26933932e-01\n","  2.08029747e-01 -5.71998321e-02  4.80861366e-02 -7.24386945e-02\n","  1.46106910e-02  1.27711236e-01  3.28059383e-02  1.51492516e-02\n","  3.28310542e-02  1.75611749e-01 -1.81984141e-01 -1.83853358e-02\n","  1.60018653e-01  9.04427171e-02 -5.74691296e-02 -4.63541970e-02\n"," -5.95091209e-02 -6.21689260e-02  1.28303587e-01  8.15915465e-02\n","  8.12440291e-02  2.00111941e-01  1.56891108e-01  7.85270333e-02\n","  9.46154892e-02 -1.96208507e-01  1.80371583e-01  1.38407201e-01\n"," -3.79028693e-02 -1.48037896e-01 -2.47647047e-01 -1.74526215e-01\n"," -1.83553100e-02  1.44946292e-01 -4.68488261e-02  2.77616203e-01\n"," -8.00749362e-02  1.07297182e-01  1.56147145e-02  8.96148607e-02\n"," -1.73825160e-01 -1.80103347e-01  3.45383026e-03  5.20925634e-02\n","  1.89134061e-01 -1.15425281e-01  9.27071460e-03 -1.29588887e-01]\n","Nationality_Usa: [ 1.04908407e-01  1.13741040e-01  2.66451091e-02  6.92641363e-02\n"," -1.12133078e-01 -1.23450294e-01  1.71646789e-01  5.11178561e-02\n","  3.01937491e-01  5.94949573e-02  2.86677387e-02 -7.77006224e-02\n","  1.02076977e-01 -2.72199549e-02  3.10691446e-01 -2.63135880e-01\n","  2.17602197e-02 -6.34892061e-02  5.35428040e-02 -2.31477767e-01\n"," -4.19978201e-02  1.04469687e-01  1.14537757e-02 -7.23249316e-02\n","  3.53954136e-02  1.12899542e-01  2.08305493e-01 -1.71756238e-01\n"," -1.78629011e-01 -6.70294166e-02 -2.68067539e-01 -1.39262155e-01\n","  1.23073570e-01  1.30571380e-01  2.66114268e-02  8.34341049e-02\n"," -8.31453279e-02  2.22772911e-01  1.80250984e-02  3.65770683e-02\n"," -1.49749294e-01 -4.40064352e-03 -1.19445212e-02  2.28897348e-01\n","  1.12058088e-01 -1.14218131e-01  8.64367038e-02 -1.14778429e-01\n","  2.50938147e-01 -3.15239746e-03  1.96100533e-01 -3.21200073e-01\n"," -1.71152130e-01 -5.51038980e-03  7.15374351e-02  5.01405746e-02\n","  1.36520892e-01  1.03130847e-01 -2.66212802e-02  3.68177220e-02\n","  1.33050501e-01 -5.47690541e-02  1.26432866e-01  3.87334377e-02\n"," -1.33712545e-01 -5.59914764e-03  2.01403618e-01 -1.01614803e-01\n","  6.91341013e-02 -9.49720144e-02  6.11499101e-02 -1.09595120e-01\n"," -1.68679908e-01  1.88184977e-01  1.08194649e-01 -1.37079775e-01\n","  2.55001158e-01  1.26128495e-02  1.64761066e-01  7.69936293e-02\n","  2.92341650e-01  3.23938206e-02 -2.68036164e-02 -8.98370519e-02\n"," -8.87426063e-02 -1.57597676e-01  1.13616407e-01 -9.80630517e-02\n"," -1.59117907e-01 -1.03195079e-01  3.09967011e-01  1.51168942e-01\n"," -1.04410201e-02 -2.17693523e-01  5.22196591e-02 -4.17645872e-02\n","  2.36446158e-05  7.54367337e-02  1.98323280e-02  1.14239752e-01\n"," -1.18220806e-01 -4.84283343e-02  5.92126064e-02 -1.78057611e-01\n"," -7.43466988e-02 -7.92012587e-02 -3.19404155e-02 -5.45454100e-02\n"," -1.10783182e-01 -1.97908431e-02 -6.54813945e-02 -2.13589981e-01\n"," -5.00940084e-02  1.79659069e-01  2.04591215e-01  3.08946639e-01\n"," -3.17721426e-01 -1.99674204e-01 -2.72783101e-01 -1.34410277e-01]\n","Nationality_Venezuela: [-0.07734303  0.12186012  0.13214695  0.02123448 -0.0469162  -0.0026201\n"," -0.00167805  0.07328469  0.04434785  0.15162143  0.18166605 -0.01017679\n"," -0.07327045 -0.07568723  0.17796224  0.10638416  0.10147998 -0.12990575\n","  0.00762899 -0.14137822 -0.06720354 -0.14252709 -0.03984191 -0.07939416\n"," -0.06449459 -0.15836544  0.13148531 -0.12162947  0.11942136 -0.12878142\n"," -0.0093594  -0.16829926 -0.04285228 -0.06488536 -0.15652882  0.00657986\n"," -0.00821115  0.06198885  0.13753927  0.15239853 -0.04171479  0.03959583\n"," -0.10869098  0.16800928 -0.06257252 -0.07897171  0.03100838  0.04606961\n"," -0.0842245   0.11765087 -0.00394753  0.15580237  0.01671995 -0.03876573\n","  0.04085501 -0.05793846 -0.1207131  -0.1656026   0.02313845  0.15820646\n"," -0.14492524  0.13279673 -0.09608391 -0.0953134  -0.16895394  0.0470999\n","  0.12680617 -0.11625668  0.16982174  0.1451107  -0.09293449  0.163719\n","  0.06151012  0.16804966 -0.08204069  0.040925   -0.14092544  0.04505678\n"," -0.10203681  0.00692756 -0.11354821  0.10769874  0.16228715  0.17296743\n"," -0.07523818  0.16895506 -0.07990428 -0.11782286  0.11054876 -0.07836597\n"," -0.02545619  0.10986298  0.10852051  0.12324232  0.05594827 -0.03386901\n","  0.1312215  -0.01772517 -0.05294782  0.02446187  0.00274399 -0.0863078\n","  0.08998188  0.13056615  0.11575112  0.08883703  0.07470018  0.08015421\n","  0.07025135 -0.02829011 -0.0602015  -0.12881681 -0.0893655   0.16006947\n"," -0.1799889  -0.1408368  -0.13426287 -0.12679563  0.14864945 -0.02973823]\n","Placeofbirth_Egypt: [ 0.04042433  0.29424837  0.3503328   0.1774629  -0.13142207 -0.14246374\n","  0.18785717  0.31255367  0.02582368 -0.05449688  0.11186901  0.07023732\n"," -0.08661129  0.2995025   0.32913786  0.08678742  0.0315311   0.07513705\n"," -0.1714296  -0.03052509 -0.1759633   0.13765961  0.17480955  0.20824482\n","  0.12432617  0.11050853  0.07773127  0.14119858  0.23388304  0.02803873\n","  0.15980421  0.20976241 -0.09135343 -0.00671728 -0.30227235 -0.01270466\n","  0.03749098  0.1280824   0.12828818 -0.14157331  0.11173001  0.20124838\n"," -0.09789282 -0.24920096 -0.0022572  -0.0233818   0.15945409  0.20399284\n","  0.05982094  0.2078109   0.09252872 -0.04400566 -0.13636391  0.14633404\n","  0.14508006  0.2156101  -0.07540106  0.03947369 -0.01628746  0.20244534\n","  0.08258492  0.13764618  0.02017335  0.09231308  0.2012613  -0.03025832\n"," -0.14326751  0.02251968 -0.05839501  0.10481484  0.01387368 -0.16695665\n"," -0.30326903  0.26535895  0.09655571 -0.10372809  0.2586471  -0.10742829\n","  0.12933253  0.33766124  0.06695679  0.09886033  0.17844886 -0.08532609\n"," -0.0213364  -0.1472637   0.00599138 -0.20891614 -0.15018272 -0.17893302\n","  0.08725321  0.18131441 -0.12689792 -0.04240495 -0.10254214  0.15396214\n","  0.20858493  0.30460122 -0.08620429 -0.0274909  -0.097295   -0.201112\n"," -0.09499825  0.11009753  0.08363437  0.07846197  0.00390009  0.00952459\n","  0.00433859  0.00164688 -0.01060154  0.0157858   0.19103928  0.0702147\n","  0.16573164  0.15233965 -0.24199669  0.1284841   0.1898715  -0.20205855]\n","Placeofbirth_Iran: [ 0.0622785  -0.1364553   0.10179278 -0.30706388  0.14009112  0.2529545\n"," -0.26841682 -0.18807532 -0.14737569  0.02226871 -0.06450935  0.12708828\n"," -0.25529322 -0.37458727 -0.21381184  0.15443689  0.1118556   0.1463595\n","  0.12774396  0.22404689  0.16451347  0.0083891   0.08215472 -0.02759415\n","  0.15956801 -0.16047886 -0.17545943  0.03496136 -0.1628677  -0.0143398\n","  0.0249731   0.16930452  0.09068342 -0.15830344  0.17948762 -0.06730409\n","  0.08479562 -0.3137696  -0.02781121  0.08058073 -0.03265399 -0.0337467\n","  0.00656169 -0.16385098  0.12968828  0.25179803  0.08551296 -0.12389582\n"," -0.08981935 -0.05690997 -0.23250347  0.09208945  0.09992158  0.11627144\n"," -0.26475987  0.04933351 -0.00171072  0.25544065  0.25838935 -0.06539582\n"," -0.06911364  0.19565114  0.05893993  0.01181701 -0.05455378  0.40082076\n","  0.09566884  0.157024    0.08066279  0.030049   -0.07449658 -0.04315777\n","  0.1640066  -0.30532035  0.11003071  0.01776369 -0.16197607  0.03617658\n"," -0.01023471 -0.12120848 -0.20586713  0.15466648 -0.10134329  0.02126969\n"," -0.04311752  0.06253716  0.07507679  0.2700208   0.11814425 -0.15248236\n","  0.01684033 -0.17374104 -0.20718358  0.25552094 -0.01640672 -0.02140442\n"," -0.07776042 -0.04528614  0.13568634 -0.04973537  0.01435921 -0.12074744\n"," -0.2241826   0.19664337 -0.28396228  0.22229807  0.08591938  0.22894359\n"," -0.14505371 -0.21176429  0.20742078  0.08659196  0.14465025 -0.08359321\n","  0.02452718 -0.27183384  0.01513618  0.29290465 -0.00276446 -0.06644154]\n","Placeofbirth_Iraq: [ 0.2035876  -0.2794437  -0.16318916  0.03613131  0.05363928 -0.01133515\n"," -0.27795476 -0.17376971  0.14223437 -0.08227105  0.02199296 -0.22402248\n","  0.0535042   0.13860191  0.13955802 -0.09458391 -0.11526781 -0.06029822\n"," -0.12242334  0.09768104 -0.09651314  0.15311432 -0.19143035  0.18955961\n"," -0.16461718 -0.16048522  0.03820288  0.13206634  0.22674583  0.15118492\n","  0.14841975 -0.04922364  0.20866147 -0.11436895  0.06656174 -0.17467736\n","  0.09646735 -0.05592884 -0.02132159 -0.00367553  0.14274392 -0.0514528\n","  0.28638375 -0.11928918  0.07303552 -0.16652787  0.02209679 -0.09296183\n"," -0.04030625 -0.14983176  0.04516612  0.08970322 -0.03938764 -0.1336256\n"," -0.18965633  0.09903374 -0.05893041  0.03725268  0.14186288  0.09530912\n","  0.15030515  0.2628579  -0.06131125 -0.16321583 -0.12334988  0.07400221\n","  0.13641995  0.1722556   0.03060857 -0.2324935  -0.21972659  0.09614027\n","  0.10390814 -0.12903918  0.15783912 -0.08519768  0.07550733 -0.3573717\n"," -0.1941905   0.26319465  0.23442598  0.08593567  0.0518211  -0.16180237\n"," -0.29500252 -0.14722127  0.02124876 -0.14059114  0.11819922 -0.09578081\n"," -0.02387679  0.16230375 -0.14352328 -0.16791524 -0.01415449  0.12274456\n"," -0.07327276 -0.04202528  0.14321244  0.09326896 -0.07056136  0.21991323\n","  0.07157879 -0.00849505 -0.16692647 -0.01403731 -0.21358769  0.12285908\n","  0.02820433 -0.13242495 -0.1439912   0.0313078  -0.23351565 -0.00477227\n","  0.01750922 -0.15634638  0.06143315  0.05313867 -0.16668607  0.26544434]\n","Placeofbirth_Jordan: [-0.06772702  0.09253059  0.2599209   0.07230756 -0.00553074  0.14777856\n"," -0.11380667  0.13869774 -0.18866824 -0.169447   -0.01888657  0.07939559\n","  0.1774973  -0.0069956  -0.03057478  0.19202828 -0.01848846 -0.09668757\n","  0.2864495  -0.04160421  0.0907184   0.05275592  0.24512324  0.10395197\n","  0.01026163  0.27914107 -0.09046897 -0.04151636 -0.3403738   0.02523895\n","  0.00668369  0.01456945  0.05223924  0.01538867  0.19933674 -0.06720328\n"," -0.13785818 -0.15182057 -0.00682834  0.1008835  -0.22463499 -0.30247656\n"," -0.01753397 -0.12905492 -0.09333652 -0.07590438 -0.18122153  0.3834274\n"," -0.00792523  0.04131619 -0.07463164  0.0086967   0.2547063   0.33689514\n","  0.16274497  0.01397892 -0.03167523  0.01108308 -0.17386031 -0.20178121\n","  0.0504479   0.00846012 -0.02055711  0.07731011 -0.07163116  0.11259003\n","  0.01665536  0.18015313 -0.14556035  0.08425946 -0.1316968   0.00897183\n"," -0.11078665 -0.02026277  0.14866617 -0.34201068 -0.05485293  0.2883668\n","  0.13246089 -0.25561318 -0.08696116  0.19722503  0.05591258  0.03650506\n","  0.33181825  0.4499711  -0.0641266  -0.07208586 -0.15785193  0.02638162\n"," -0.12924434 -0.15822089  0.09709245 -0.13152586  0.08903703 -0.20092085\n"," -0.22116584 -0.15685059  0.25664327  0.11973317  0.03923684  0.0012033\n"," -0.2351846   0.13516127  0.02028076  0.05522392  0.02417808 -0.03775091\n","  0.3030745  -0.18573797 -0.02302286  0.0571706   0.15122747 -0.17601426\n","  0.23485881 -0.11937818  0.09734701 -0.02290304  0.23796655 -0.20690443]\n","Placeofbirth_Kuwait: [-0.14117692 -0.00551269  0.13648462  0.00706775  0.15018313 -0.35306713\n","  0.01879335  0.09066597  0.0813546   0.15031995 -0.14857002 -0.12672271\n","  0.06040537  0.06327623 -0.02841304 -0.18172877  0.12397543 -0.13876669\n"," -0.20398614 -0.0573252   0.07075114  0.32961297  0.16446488  0.08246645\n","  0.09028847  0.00306545  0.12160905  0.04843162 -0.00484552  0.03990393\n","  0.15340902  0.11123285  0.03924554  0.05191861  0.1633325  -0.1459207\n"," -0.14503801  0.13948473  0.02500838 -0.11261299 -0.13375683 -0.01229267\n","  0.09569687 -0.13624564 -0.20198332  0.14942583  0.03210689 -0.06125884\n"," -0.07635947  0.17475653 -0.06293016 -0.06567407 -0.08010998  0.05963461\n"," -0.04767736  0.13750413  0.05307851 -0.02857699  0.11114506  0.1181994\n","  0.01635929 -0.06400006  0.05638127 -0.1667299  -0.17930792 -0.19708268\n","  0.14187382  0.12938458 -0.04768624 -0.22629893 -0.00105605 -0.043385\n"," -0.11757264 -0.16360274  0.13654658 -0.05371518 -0.1304651   0.01512487\n"," -0.06308368  0.03003981 -0.06000663 -0.02733138  0.12638465 -0.15629703\n","  0.15675868  0.01757672 -0.01705023 -0.04909804  0.21577822  0.13984582\n"," -0.1354892   0.10253745 -0.00891678 -0.16739243 -0.19455375 -0.12157074\n","  0.03890711 -0.03211612  0.07910003 -0.22835912 -0.13615331  0.11673232\n"," -0.1953982  -0.11156518 -0.08550391 -0.12647662  0.07195468  0.02896571\n"," -0.17701375  0.18340334  0.0857783  -0.02328778  0.092318   -0.10986435\n","  0.05365643 -0.04777294  0.06959876  0.04339495  0.1636065   0.2546091 ]\n","Placeofbirth_Lebanon: [-0.1127774  -0.19154014 -0.18953954 -0.03121842  0.07647716 -0.41497403\n","  0.1523385  -0.12223763 -0.17228478 -0.06187642 -0.0266617  -0.3159113\n","  0.06343324 -0.02494493 -0.10367634  0.03458507  0.10863159 -0.09290759\n","  0.03404329 -0.08736054  0.10917383 -0.15415642  0.11912072 -0.1852456\n","  0.05472951  0.011567    0.20687592  0.0613237   0.2607709   0.1624236\n"," -0.08270276  0.30630642  0.13145222  0.25238323  0.1119888  -0.1206374\n","  0.01117501  0.1204856  -0.16103402  0.03993881  0.07851845 -0.05368993\n"," -0.02818606 -0.14834264 -0.05904084  0.13316402  0.18653588 -0.07133432\n"," -0.10829288  0.00315617 -0.07292496 -0.05570206 -0.12448586  0.17746751\n"," -0.18021782 -0.08758768  0.18150674 -0.10641386 -0.00499116 -0.3623057\n","  0.00749744 -0.11443507  0.05730228  0.02944179 -0.03474425 -0.00121662\n","  0.0991763   0.17021     0.12379494  0.05394869 -0.04305181 -0.12432666\n"," -0.10803562  0.08315235  0.01206182 -0.09577572  0.08406808 -0.02040606\n","  0.17812638  0.09493024  0.1295937   0.1942272  -0.10466667  0.14109424\n"," -0.03802591 -0.1650881   0.11140114  0.10406025 -0.00057193  0.16170505\n","  0.02432192 -0.1704913  -0.2536907   0.10647148  0.01322679  0.1465523\n","  0.09899305 -0.06873453  0.01991226  0.23706989  0.08139876  0.11038974\n"," -0.23200765  0.19032998 -0.10252766 -0.06416767 -0.35107857 -0.21167818\n","  0.03355889 -0.39880493  0.12885544  0.154318    0.16392326  0.01284824\n","  0.00500381 -0.04120313  0.02993439 -0.01109789  0.13592958  0.01122081]\n","Placeofbirth_Lybia: [-9.18680131e-02  1.91212595e-01  2.15524390e-01  5.64579517e-02\n","  7.39377737e-02  1.16715275e-01 -8.59902278e-02 -7.45754549e-03\n"," -1.84291765e-01  1.63837671e-02 -5.39543256e-02 -1.79097146e-01\n"," -1.26930371e-01  1.17678940e-01  2.41702702e-03 -5.44257239e-02\n","  7.15861768e-02 -1.65871158e-01 -7.43090436e-02 -1.96731627e-01\n","  1.63279831e-01 -5.40039837e-02  4.21817861e-02 -7.41275027e-02\n"," -1.61324725e-01 -1.84827030e-01  2.50798501e-02 -4.62365784e-02\n"," -7.05573335e-02  2.51141544e-02 -1.38803378e-01  3.99176776e-03\n","  3.32082491e-05  2.86436558e-01 -1.39064595e-01  1.28472596e-02\n"," -8.09706450e-02  2.29327530e-01  5.26645454e-03  8.09701439e-03\n"," -1.00760281e-01 -3.24139744e-03 -1.08041100e-01 -4.19906229e-02\n"," -7.72489533e-02  6.01844452e-02  1.22783855e-01  2.14506865e-01\n","  8.12943503e-02  1.57681361e-01  1.32127255e-01  1.79240018e-01\n","  1.68325827e-02  3.00062686e-01 -1.68172374e-01  1.30352885e-01\n","  1.61104828e-01 -1.74019814e-01 -5.58313914e-02 -1.26817942e-01\n"," -4.77333814e-02  6.80525303e-02  1.13282479e-01 -3.60317193e-02\n","  1.13416813e-01 -1.26468718e-01 -7.75672793e-02 -5.53282797e-02\n"," -2.04627305e-01  1.31461337e-01 -7.66812116e-02  6.68112636e-02\n"," -8.54404718e-02  2.24669829e-01 -7.43123218e-02  1.31819963e-01\n"," -1.58011317e-02 -7.54505619e-02  1.71958268e-01 -2.48450935e-02\n","  6.16108216e-02  7.84244090e-02  1.76882952e-01  5.56668490e-02\n","  1.74597397e-01 -7.94174075e-02 -8.04992020e-03  8.14810768e-02\n"," -1.91907555e-01 -1.28611803e-01  1.70717612e-01  1.28481776e-01\n","  5.94785661e-02 -8.41717869e-02  1.71195511e-02 -1.91054925e-01\n","  4.44425792e-02  7.36174509e-02 -1.78729147e-02 -1.23384278e-02\n"," -1.70448720e-02  1.41393885e-01 -1.11258745e-01 -1.53585911e-01\n","  1.93410173e-01  4.09864411e-02  6.30334318e-02  1.13649100e-01\n","  1.32901445e-01  1.72108084e-01 -1.88953981e-01 -2.12222859e-02\n","  1.61472827e-01  1.12283543e-01  1.30016282e-01  1.43488720e-01\n"," -5.13257496e-02 -1.79625854e-01 -3.89704034e-02  1.26263648e-01]\n","Placeofbirth_Morocco: [-0.04777489  0.04014748  0.2604528  -0.1922283   0.12702692  0.2792107\n","  0.21398328 -0.08150055 -0.2781836  -0.28822643 -0.01851125 -0.14159034\n","  0.09580574 -0.14868104 -0.22815755  0.04412022 -0.07164827 -0.0909971\n","  0.25940582  0.08578985 -0.04819731 -0.17824025  0.12101819  0.36266497\n","  0.0541392   0.20047803 -0.17733118  0.04963516 -0.18321502  0.24215026\n","  0.1688773  -0.07776685  0.11027682  0.06158294  0.1287223  -0.02250458\n"," -0.16241282 -0.09639511 -0.14680965  0.11829722  0.17820713  0.17930743\n"," -0.3269871   0.00927495  0.0665951  -0.00775739 -0.25346562  0.25513947\n"," -0.2644124  -0.01960552  0.12383201  0.00134705  0.13049518  0.02837672\n","  0.01929221  0.09032006  0.1423859  -0.11762657 -0.2739385  -0.08549263\n","  0.1618819   0.01556938  0.00951496  0.00607718  0.26029032  0.10327691\n","  0.02652651  0.11330158 -0.3823569   0.05213005 -0.03324199  0.00492261\n"," -0.13351825  0.14213422  0.0183832  -0.09886977  0.21020028 -0.01780044\n"," -0.0394753  -0.35264558 -0.00754741  0.04482517 -0.0448004   0.05975123\n","  0.16462123  0.17030764  0.10418737 -0.05413893 -0.12359677 -0.0921303\n"," -0.0021687  -0.02057762  0.03776142 -0.15498605 -0.0145678   0.03185123\n"," -0.00980122 -0.02504475 -0.04933006 -0.11321238  0.08594187  0.02398486\n"," -0.20213749  0.14983891  0.11972976 -0.28320712 -0.07736453 -0.11908247\n","  0.15179315  0.09230594 -0.11866993  0.00693318 -0.13298884 -0.02613229\n"," -0.00380501 -0.15631823  0.00790284  0.1696668   0.21110207  0.01013078]\n","Placeofbirth_Palestine: [ 0.0958174   0.18023334  0.09799567 -0.13159198 -0.11945589 -0.00080626\n"," -0.1750985  -0.03260843 -0.03414705  0.08834131 -0.05946395  0.01293653\n"," -0.1768874   0.00591214  0.07216448  0.19303328  0.17504479 -0.12453064\n","  0.00908691  0.19891858  0.03505523  0.13077828 -0.02485546 -0.00778601\n","  0.05918998 -0.15336727 -0.24957621 -0.05445062  0.2157001  -0.09242077\n","  0.19873318  0.04898923 -0.14782952  0.01907592  0.19679944 -0.17036793\n","  0.14657667  0.09616695  0.10003076  0.11458659  0.03865387  0.28455994\n"," -0.03479768 -0.13882436 -0.00833505 -0.10591416  0.08066917 -0.16009082\n"," -0.24872974 -0.15129985 -0.12587881  0.22156668  0.04748027 -0.16012397\n"," -0.07133131  0.11920521 -0.06633423 -0.10177577 -0.24858111  0.20106536\n","  0.16082212  0.09352936 -0.12858607 -0.15658201  0.07717496  0.0024892\n","  0.04564542 -0.06522062 -0.11263146 -0.0316156  -0.12513517 -0.09323245\n","  0.25700834 -0.09206878  0.17389235 -0.0955919  -0.16134267 -0.10777564\n"," -0.19837375 -0.06584651  0.0561938  -0.04946697 -0.11343501 -0.01688932\n"," -0.14723557 -0.13671334 -0.04804875  0.12470274 -0.16991949  0.15351847\n"," -0.10379448 -0.10100313 -0.12635538  0.19984391 -0.25656042 -0.00102101\n"," -0.13356632 -0.09475362 -0.04893079  0.0934453   0.19669929  0.01076835\n"," -0.03458178  0.09424338  0.0615442   0.08878871 -0.03029288 -0.07898601\n","  0.0265636   0.13754946 -0.03294611  0.09429773  0.08971113  0.0610073\n"," -0.07489113 -0.01404307  0.03677056 -0.03797605  0.22476383 -0.02957745]\n","Placeofbirth_Saudiarabia: [ 0.23155944  0.11949306  0.38023597  0.0606589  -0.11791039  0.0929653\n"," -0.19448632  0.04159974  0.12356725  0.25505278 -0.15262143 -0.14677088\n","  0.0950821   0.19718294 -0.13925977 -0.0948757  -0.27089468  0.02329832\n","  0.05210201 -0.07265604  0.0308839  -0.07115243 -0.15108806  0.0226093\n","  0.02626188 -0.27749303 -0.02286876 -0.17861876  0.1148792  -0.04924646\n"," -0.05663791 -0.04575277 -0.30832347  0.04992902  0.0489469   0.11877395\n"," -0.12131136 -0.03936525  0.21685946 -0.05829698  0.04959233 -0.21050821\n"," -0.01706202  0.2540416   0.3015499  -0.32389414 -0.15069985 -0.24822743\n","  0.02390201 -0.24389881  0.22786817 -0.13934782  0.01803564  0.206298\n"," -0.00667833 -0.14628802 -0.01269262 -0.00791396  0.31616437 -0.05580529\n"," -0.17268929 -0.16842522  0.28684396  0.12948179 -0.01842691 -0.02611889\n","  0.18253134 -0.08188294  0.38563567 -0.32637194  0.16923353  0.12309706\n","  0.0233521   0.16465347 -0.0917858  -0.12985417 -0.07884854 -0.18802264\n"," -0.10978654 -0.11459891  0.27267024 -0.2528767  -0.18675195 -0.14256355\n"," -0.2958126   0.01165635 -0.04163975 -0.24667247  0.10210112  0.23869173\n","  0.39636663 -0.10420826  0.08983923 -0.1848001   0.02483909  0.04727332\n"," -0.09420101 -0.14311153 -0.20549007  0.2576102  -0.24249102  0.30196917\n","  0.3466206   0.07511124 -0.24064036  0.19435066 -0.09833828  0.3108428\n"," -0.24693763 -0.06788852  0.0218514  -0.35184675  0.05201615  0.00741112\n"," -0.29529628  0.3251799  -0.23053767 -0.14657405 -0.01318048  0.15729551]\n","Placeofbirth_Syria: [ 2.16339216e-01 -3.39021161e-02  3.50967944e-02 -4.16407734e-02\n","  1.02542132e-01 -1.63425520e-01  8.25814456e-02 -2.43228406e-01\n"," -6.98437542e-02  2.19073016e-02 -3.03284787e-02  6.95468113e-02\n"," -9.76495631e-03  1.48632545e-02  8.88980180e-02  8.84986371e-02\n","  1.41812220e-01  4.78361994e-02  1.28109455e-01  3.82598699e-03\n"," -1.08895097e-02 -1.13301098e-01 -1.85808226e-01 -6.39545768e-02\n"," -9.84567627e-02  8.25610757e-02  1.03518934e-04 -2.65367329e-02\n"," -1.73466187e-02 -1.16669878e-01  6.47254586e-02  1.68611884e-01\n","  6.10171817e-03  9.87489223e-02  1.91779602e-02  9.69148278e-02\n","  1.97692215e-03 -1.29236495e-02  2.17340281e-03 -4.40845415e-02\n"," -6.34509027e-02 -8.23556632e-02 -8.12679976e-02 -9.16806534e-02\n","  3.54504138e-02 -3.38552818e-02  1.14784375e-01 -1.21246770e-01\n"," -5.59166260e-02 -3.46269161e-02  3.23129036e-02  9.30905044e-02\n","  2.21375316e-01  2.70798802e-02 -3.96288708e-02  7.54069984e-02\n","  8.84519517e-03 -1.97846461e-02  2.86828548e-01 -2.13930339e-01\n","  1.22803748e-01  1.67947933e-02 -1.70649871e-01  5.22488914e-02\n","  4.69966121e-02  9.29844156e-02  7.59867504e-02 -1.59725547e-03\n","  1.88713208e-01 -2.61652231e-01  1.29398718e-01 -5.14080077e-02\n","  7.16044456e-02  6.20483421e-02  3.23995948e-03  7.93301463e-02\n","  5.18272854e-02 -1.46984816e-01  4.00847793e-02  1.25851005e-01\n","  1.53399840e-01 -1.61842983e-02 -1.93558872e-01 -1.32359743e-01\n"," -3.38281840e-02  1.66495144e-01  6.81949556e-02  4.42622900e-02\n"," -1.46644548e-01 -6.80979788e-02 -3.02068852e-02  1.14004970e-01\n","  1.03899688e-01  1.40753701e-01  5.32976538e-02  2.97011137e-02\n"," -1.61455542e-01 -2.18142748e-01  1.09657764e-01  1.68488055e-01\n","  1.47804633e-01 -1.79033782e-02 -3.45981568e-02  5.58082759e-02\n"," -2.96844095e-01  2.45055985e-02  5.65732569e-02  7.70960525e-02\n"," -9.07793269e-02 -2.62382418e-01  2.02458389e-02 -1.42863587e-01\n"," -8.80493522e-02  8.59306604e-02  1.53311163e-01 -1.57655820e-01\n"," -2.34183948e-02 -6.45481870e-02  2.89294869e-02 -3.70192528e-02]\n","Placeofbirth_Tunis: [ 0.09251639 -0.25074664  0.1652914   0.14612079 -0.07046404 -0.09790164\n","  0.03785724  0.00583373  0.21663965 -0.12673056 -0.04247357  0.17070064\n","  0.09622183  0.01747168  0.0553401   0.19971313 -0.00228342  0.13052851\n","  0.0579345   0.10289187 -0.17182843 -0.16523734 -0.0590943  -0.11640742\n","  0.1190168  -0.00957864  0.2218373  -0.34801963  0.2449382  -0.15876918\n"," -0.14755629  0.35357738  0.2567964  -0.13084692 -0.04806184  0.07479629\n","  0.04865588  0.12081601 -0.04730276 -0.11655755  0.13320333 -0.20381105\n","  0.14101855  0.18967745 -0.15838829  0.020674   -0.16923532 -0.05853966\n","  0.09521443  0.01218836 -0.00419186 -0.14514399  0.34342724 -0.03674398\n","  0.14615737 -0.02575733 -0.13412759  0.10609937  0.22952347  0.0321352\n"," -0.1819797   0.20016195 -0.16526681  0.04297352 -0.2310573   0.15486819\n","  0.00443015  0.08484018  0.14448579 -0.1910481   0.03622842 -0.11062463\n","  0.08255649  0.00520689 -0.0102147  -0.04555905 -0.07618479  0.01368607\n"," -0.19407767 -0.05493356  0.2583886  -0.02014542 -0.09406211  0.08474323\n"," -0.2812135   0.03632575 -0.00752774  0.06177653 -0.11513571  0.08597472\n","  0.3542207   0.03553893  0.01274394  0.22059236  0.2181053  -0.11681589\n","  0.1317952  -0.16521238  0.01384738 -0.05195165 -0.11227091 -0.02694197\n","  0.23072055  0.03576867 -0.04320694  0.09261534  0.04988208  0.07162535\n"," -0.33228028  0.1216161   0.07904136 -0.14793424 -0.3843655  -0.16624679\n"," -0.08814766  0.19220191  0.18715686 -0.18097903  0.00412817  0.00870807]\n","Placeofbirth_Usa: [-3.70456614e-02 -6.01097830e-02 -2.37821490e-02 -1.33245468e-01\n","  1.32484913e-01 -1.11190066e-01 -3.97711657e-02 -8.30945522e-02\n"," -1.50212020e-01  9.86911133e-02 -4.73126844e-02  4.82395291e-04\n","  7.31558353e-03 -2.25376099e-01 -1.76594555e-01  3.61855961e-02\n","  1.72316208e-01 -1.49232000e-01  2.11215809e-01  1.07056282e-01\n","  1.00435227e-01 -4.55364585e-04  2.70829618e-01 -3.04429065e-02\n"," -1.73501685e-01 -1.92005828e-01 -2.33806640e-01 -4.90459427e-02\n"," -3.21708262e-01  1.96912915e-01  1.03868686e-01  1.12310223e-01\n"," -3.22472215e-01  2.48018466e-02 -6.87181354e-02  8.94652382e-02\n","  1.66054457e-01 -3.26764621e-02  1.34163365e-01 -1.15848053e-02\n","  8.27617943e-03  6.48579225e-02  2.65003797e-02  5.83480783e-02\n"," -2.26626843e-01  4.46449034e-02  1.39908761e-01  7.12945685e-02\n"," -1.79253072e-01  3.72704938e-02 -5.38301729e-02 -7.78464228e-02\n","  3.33994776e-02  1.08343102e-01  1.17102340e-01 -1.87590718e-02\n","  3.05876553e-01 -4.10702862e-02 -1.51933551e-01 -2.03899503e-01\n","  1.49306953e-02 -4.85678211e-05  6.71577007e-02 -9.03338939e-03\n","  1.70881674e-01  8.43769461e-02 -1.31416872e-01  8.58575702e-02\n","  1.12659833e-03  2.24430010e-01 -1.55609742e-01  1.28081918e-01\n"," -1.31639928e-01  1.58726037e-01  7.19761252e-02  1.41915679e-01\n"," -8.64296108e-02 -5.01342267e-02 -4.54890728e-02 -9.45246145e-02\n"," -1.82014555e-02  2.71720856e-01  9.90938693e-02  3.26668769e-02\n"," -8.56123120e-02  1.73278332e-01  1.14365697e-01 -9.73431990e-02\n"," -1.63333043e-02 -4.41309959e-02 -4.09332849e-02  6.71523809e-03\n"," -2.99082130e-01 -2.10725114e-01  1.92178205e-01 -5.18704951e-03\n","  1.12884030e-01 -6.55447915e-02  8.86347666e-02  2.33308733e-01\n","  5.39205931e-02  1.15035012e-01 -5.53092770e-02 -1.57989696e-01\n","  2.33371668e-02 -5.07596172e-02  1.22857600e-01 -1.57291457e-01\n","  1.75319929e-02  5.27022928e-02 -1.31833702e-01 -4.03342173e-02\n"," -8.25554952e-02 -1.44066140e-01 -5.70262671e-02 -8.87654796e-02\n","  8.32356289e-02  2.80876737e-02  4.98675071e-02 -1.72218040e-01]\n","Placeofbirth_Venzuela: [-0.13726172  0.08099091 -0.1704266  -0.16519968  0.17981508  0.15509501\n","  0.01272002 -0.04306157  0.13829419 -0.14913815 -0.1407638   0.06976187\n"," -0.18001132  0.16782323 -0.00343291  0.04383643  0.04019083 -0.0922977\n"," -0.16030383  0.16711754 -0.00524926 -0.14783497 -0.1025492   0.04798158\n"," -0.01116495  0.17840096 -0.00185038 -0.02196865 -0.1441169   0.1796771\n","  0.07478818  0.16204187 -0.05667377 -0.04591089 -0.11229144 -0.15243356\n","  0.13579425 -0.03113848  0.07270131 -0.1359888  -0.1705562   0.12348163\n","  0.03293893  0.10198706  0.10457096  0.15793702 -0.10040539 -0.16316675\n","  0.0934138  -0.04023431 -0.09171637  0.16374841 -0.04093827  0.10661659\n","  0.0771572   0.11968985 -0.04829808  0.06117603 -0.05014963  0.09624204\n","  0.00597632 -0.14931366  0.15301767  0.04446626  0.12303397 -0.11122902\n","  0.13598892 -0.15798822 -0.18009111  0.02312422 -0.03367436 -0.1410467\n"," -0.0227977  -0.11115028  0.01817966  0.05554758 -0.12668917 -0.01525798\n","  0.1820805   0.12848946 -0.02119569  0.1291028  -0.07496055  0.03481185\n"," -0.01943347  0.09612295  0.01905864 -0.10803825 -0.12258179 -0.16009067\n"," -0.1572996  -0.12480453 -0.08648897  0.05976969 -0.03647205 -0.01295246\n","  0.05600077  0.13651633  0.12174261  0.03728844 -0.06377702  0.15690339\n","  0.16597512  0.07890752  0.11334023 -0.0667854  -0.15719181  0.03566311\n","  0.12434965  0.08001232 -0.08710116 -0.13185641 -0.17409833  0.13516045\n"," -0.0685953  -0.10253745 -0.11988117  0.04165724 -0.17723918 -0.02364926]\n","Stageid_HighSchool: [ 0.00561523 -0.00981726 -0.2031605   0.32435456 -0.12282822  0.17272659\n"," -0.17349064 -0.05370718  0.2742488   0.03551962  0.03151169 -0.17142074\n"," -0.028433   -0.00945473 -0.10925029 -0.26730013 -0.00814909 -0.00291784\n"," -0.3421856  -0.19934225 -0.224611   -0.12402391 -0.202851   -0.01667753\n"," -0.04423207  0.04620324  0.3267068  -0.15602803  0.21812147 -0.03581288\n"," -0.14084929 -0.05814167 -0.18304183 -0.13294214  0.01490359 -0.19673343\n","  0.03980733 -0.0346695  -0.01113759  0.07733598  0.01114123 -0.0851095\n"," -0.0849325   0.03002292  0.06029339  0.15576942 -0.00224597 -0.35882035\n","  0.29975832  0.00898471 -0.10747174 -0.30643144 -0.08187562 -0.14625363\n"," -0.1559991   0.12827447 -0.06223153  0.09086396  0.12717822 -0.23131117\n"," -0.17605078  0.01695908 -0.04695652  0.14694902  0.00090204  0.01810542\n","  0.30058974  0.09833497 -0.15519977  0.10712838  0.06150289  0.07233405\n"," -0.03207141 -0.00992662 -0.04599273 -0.14904988 -0.15871203 -0.06996624\n","  0.1429988  -0.16472141  0.00307743 -0.0404573  -0.06401914  0.16332236\n","  0.14712337 -0.03189542 -0.10298371 -0.23565061 -0.05357424  0.16586891\n","  0.16759779 -0.04357605 -0.26505244 -0.01648101 -0.23886532  0.02292304\n"," -0.19550878  0.02582919 -0.10911205  0.11478228  0.00898414  0.21305569\n","  0.07042418  0.1122684  -0.16755168 -0.26029935  0.06766775 -0.0798259\n"," -0.27463558  0.17897207 -0.1441108  -0.09935522 -0.14180718  0.19259946\n","  0.05479129  0.23895942 -0.04849    -0.12560348 -0.2857546   0.2632998 ]\n","Stageid_MiddleSchool: [-0.01257903 -0.17372294  0.10545357 -0.04299621  0.13632178 -0.02515696\n","  0.10881155  0.05359431 -0.22616813 -0.1175369   0.08860172 -0.05415338\n","  0.01289187 -0.203416    0.09434114  0.09549061 -0.04839908  0.07476059\n","  0.02083265 -0.0267415   0.16518712 -0.16700295 -0.13664965  0.06967484\n","  0.03419882  0.10643762 -0.0034078  -0.05477364 -0.3153377  -0.12161262\n","  0.2613527   0.0230725  -0.01521292  0.43098423  0.20939805 -0.24587528\n"," -0.03001966  0.06967715 -0.02851242 -0.02874189  0.09176175  0.04730137\n","  0.05441849 -0.04139791  0.02744708  0.25865975 -0.17286333  0.30684844\n","  0.00445275 -0.09334186  0.04975747  0.09545645  0.02771403  0.42384943\n"," -0.16686346 -0.22542162  0.00325354  0.12399769  0.06310713  0.1307932\n"," -0.16217759  0.1298529   0.07188891 -0.19849418  0.19208178  0.00076669\n","  0.09636903  0.14495131  0.04304071 -0.05027775 -0.13513207 -0.13503346\n","  0.04473507 -0.03145693 -0.07367828  0.13501686  0.18189052  0.01104781\n"," -0.0908018   0.05273665 -0.00745412  0.17831697 -0.19112495  0.17338052\n"," -0.07384329 -0.10348989  0.03049259  0.15117939 -0.13095047  0.12735748\n"," -0.05196626  0.11932752 -0.02977807  0.14081882 -0.02567958 -0.1986988\n","  0.1305075  -0.20537226 -0.00392591 -0.3326291   0.11111056  0.07768751\n","  0.04992454 -0.14547825  0.22329769  0.11937617  0.18126586 -0.03967386\n","  0.20515223 -0.09919475 -0.05844484  0.00701357 -0.26455092  0.04541894\n"," -0.06086603 -0.07833707  0.10218633 -0.13510457  0.16784306 -0.17387833]\n","Stageid_PrimarySchool: [-0.21861237  0.15403734  0.08306921 -0.20393102  0.09282371 -0.26050898\n","  0.01230162 -0.01690244 -0.23954037 -0.17512922 -0.20002426  0.07964382\n","  0.11693456  0.03209576  0.23587771  0.01910138 -0.07049204  0.00604101\n"," -0.24068947 -0.18728238  0.14798535  0.23912857  0.25656334  0.006915\n"," -0.02295412 -0.05713076 -0.15179288  0.24953696  0.035216    0.22000378\n","  0.27075768  0.32783225  0.03711419 -0.08569467 -0.06590649 -0.09779917\n","  0.04244579 -0.0553664   0.13318561 -0.07548919 -0.12267581 -0.07127788\n"," -0.12035889 -0.05858187  0.01460611  0.11712482 -0.12894933 -0.00112853\n"," -0.04607159  0.09845781 -0.02266182 -0.08731504  0.20000744  0.01044363\n","  0.2920953   0.20582996  0.17161554 -0.05107648 -0.19317652  0.05923426\n"," -0.06093183  0.19797501 -0.13813445  0.06763951  0.1412176   0.10885073\n"," -0.11195731 -0.03765801  0.14183284 -0.06205253  0.21457048 -0.09082051\n","  0.02610367  0.18154919  0.09720087 -0.01744348 -0.12533379  0.04709774\n"," -0.00199486 -0.10381029 -0.01159576 -0.02102705  0.06421319 -0.15159163\n"," -0.02579496  0.10132543 -0.17117156  0.03722894  0.12940156  0.04398558\n"," -0.1641369  -0.07619974 -0.12521738 -0.1269174  -0.05188918  0.11305507\n"," -0.28660998  0.12117575  0.09295817  0.19469342 -0.06160321 -0.09079791\n"," -0.14009318  0.0197967  -0.1447441   0.2801158  -0.2021883   0.03711087\n","  0.30163655  0.06478497  0.05655344  0.16702224  0.0756282  -0.09581615\n","  0.00629135 -0.27812096  0.02630127  0.18994577  0.09825525  0.26601884]\n","Sectionid_A: [-0.25261375  0.03455107 -0.03952419 -0.23077269  0.14011352 -0.03932172\n","  0.1351272   0.14836341 -0.18887514 -0.18603685 -0.11369438 -0.02704396\n"," -0.03950099  0.06935745 -0.10351986 -0.05556877  0.07194052  0.14877695\n","  0.17119084 -0.02969304  0.25813428  0.0858755  -0.13016702 -0.13010702\n"," -0.11682582  0.27874932 -0.23154305  0.2713574   0.15674667  0.05934793\n","  0.1601822   0.2199009  -0.09024663  0.3070595   0.16666925  0.03762525\n"," -0.03670882  0.05895881  0.11990614  0.03852989 -0.23905917  0.03918673\n","  0.02825547  0.01960537  0.04169503  0.10839061 -0.1701339   0.20383863\n"," -0.07016489 -0.03257501 -0.17765358  0.19770221  0.10825833 -0.13922936\n","  0.2653056   0.2081335   0.2299527  -0.20746812 -0.0673637   0.07904755\n","  0.03496842  0.03289737 -0.11168956 -0.01591486  0.04145981  0.24133027\n","  0.04048314  0.0895662  -0.20444776  0.1652801  -0.27032998  0.05537991\n","  0.1063286  -0.05915395 -0.14021352 -0.16558242  0.1716029   0.1584884\n"," -0.12308331  0.09857181 -0.18832019  0.18314032  0.1311771   0.08896032\n","  0.06739467  0.08557823  0.0691071   0.21067694 -0.00178086  0.17805576\n"," -0.04862847  0.15981126 -0.08392578 -0.03477035  0.19986586  0.04655936\n"," -0.01970276 -0.15227617 -0.03465497  0.14721689 -0.02420807  0.00314187\n","  0.03375461  0.07495087  0.03861084  0.15059423  0.35495865 -0.11149164\n","  0.08841698  0.05661855 -0.00658191  0.18552592 -0.1299964  -0.03032532\n","  0.07701021  0.06880658  0.1246089   0.20907998  0.13388798 -0.09899873]\n","Sectionid_B: [ 0.1293473  -0.17645118  0.08469967  0.09764873 -0.05636548 -0.01252163\n"," -0.21667588  0.05342504  0.13323544 -0.12719223 -0.03745071  0.08692563\n"," -0.17264229 -0.08074214  0.09265063 -0.08960367  0.07480033  0.00312921\n"," -0.0587001   0.08082684 -0.20561938  0.2534005   0.00934087  0.3455817\n"," -0.08062753 -0.05400765  0.18062201  0.12642553 -0.10785041  0.06781363\n","  0.14929877  0.1983711   0.12765665 -0.12166824 -0.14695655  0.04567076\n","  0.12591662 -0.15352485  0.05681184  0.06390488 -0.11317278 -0.05740159\n","  0.06954664  0.20186803  0.12474948 -0.32123202 -0.05585703  0.05754932\n","  0.15751554  0.08660066  0.09851156 -0.11983258  0.14709169  0.3774053\n","  0.17051227  0.1360944  -0.14235118  0.09705964 -0.05632793 -0.01586225\n"," -0.14090802  0.23422553 -0.18942381  0.16890566 -0.09268288 -0.14828326\n","  0.07231868 -0.16703187  0.26885208 -0.2854951   0.27400982 -0.08183027\n"," -0.15961036 -0.11355039  0.15058431 -0.08685962  0.00393135 -0.2612088\n","  0.07675734 -0.03907292 -0.11371025  0.11061839  0.14264365 -0.0476431\n"," -0.00043914 -0.0886495   0.0308713   0.05043929 -0.04651644  0.14813907\n","  0.01093611  0.15918404  0.01348229  0.1416946  -0.0099533  -0.00946317\n","  0.06662752 -0.03309367  0.04233849  0.01801977  0.13475624  0.05254623\n","  0.04252788 -0.09679276  0.10033182  0.30877018 -0.2440287   0.0867154\n"," -0.10469375 -0.28683385 -0.09399074  0.16471782 -0.02616692  0.06005306\n","  0.20184597 -0.12316047  0.09754172 -0.04467804  0.05892104  0.06600994]\n","Sectionid_C: [-0.0108309   0.09117525  0.05083601 -0.06634957 -0.00400385  0.07956782\n","  0.09530011 -0.00216246 -0.16659912  0.21401703  0.06627923 -0.0232208\n"," -0.25335234 -0.10883036  0.0859978   0.00568122 -0.03921973 -0.10473666\n"," -0.25052533  0.18183656  0.01541188 -0.20445538  0.18485424  0.049133\n","  0.15695912 -0.17749692 -0.07524905 -0.00694281 -0.10823817  0.18790607\n"," -0.05981588  0.08681758 -0.12537488  0.27499586  0.03614999 -0.12209722\n"," -0.11704604  0.08097776 -0.10259893 -0.08634122 -0.04836369  0.06636338\n"," -0.11182661  0.11849664 -0.13388646  0.32411537  0.15847266  0.27145725\n"," -0.19925003 -0.08537375 -0.20816813  0.19740097  0.01775826 -0.35345232\n"," -0.22654735 -0.09504557  0.15105163  0.17302614  0.15915447  0.08078963\n"," -0.0733861  -0.06518155  0.05894624  0.0773891  -0.25375372 -0.1675924\n"," -0.05362305  0.18010688 -0.2793493  -0.02413841  0.02629081 -0.15112682\n"," -0.03690274 -0.0012502   0.16715562  0.22702953 -0.00537282 -0.0926826\n"," -0.16167882 -0.12398644  0.18151848  0.17630237  0.0899249   0.05428794\n","  0.06696495 -0.11672196  0.00457869  0.07996199  0.0839394  -0.04656553\n"," -0.29483747 -0.04756013  0.03894564 -0.16075146 -0.24806674  0.06033272\n"," -0.25814036 -0.17821921 -0.02504715  0.11009031  0.18277913  0.01566966\n","  0.15915477  0.19135803 -0.11043734 -0.09994186 -0.07402675  0.01382823\n","  0.11725077  0.24284877  0.07195815  0.02858219  0.03318718 -0.18535706\n","  0.04991506 -0.09715902 -0.12808971  0.14636777 -0.22757713  0.39905328]\n","Topic_Arabic: [-0.1326109  -0.02481789  0.01359948 -0.00340968  0.13287027  0.16079582\n","  0.05882388 -0.04962052  0.17281647  0.18541452 -0.04121377 -0.06726325\n","  0.09794506  0.08977223  0.07342586 -0.04563334 -0.11922093  0.09547549\n","  0.08482329 -0.0004588  -0.09155869  0.21795158 -0.03129917  0.07399639\n","  0.13125804  0.03381693 -0.03553646  0.07907807  0.25303048 -0.13992617\n","  0.13847046  0.12069146 -0.06199142 -0.1553154   0.12903446  0.18626076\n","  0.18969439  0.10620036  0.0240499   0.19172107 -0.13845102 -0.11191336\n","  0.25379467 -0.01941348  0.08937672  0.16425224 -0.03179359 -0.01448662\n"," -0.13320929 -0.17343895 -0.01442844 -0.09115595  0.0679737   0.32676616\n"," -0.01531154 -0.056692   -0.12635411  0.0016948   0.26367044 -0.146424\n"," -0.14706133  0.09924208 -0.13615768 -0.06353342 -0.07225184  0.24675187\n"," -0.12410842 -0.17392026  0.11114918 -0.0118416  -0.25236776  0.10860926\n","  0.10386516  0.03674698 -0.02877377 -0.1798013  -0.03388368 -0.0101769\n","  0.0989285  -0.00875795  0.21822894  0.12666255 -0.02374756  0.00150084\n"," -0.13210684  0.07789321  0.03896366  0.16808008 -0.13092254  0.18405639\n"," -0.11537763  0.03813644  0.22259618  0.00534173  0.03550781 -0.08048264\n","  0.19954638  0.03398682  0.18376313 -0.20376264 -0.08987391 -0.04147463\n","  0.01206514  0.04296909 -0.04469995  0.08683634 -0.03104705  0.08807456\n"," -0.23375405 -0.0756743   0.10198309  0.06927122 -0.05126501 -0.08507563\n","  0.0432692   0.17771418 -0.03854998  0.07377755  0.1531588   0.1562202 ]\n","Topic_Biology: [ 0.1911862   0.14729893  0.23480666  0.29960677  0.1608907   0.14848422\n"," -0.11476015 -0.00198413  0.26813585 -0.14770885 -0.04301864  0.08780672\n"," -0.16164036  0.06673208  0.10714266 -0.31528324 -0.14744468 -0.08475816\n","  0.11336748 -0.16656682 -0.10593563  0.13873345  0.05040839 -0.06859457\n"," -0.19111897  0.3678307   0.15394345 -0.08087958  0.16594079 -0.12052449\n"," -0.05065    -0.3395905  -0.20795466  0.10307579 -0.22333056  0.09636271\n","  0.01071288  0.29494855  0.2825379  -0.02480385  0.01121484 -0.02049701\n"," -0.14858305  0.02737713  0.22671382  0.12612537 -0.3992426  -0.21048953\n","  0.12402119 -0.21106501  0.25795913 -0.02643527 -0.12153979  0.1324594\n"," -0.1441123   0.15577966  0.0524482  -0.08987565  0.12845866  0.27400997\n"," -0.12786567 -0.0507147   0.11651541  0.30264518  0.03639293  0.09583956\n","  0.30070552 -0.10205114 -0.12406198  0.00101686 -0.05107501 -0.13005325\n"," -0.14075218  0.1425073  -0.10018152  0.14574313  0.33964032 -0.14269066\n"," -0.12482731 -0.05482094  0.3504633  -0.0117205   0.1534193  -0.05196889\n"," -0.04234496  0.09640917 -0.07682086 -0.00081033 -0.15166214  0.11459398\n"," -0.05155565 -0.16754198  0.27882287  0.03810279  0.01351612  0.03848479\n"," -0.05970909 -0.02147027  0.1060445  -0.0162032  -0.24217193  0.06266096\n","  0.02894377 -0.14403619 -0.16315164 -0.38084275  0.07593026  0.20775944\n","  0.04505408 -0.07079352 -0.26140484 -0.0553701   0.05928128  0.14367507\n","  0.1642649   0.28937215 -0.31599903 -0.35208663 -0.24700685 -0.39817673]\n","Topic_Chemistry: [ 0.14200379 -0.12116142 -0.02647036  0.25835428 -0.10551997  0.21770205\n","  0.23186621  0.09331313  0.13951631  0.06093216  0.15056686  0.33303136\n","  0.13241908  0.27407673  0.17592151 -0.40007827  0.03130439 -0.14094767\n","  0.22141413 -0.31964594 -0.03804885 -0.07960606 -0.02291503  0.09557036\n","  0.12226269  0.13102727  0.29254583  0.09712993 -0.12206016 -0.12954593\n"," -0.13684447 -0.295481    0.0037665  -0.1343686  -0.11357576  0.17027245\n","  0.05408849  0.33674958  0.34681436 -0.18904206 -0.15455125 -0.30601755\n","  0.28964248  0.2320329  -0.06491771 -0.15620048 -0.22734343  0.20705034\n","  0.2582246   0.02999276  0.2962755  -0.03333299  0.0453871  -0.01212266\n","  0.41820762  0.14393026  0.00121727 -0.37401608  0.05974014  0.2855965\n"," -0.16768758  0.04253597  0.14127386  0.41875982  0.23640394 -0.07363942\n","  0.15482293  0.07143793 -0.17719793  0.1258208   0.04736617  0.08510548\n"," -0.27004784  0.18685688 -0.05275825 -0.08985432  0.23228958  0.0871363\n","  0.10790109 -0.14040531  0.14997278  0.01506731  0.36415577  0.09851274\n"," -0.19461146 -0.08501574 -0.07836335 -0.11732204 -0.21634294  0.18740144\n","  0.23803523 -0.15585168 -0.17735271 -0.16781059 -0.04494925  0.11080119\n","  0.07293103  0.17233188  0.06568596 -0.01395227 -0.06345722  0.18030871\n"," -0.05017003  0.21966043  0.18334618 -0.1848439   0.09996829 -0.12435661\n","  0.1188285   0.13536473 -0.19886163 -0.22767934  0.0584032   0.24723122\n","  0.03257919 -0.03035661 -0.2995859  -0.08771999 -0.03478952 -0.0397853 ]\n","Topic_English: [ 0.06502581  0.03741969  0.02721711 -0.06345949 -0.13209327  0.26195088\n"," -0.03859757  0.05995334  0.02926374  0.04097415  0.18011153 -0.07952148\n","  0.13196194 -0.09836639  0.0549297  -0.03283831  0.1254609  -0.03012957\n"," -0.12456272  0.00273619  0.00603102 -0.13750893 -0.19321014 -0.22480094\n"," -0.01189266 -0.13969779 -0.08794495 -0.12820166  0.15445057  0.09923414\n","  0.03647079  0.08442809 -0.10633556 -0.06509817 -0.11261787 -0.09707981\n","  0.0078211  -0.10409392 -0.13521457 -0.22409545 -0.16143571 -0.06232655\n","  0.19186473  0.08184832 -0.15168126 -0.10525909  0.10219228 -0.0482581\n"," -0.01024831 -0.32936382  0.09254014  0.00595704  0.06281287 -0.23178975\n","  0.00685966 -0.09053776 -0.15040329  0.00298762  0.02615204  0.28911233\n"," -0.02246118 -0.10518268  0.17294939 -0.14048943 -0.06292598 -0.15406142\n","  0.19840947  0.11511695  0.03316426  0.16362643  0.05154042 -0.05868738\n"," -0.16622716 -0.03251832 -0.13341431  0.05715229 -0.08561476 -0.10010733\n"," -0.13959362 -0.27363992  0.09113555  0.11590861  0.05589937 -0.03046557\n","  0.00713564  0.17409405  0.11853346  0.02932742  0.26595995  0.09202144\n"," -0.22367558 -0.17913717  0.13389647  0.15422112 -0.0863647   0.00509438\n"," -0.45656165 -0.02118537 -0.10809993  0.07718319 -0.0656148  -0.01098308\n","  0.15473406  0.10616215  0.03844157 -0.27171907  0.1296195  -0.11765737\n"," -0.13796864  0.27078298  0.06391585 -0.01447344 -0.02718404 -0.13295127\n","  0.00446357 -0.12249982  0.00756062 -0.10520407 -0.05561301  0.17973486]\n","Topic_French: [-0.2247836   0.24569757  0.48242652 -0.12942584  0.13807485  0.3474489\n","  0.1769199  -0.0032111  -0.09598512 -0.02131541 -0.24581406 -0.02351728\n","  0.2615968  -0.31499586 -0.08897533  0.1279933   0.1835192   0.08136761\n","  0.01801088  0.0896562   0.08835337  0.21138673  0.13332988  0.33575216\n","  0.11137915 -0.46973625 -0.29480103  0.11882187 -0.08092284  0.02727685\n","  0.30331412  0.17605884  0.19036171  0.13318299  0.08615194 -0.19044235\n","  0.0252839  -0.0909108  -0.2698807   0.1895895  -0.11935411  0.12493478\n","  0.00093037 -0.08271668 -0.298081   -0.02271914  0.02408423  0.39274278\n"," -0.32020798 -0.20012112 -0.19163992  0.06853566  0.25992763 -0.11616805\n","  0.01696633  0.28415385  0.4655161  -0.2803665  -0.24998792  0.05998539\n"," -0.04211847 -0.09538102  0.11313666 -0.23743118  0.3110283  -0.11444971\n"," -0.1062173   0.1713008   0.13445018 -0.09238572 -0.11682262 -0.12038924\n","  0.13946956  0.12489931 -0.01741777 -0.18189971  0.02399193 -0.18002465\n"," -0.04137322 -0.01682764 -0.05827661  0.15695652  0.07636218 -0.04948677\n","  0.19067614  0.1852329   0.08083054  0.24632096  0.18070579 -0.16064458\n","  0.0904768  -0.14982569 -0.04466023  0.19136305 -0.07901456  0.04816318\n"," -0.13982733 -0.14899473 -0.33717763  0.15778793  0.3674095  -0.07168388\n"," -0.3886982   0.2324866  -0.01946752  0.28019464 -0.0630267  -0.03197482\n","  0.23488685  0.0637735  -0.02337304  0.18690455  0.00623156 -0.08314081\n","  0.2243113  -0.04287509  0.25944233 -0.00148816  0.06207543  0.15039788]\n","Topic_Geology: [-0.10985164 -0.13028549 -0.16329785 -0.04377825 -0.00269689  0.13823503\n"," -0.05580754  0.00560656 -0.0852562   0.0058191  -0.02167967 -0.0703961\n"," -0.16006662 -0.08804889 -0.08728459  0.03075822  0.22934312  0.15098569\n","  0.169119    0.19148412  0.14822258 -0.10949513  0.08997332  0.20000534\n"," -0.09830515  0.36628425 -0.11940892  0.20905465 -0.29977593  0.33398777\n","  0.09539837 -0.03055664 -0.02770782 -0.09568831  0.05419885 -0.06270339\n"," -0.00173698 -0.23671198 -0.03875576  0.07898428 -0.05500291  0.01050395\n","  0.1751701  -0.27160832  0.30642748  0.14450885  0.07624166  0.19104096\n"," -0.11898667 -0.22124316 -0.13851519  0.12423719  0.2067332   0.17397335\n","  0.09347052 -0.099296   -0.00538246  0.30124298 -0.2688684   0.07140311\n"," -0.04085109  0.03496229  0.01992157 -0.2755057   0.12121482 -0.00607534\n"," -0.2409045  -0.06499744 -0.03960395  0.18917969 -0.15164125 -0.03661235\n","  0.08266648 -0.04446749 -0.09067694 -0.0436648  -0.13512385  0.06477292\n"," -0.3260128   0.19718996 -0.02057677  0.1495533  -0.16709188 -0.00271656\n","  0.17462063 -0.03543672  0.13465983  0.08247057 -0.10350188  0.06450944\n","  0.09483647  0.08860469 -0.13429116  0.08262041  0.25587407  0.06016676\n"," -0.02412543 -0.2717603   0.04610173 -0.24307877  0.05552942  0.13674475\n"," -0.3060742   0.03718759 -0.10134585  0.21012086 -0.17491415  0.45552665\n","  0.04969097 -0.12384184  0.27118668  0.29904208 -0.33517373 -0.10442717\n"," -0.05206814 -0.29244816  0.303122    0.08347192  0.06586851 -0.14924225]\n","Topic_History: [-1.01774260e-01  4.88375453e-03  1.42506689e-01 -6.35165051e-02\n","  4.22053188e-02 -1.46589510e-03 -8.50687921e-02  2.71543950e-01\n","  6.52767792e-02 -2.37086087e-01 -1.70120686e-01  1.12449527e-01\n","  1.47044107e-01 -2.12964743e-01 -1.20559394e-01 -1.15406863e-01\n","  8.69242027e-02 -1.76272571e-01  5.85623309e-02 -1.54987171e-01\n","  3.52634519e-01  2.14387178e-02  3.48522663e-01 -2.49927819e-01\n","  1.28506571e-01 -4.06946801e-03 -1.63249984e-01 -4.34885398e-02\n"," -2.09660694e-01 -1.57759771e-01  1.40535489e-01  1.80946231e-01\n","  1.47593915e-01  9.98781323e-02  3.55385877e-02  6.22373819e-03\n","  1.59425929e-01 -8.47215876e-02 -1.87657326e-02 -2.69140691e-01\n","  1.28679365e-01 -2.02926591e-01  6.34512352e-03 -1.91598818e-01\n"," -1.00784712e-01  1.26406550e-01  4.30379855e-03 -1.09061159e-01\n"," -1.61306813e-01 -6.92382902e-02  2.07354680e-01  1.68421894e-01\n","  1.61331519e-01 -1.39735550e-01  2.22328350e-01 -1.26118556e-01\n","  1.89781174e-01 -2.89600998e-01 -1.50463939e-01  2.09584340e-01\n","  7.82553852e-02  1.45939505e-02  1.82475358e-01  1.30795747e-01\n"," -3.47128473e-02 -9.65029150e-02 -1.22237772e-01 -8.18142965e-02\n"," -1.43892854e-01 -6.80550933e-02  9.28167403e-02  1.15882188e-01\n"," -5.93763851e-02  2.86724716e-01  8.64595771e-02  1.54101193e-01\n","  4.66324016e-02 -1.43640071e-01  5.43145500e-02 -3.29921007e-01\n"," -1.15697682e-01  1.07499219e-01  2.89483488e-01  8.97912681e-02\n"," -1.45289049e-01  2.33746067e-01 -6.02337718e-03  5.65172806e-02\n"," -9.73621458e-02  1.35468453e-01  9.63902920e-02  1.70772374e-01\n","  3.45158651e-02 -2.32362941e-01  4.22009796e-01 -7.23796263e-02\n"," -3.32998544e-01 -1.31947339e-01 -2.13590041e-01 -8.67710188e-02\n"," -2.07345989e-02  2.78739184e-01 -2.51636863e-01  1.30294248e-01\n"," -3.77006829e-04 -1.72967285e-01  1.52238607e-01 -1.35577872e-01\n","  2.17930108e-01 -3.46446633e-02 -1.02256082e-01  1.82950139e-01\n","  8.29252899e-02 -7.59126842e-02  1.19854212e-01  2.58971918e-02\n","  2.85127424e-02  4.68958393e-02 -1.06030621e-01 -3.21825743e-02]\n","Topic_IT: [-2.38563190e-03 -1.26976952e-01  5.59386276e-02 -1.85409948e-01\n","  1.65973336e-01 -3.83544981e-01 -2.59507280e-02 -1.53975517e-01\n"," -1.98844835e-01 -6.17101863e-02  1.73058808e-02 -9.69153419e-02\n"," -2.33553484e-01 -1.91581711e-01  5.34445308e-02  2.89232321e-02\n","  8.25574249e-02  7.53135979e-03 -5.31659648e-02 -2.56649870e-02\n"," -1.43377587e-01 -5.41921221e-02 -1.65066838e-01  1.61791176e-01\n"," -8.23289752e-02 -1.97967038e-01 -3.09644192e-02 -2.17421725e-02\n"," -7.29909614e-02  5.12494929e-02  8.89069736e-02  2.93035954e-02\n","  2.85516540e-03  2.65777186e-02  9.62441266e-02  1.19619526e-01\n","  1.61375180e-01 -2.20473617e-01 -1.34552360e-01  2.23130748e-01\n","  1.77363619e-01  6.38553873e-02  1.72016118e-02  1.47329330e-01\n","  1.71449825e-01  1.86018690e-01  1.49505067e-05  2.46870309e-01\n"," -1.75859094e-01 -7.13540614e-02 -9.90945473e-02  1.14555530e-01\n","  5.98116517e-02  3.90648544e-02 -2.18780771e-01 -9.90129560e-02\n"," -6.57672882e-02  1.71927288e-01  1.01524033e-01 -1.90879628e-01\n","  1.11149564e-01  1.40502229e-01 -1.71880767e-01  8.35307613e-02\n"," -1.07131362e-01  3.66431251e-02 -1.61547214e-01  1.18529946e-01\n","  2.00124681e-02 -2.96441376e-01  1.49929523e-02  3.66816521e-02\n","  1.01738378e-01 -1.17430538e-01  6.67498857e-02  7.91954547e-02\n"," -2.78826922e-01 -1.07615136e-01  5.24453148e-02 -1.89579744e-02\n"," -2.39142939e-01 -3.16529647e-02 -1.50668755e-01  1.61733806e-01\n"," -1.01654798e-01  4.63273861e-02  8.00744370e-02  1.76522713e-02\n","  2.25753292e-01 -2.66214542e-04 -4.66599688e-02 -1.39714748e-01\n"," -1.35960057e-01  1.98252037e-01 -3.03221613e-01  5.69795072e-02\n"," -9.22732279e-02 -1.17353030e-01  1.74184665e-01  1.13187715e-01\n","  1.63435549e-01 -2.55369581e-02 -1.53512225e-01  2.45373920e-01\n"," -1.75541602e-02  1.50855049e-01 -3.04628134e-01 -3.86113934e-02\n"," -1.35175571e-01 -8.18810333e-03 -9.24229994e-03  4.63664904e-02\n","  1.06139466e-01  7.57827982e-02 -6.01151399e-03 -1.31773710e-01\n","  9.92487893e-02  1.42665163e-01  1.04010418e-01  2.23163575e-01]\n","Topic_Math: [ 0.20079827  0.10168101  0.04668182 -0.07737277 -0.12204348 -0.11347459\n","  0.00102758 -0.19059668  0.04137341 -0.06946075  0.19445921 -0.01429634\n","  0.01637863  0.13063456  0.04202912 -0.17909512 -0.11029462 -0.09895848\n"," -0.08636405 -0.06650521 -0.00821932  0.18359622 -0.05437994 -0.0539437\n","  0.15712455  0.39314038  0.18479475 -0.240598    0.2855952   0.12931633\n"," -0.05205974 -0.05696256 -0.09882262  0.46830088 -0.23598972  0.03879765\n"," -0.09329364 -0.01555254  0.15088347 -0.14118244  0.14690028 -0.18421088\n","  0.10689438 -0.09283779 -0.07848871  0.03480563  0.10058513 -0.03423139\n","  0.1582903   0.21017125  0.06401809 -0.18782371 -0.14803647 -0.12309745\n","  0.14682199  0.02090527 -0.14054437 -0.01497973  0.25205246 -0.06590925\n","  0.10295701  0.0522466  -0.02159404 -0.0339645  -0.16003104 -0.10674912\n","  0.01673458 -0.12617156  0.04287406 -0.2287931  -0.00148495 -0.17099753\n","  0.11784257  0.07735529 -0.00637192 -0.05580889 -0.07531957 -0.16037866\n","  0.11670014 -0.03805269 -0.00645923  0.02843489  0.04710146  0.16922346\n","  0.3023186  -0.00226094 -0.12288345 -0.03043761  0.15637536  0.12277636\n"," -0.20152545 -0.17323828  0.2733453   0.0059641  -0.3151341  -0.0290278\n","  0.22431324  0.01312919 -0.05088424 -0.12201382 -0.31300265 -0.14051275\n","  0.06662611  0.0883059   0.1777627  -0.11623812  0.08615023  0.11536112\n"," -0.21247278 -0.0482155  -0.12549098 -0.03908289 -0.02028252  0.20516083\n","  0.04716391 -0.09026194  0.1397339   0.00056415 -0.01276527  0.04905311]\n","Topic_Quran: [-0.00252975 -0.08575819  0.15461269 -0.04705796  0.00573522  0.31134817\n"," -0.04517186 -0.07745114 -0.12589058 -0.02506235  0.2246997  -0.13057598\n"," -0.01717812 -0.12740424 -0.03759532 -0.03494127  0.11978012 -0.0379073\n"," -0.10513858 -0.03091773 -0.10566623 -0.13299936 -0.06875303  0.19337583\n"," -0.00066099 -0.24508898  0.26546425  0.08212018 -0.13323312  0.1527393\n","  0.20388845 -0.03050143  0.05058796  0.0460282   0.12887277  0.00176694\n","  0.06064057 -0.14055265 -0.06766836 -0.17313741 -0.3061786  -0.23357879\n","  0.03988913 -0.08826499  0.00241633 -0.08043879  0.00728402  0.15084998\n","  0.11563166 -0.15041001  0.05005892  0.18532214  0.22132346 -0.09277833\n"," -0.05924373  0.01474833  0.28771004 -0.15749653 -0.1154946   0.04995428\n","  0.04143533  0.3244699  -0.17231591  0.09007879 -0.1148402   0.20608845\n","  0.00610619 -0.1544405  -0.00570538  0.07136485 -0.1871463   0.0362377\n"," -0.1342279   0.01869159  0.17593747 -0.30382094  0.05267907 -0.0067606\n"," -0.08402536 -0.38519108  0.03289197  0.17700453  0.17149082 -0.12375674\n","  0.06026543  0.07162748  0.02840886 -0.03172595 -0.21442084 -0.01880561\n","  0.1283235  -0.03689459  0.18375103 -0.09119172  0.01816435 -0.07511573\n","  0.04408998 -0.08355187 -0.03918194 -0.08137182  0.11054002 -0.34822437\n"," -0.15702902 -0.06026552 -0.02012914 -0.27325612 -0.05877607 -0.1129551\n","  0.20715505 -0.00506609  0.07150391 -0.13795783 -0.17817225 -0.09377991\n","  0.1827632   0.11710712  0.01116354  0.10697877  0.09996327 -0.07289556]\n","Topic_Science: [-0.16443788 -0.21658194 -0.15132892 -0.1777256  -0.02087471 -0.308075\n","  0.06088337 -0.1515696  -0.07041792  0.17728133  0.22621474 -0.16104488\n","  0.21424446  0.23774822  0.26650122 -0.13034178  0.02871069  0.01159161\n"," -0.12554732 -0.12465331 -0.2030897   0.09745193  0.02482209  0.11678732\n"," -0.08715022 -0.37822512  0.1645637   0.2057988  -0.10767828 -0.0171682\n","  0.17279188  0.09796572  0.16783138  0.1518413   0.04025807 -0.03404439\n","  0.05724749 -0.0098015   0.01679632  0.06146107 -0.00317898 -0.11263006\n","  0.05788171  0.09935436 -0.0289597  -0.02860123 -0.10353808  0.05558791\n"," -0.16589269  0.06964246  0.17923276 -0.1039989   0.17357221  0.0520084\n","  0.31076345 -0.2833815  -0.17534713  0.10218928 -0.16089316  0.1036493\n","  0.04867283 -0.05740577 -0.15835029  0.05773944 -0.00505837 -0.06028092\n","  0.10399172  0.1230568  -0.20315398  0.32498106  0.0333901  -0.00177516\n"," -0.0562418   0.0928456   0.17729399 -0.18078035 -0.24322486  0.02539596\n"," -0.12614058  0.04971172  0.06038327 -0.13224126 -0.12181323  0.08652905\n"," -0.03119861  0.16534571 -0.05101621 -0.08365963 -0.24258365  0.00078061\n","  0.23632328 -0.14708066  0.01118788 -0.07397247 -0.17572676  0.17282254\n"," -0.12079782  0.32001156  0.23647684  0.19229728  0.16013221  0.17145999\n","  0.01904672  0.17205678 -0.07427429 -0.04910656  0.14787188  0.19390541\n","  0.08889493 -0.45694992  0.08129394 -0.07720917  0.4502095  -0.00985918\n","  0.34245026 -0.06357138  0.14286289  0.11781941 -0.03615145 -0.2270553 ]\n","Topic_Spanish: [-0.22452268  0.14804076  0.21386771 -0.12888397 -0.12586829  0.37724438\n"," -0.05810311 -0.1429383  -0.0187455   0.16336152  0.14242305 -0.09229261\n"," -0.3163161  -0.23726454 -0.14821386 -0.10984796 -0.15166962 -0.10869302\n"," -0.05807773 -0.14221491  0.14260408 -0.03239493 -0.07925159  0.25011224\n"," -0.08646207  0.03042738 -0.2317069   0.2567139  -0.23574759  0.17193086\n"," -0.04561439  0.26681906 -0.0535191   0.07444941  0.292567   -0.1825036\n","  0.04814845 -0.1847153   0.08102868  0.14309984  0.06978181  0.15044244\n"," -0.12259532 -0.07936604  0.02537138 -0.00893282  0.14531346  0.3361943\n"," -0.13029969  0.11714084 -0.12429473 -0.04270943 -0.03575436 -0.0078916\n"," -0.19451031  0.1998088   0.39971024  0.05579964 -0.13300991 -0.22346027\n"," -0.13982023  0.38372573 -0.0440713  -0.09211264  0.09813123  0.20883383\n","  0.06475177 -0.09879138  0.04282075  0.2704014  -0.00311556  0.08480251\n"," -0.09126588  0.03700979 -0.04289159 -0.17926235  0.12878141  0.20425679\n"," -0.08602993 -0.15501347  0.02873999 -0.02277295  0.00422774 -0.01303583\n"," -0.02725567  0.2795225   0.02113605  0.10930406  0.05180236  0.18127052\n"," -0.14256419  0.09173286 -0.29443493  0.0385603  -0.02337858  0.03463939\n","  0.07167566 -0.16530281 -0.1809337   0.12038731  0.11178168 -0.07530826\n"," -0.17429288 -0.04205899  0.18346271  0.1205247   0.0642782  -0.18709178\n","  0.03717383  0.47043136  0.03757795  0.17943989  0.16240704 -0.04781194\n"," -0.21924669 -0.09612924  0.17123184  0.2552708   0.11694232  0.23094465]\n","Relation_Father: [-0.23410106  0.00506693  0.12439834 -0.13646409 -0.07154463 -0.00923683\n","  0.08930732 -0.0367586  -0.20543335 -0.05385689 -0.32709217 -0.09651644\n"," -0.02891494 -0.06028786 -0.03078138 -0.0707944   0.07357012 -0.00766225\n"," -0.04784247  0.10366943  0.0863936  -0.03304918  0.07058496  0.01462808\n","  0.05324763  0.17806304 -0.29800355  0.37454933 -0.30607554  0.10816322\n","  0.27030057  0.275203   -0.12435905  0.09980864  0.08406799  0.00246117\n"," -0.03772812 -0.08283284  0.04535457 -0.07617105 -0.11247262  0.02298999\n"," -0.19058336  0.04142855  0.00610552  0.32257795 -0.16296652  0.3377396\n"," -0.12419295  0.07662265 -0.02461886  0.10431378  0.08871834  0.18442276\n"," -0.01859483  0.17806458 -0.02189676 -0.14421254 -0.20443751  0.13140446\n"," -0.07259902  0.08816767 -0.18181202 -0.05139495 -0.31738597  0.15677103\n","  0.04070855  0.16387144 -0.2019752   0.0297386   0.08475367 -0.03654784\n"," -0.05591419 -0.19614963 -0.03918652  0.14875223  0.03356025 -0.02829502\n"," -0.02206149  0.07740317 -0.20062941  0.10389398  0.03229205 -0.17977287\n","  0.13780391  0.08230807 -0.06208564  0.20660242  0.28078917  0.07473566\n"," -0.29013312 -0.07736288  0.11586574 -0.09453461 -0.08820485  0.09831474\n"," -0.19045608 -0.33218983  0.04393672  0.10029779  0.10217436 -0.14782512\n"," -0.21829428 -0.04481247  0.11395613 -0.0231797   0.03729874 -0.06041534\n","  0.24315178  0.04347456  0.0070041   0.03612368 -0.10138816 -0.03231314\n","  0.2337306  -0.2863481   0.13425736  0.0994986   0.01450064  0.25652754]\n","Relation_Mum: [ 0.05135934  0.06444705  0.22980136  0.0770699  -0.00542129 -0.09486667\n","  0.24781804  0.09986082  0.13653445  0.17960614 -0.013951   -0.00542756\n"," -0.04909543  0.15190609  0.2065633  -0.18636541  0.11090359  0.06574737\n","  0.02933251 -0.27233034 -0.11469286  0.05650151  0.02647387  0.15145391\n","  0.08385523  0.15104279  0.15709823 -0.07508304 -0.00895513 -0.15153305\n","  0.09862214  0.03100523  0.03074998  0.17972395  0.08173006 -0.05360101\n","  0.07407948 -0.01398375 -0.08716732 -0.20294732 -0.04244862 -0.1235597\n","  0.07348596  0.02927011 -0.08764431  0.08931001 -0.14818588  0.14143659\n","  0.18153104 -0.07844871  0.15709476  0.11507135 -0.1725922   0.02777583\n"," -0.00321899 -0.15339997 -0.04521034  0.07996065 -0.13958132  0.11294574\n","  0.06339671  0.05597249  0.09717906  0.06040948  0.08956309  0.09529497\n"," -0.13149583  0.1636365  -0.10793176  0.05902966 -0.22999348 -0.1566248\n","  0.0077537  -0.05558042  0.08635572 -0.1439727   0.00246743  0.20192407\n","  0.11346883 -0.22873253  0.13884337 -0.03656341  0.2255994   0.01696768\n"," -0.09146098 -0.11612333  0.16540828 -0.02069697 -0.13375708 -0.09614305\n","  0.02207552 -0.06319378 -0.25652725 -0.03616423  0.0542991   0.1031021\n","  0.17882612  0.274151    0.08722366  0.15298694 -0.13449092  0.10484962\n","  0.19041407 -0.06126155  0.15247913  0.06604158  0.02441747 -0.2131879\n","  0.19715913 -0.26612902 -0.23660505  0.02378195  0.0476615  -0.01584671\n","  0.18477738  0.21247688 -0.02510615 -0.03104367  0.09307854 -0.2820721 ]\n","Studentabsencedays_High: [-0.34426093 -0.02911746  0.43763223 -0.32810885 -0.02063944  0.21792598\n","  0.09030955  0.27208212 -0.4573577  -0.08905764  0.01096133 -0.20651364\n","  0.1482038  -0.21429229  0.09498464  0.00096598  0.21520029  0.09673372\n","  0.45030528 -0.41358146  0.42155752 -0.22239214  0.25686905  0.365572\n"," -0.19792525 -0.27984616 -0.3664404   0.45205265 -0.2572127   0.07569401\n","  0.20875965  0.23578644 -0.2777998   0.05431249 -0.10482199 -0.17727992\n"," -0.06471855 -0.28328538 -0.1533827  -0.18089026 -0.08708636 -0.4079486\n","  0.0113408  -0.36376384 -0.06751295  0.08783086 -0.2557254   0.47128245\n"," -0.39959058  0.16310334  0.06665318  0.3263117   0.2910311   0.32024476\n","  0.01095079  0.28035587  0.37671638 -0.12886241 -0.3805552   0.18396339\n"," -0.10706783  0.36722437  0.28565034  0.09001745  0.2710353  -0.12669113\n","  0.18307209  0.04606116 -0.40138417  0.16531968  0.36734974 -0.1396774\n","  0.01598113  0.07708032 -0.17965168 -0.06239732  0.23888369  0.03311949\n","  0.347611   -0.34683168 -0.3380483   0.46384406  0.30778086  0.01644616\n","  0.43664864  0.2509514  -0.05913108  0.09700793  0.12562765  0.07026596\n"," -0.09072776  0.14902985 -0.39193746 -0.05712022  0.41943634 -0.02355258\n"," -0.31193337  0.05801827 -0.03482354  0.2951755   0.26147538  0.05804774\n"," -0.48411343 -0.08323299  0.2857492   0.2287295  -0.10095288 -0.12800238\n","  0.51145536 -0.36326316 -0.09600303  0.25919813  0.15934001  0.12323699\n","  0.44032657 -0.31341115  0.07702187  0.05728138  0.29366913  0.27388066]\n","Studentabsencedays_Low: [ 2.17065394e-01  1.16668917e-01 -2.33621195e-01 -2.92951595e-02\n"," -1.65434569e-01 -3.64621252e-01 -3.96767288e-01 -2.98969746e-01\n"," -4.90254052e-02  1.89071164e-01 -1.03675298e-01  1.82384685e-01\n"," -3.09190661e-01 -1.03945464e-01  8.34838375e-02  4.07101102e-02\n","  1.05975233e-01 -1.69790745e-01 -8.59135836e-02  1.00395463e-01\n"," -1.70549303e-01  2.90476531e-01 -4.02817309e-01 -3.10835719e-01\n"," -2.08031405e-02  1.29243553e-01  3.90996225e-02 -2.92313136e-02\n","  2.64616102e-01 -1.74841762e-01 -5.81757799e-02 -1.96427852e-01\n","  2.06540555e-01  2.13861898e-01 -1.18726857e-01  3.68349627e-02\n"," -3.12405918e-02  1.05458289e-01  7.36094564e-02  5.87147884e-02\n"," -2.79629733e-02  2.51735628e-01 -9.27263796e-02  2.92012710e-02\n"," -1.36565030e-01 -7.32687712e-02  3.15941691e-01 -3.70299101e-01\n","  2.10452899e-01 -1.72764063e-01 -1.90176800e-01 -8.22717249e-02\n","  1.66422099e-01  1.25613809e-02 -2.67034709e-01 -1.26991421e-01\n"," -8.87738839e-02  4.56482947e-01  1.89934507e-01 -1.12790495e-01\n","  7.30378628e-02 -3.31636965e-02  4.14040813e-04 -2.88840175e-01\n"," -2.70420760e-01  1.57301798e-02 -1.38729751e-01 -4.94005382e-02\n","  3.49145196e-02 -4.29309398e-01 -1.84685007e-01  1.75116301e-01\n","  9.77692828e-02 -2.66850650e-01 -1.42319664e-01  2.44536981e-01\n"," -2.72650272e-01 -1.65061817e-01 -2.51484245e-01  3.55448455e-01\n","  3.80708314e-02 -6.52538761e-02 -2.54812449e-01  1.05579048e-01\n"," -1.81566477e-01 -9.77147147e-02  1.48238435e-01  3.08279134e-03\n"," -1.32799819e-01 -2.13909209e-01  6.57472461e-02 -1.63102761e-01\n","  2.36248136e-01  2.77311027e-01 -3.73829067e-01  2.82433093e-01\n","  7.16631338e-02  1.01243369e-01  5.29340655e-02 -2.64641285e-01\n"," -2.41960753e-02  1.80527605e-02  1.25251159e-01  5.77830477e-03\n"," -1.67009130e-01 -1.91667393e-01 -7.93652236e-02  4.45013255e-01\n"," -4.82260346e-01  1.75857469e-01  1.07308060e-01 -2.50037074e-01\n"," -1.43226370e-01 -1.02103747e-01 -3.38671133e-02  1.75053582e-01\n","  4.65582237e-02 -2.44915597e-02 -4.71512601e-02 -2.90888101e-02]\n","Biases:\n","[-1.03536427e-01 -1.76967047e-02  1.01124138e-01 -5.82600608e-02\n"," -3.88682522e-02 -5.21667227e-02  3.17597017e-02  3.81421559e-02\n"," -7.68668875e-02 -2.53437199e-02 -2.79600993e-02 -1.38533814e-02\n","  2.31998637e-02 -3.68252099e-02 -1.15218409e-03  1.39597105e-03\n","  3.49816866e-02  0.00000000e+00  3.66288163e-02 -3.54928449e-02\n","  1.54281082e-02  7.51639530e-02  6.78298399e-02  8.03478658e-02\n"," -2.71014720e-02 -9.14610282e-05 -4.02958244e-02  8.98125768e-02\n"," -5.31621687e-02  3.31870131e-02  7.80090392e-02  7.85550550e-02\n"," -4.50029038e-02  1.02379866e-01  4.35133427e-02 -4.51670913e-03\n"," -1.07838083e-02 -3.90720405e-02 -5.96189126e-03  8.19391664e-03\n"," -1.72117185e-02 -5.48803667e-03 -1.99535191e-02 -2.49667447e-02\n"," -3.89597453e-02  4.50743362e-02 -5.12433127e-02  1.85893193e-01\n"," -5.41636869e-02  7.07774460e-02  1.97128626e-03  6.42677397e-02\n","  7.00302497e-02  2.88286600e-02  3.88805680e-02  3.77617478e-02\n","  9.02162194e-02 -3.17636766e-02 -5.41081503e-02  3.29835601e-02\n"," -6.00451557e-03  5.62793687e-02 -7.05103343e-03 -2.52533667e-02\n","  3.16865998e-03  4.02373495e-03 -2.08026432e-02  0.00000000e+00\n"," -5.11218533e-02  1.25710610e-02  4.12800089e-02  0.00000000e+00\n","  2.86520049e-02  2.13784575e-02  0.00000000e+00 -3.71021852e-02\n"," -8.06989521e-03 -4.44143452e-02  5.74211478e-02 -2.07094941e-02\n"," -9.36520770e-02  6.30055070e-02  3.29256877e-02  0.00000000e+00\n","  1.00816362e-01  4.43302654e-02 -8.09449609e-03  2.69197300e-02\n","  4.65218462e-02  2.65045408e-02 -4.05579582e-02  0.00000000e+00\n"," -1.50848851e-02 -3.12957428e-02  4.22286689e-02 -3.23354900e-02\n"," -6.52562901e-02 -3.23301591e-02 -2.55579986e-02  8.66304990e-03\n","  5.85266873e-02  7.34716281e-03 -8.69228244e-02  2.36317818e-03\n","  5.48681058e-02  6.30885810e-02  1.86376683e-02 -4.49460708e-02\n","  1.22909240e-01 -3.77027243e-02  2.61683483e-02  9.10007060e-02\n","  2.17436459e-02 -7.67750153e-03  1.37553766e-01 -6.56308010e-02\n","  6.07829355e-03  3.98683064e-02  5.63138053e-02  4.36802097e-02]\n","Layer: dense_1\n","Weights:\n","Gradeid: [ 0.09877978 -0.21253332 -0.08308555]\n","Semester: [ 0.06322894  0.09288861 -0.05862248]\n","Raisedhands: [ 0.1780378   0.16867276 -0.3556666 ]\n","Visitedresources: [ 0.14807512  0.01603657 -0.09896041]\n","Announcementsview: [-0.00949408 -0.1102498   0.1746756 ]\n","Discussion: [ 0.00583268  0.06955896 -0.12755783]\n","Parentansweringsurvey: [-0.1128298   0.11997034 -0.09334397]\n","Parentschoolsatisfaction: [-0.03935065  0.1153363  -0.05882057]\n","Gender_F: [ 0.03259419 -0.14029677 -0.16186069]\n","Gender_M: [ 0.1622759  -0.14492197 -0.18820095]\n","Nationality_Egypt: [ 0.00226703  0.00928781 -0.07553716]\n","Nationality_Iran: [0.24534474 0.01118588 0.00467819]\n","Nationality_Iraq: [-0.05874484  0.09518592 -0.08284528]\n","Nationality_Jordan: [ 0.16630772  0.19454572 -0.12821668]\n","Nationality_Kuwait: [ 0.06846675  0.21741676 -0.14934956]\n","Nationality_Lebanon: [-0.06757268 -0.18287334  0.06737038]\n","Nationality_Lybia: [0.06461691 0.07974231 0.13315178]\n","Nationality_Morocco: [-0.14694339  0.08288859  0.03507219]\n","Nationality_Palestine: [-0.22820055  0.06470217 -0.01773779]\n","Nationality_Saudiarabia: [ 0.05254732 -0.13214517  0.12744817]\n","Nationality_Syria: [-0.18032497  0.00371082  0.10592204]\n","Nationality_Tunis: [-0.3997312  -0.03992856  0.22456655]\n","Nationality_Usa: [-0.17710078 -0.04836869 -0.1707094 ]\n","Nationality_Venezuela: [-0.2069925   0.07542809 -0.13517594]\n","Placeofbirth_Egypt: [ 0.06363666 -0.12411495  0.10195399]\n","Placeofbirth_Iran: [-0.08553112 -0.1280956   0.2509762 ]\n","Placeofbirth_Iraq: [ 0.16418454 -0.04055335 -0.23807648]\n","Placeofbirth_Jordan: [-0.14129849  0.06144518  0.01027411]\n","Placeofbirth_Kuwait: [ 0.23116976 -0.17684455  0.05053356]\n","Placeofbirth_Lebanon: [-0.0466052  -0.00394592  0.20459421]\n","Placeofbirth_Lybia: [-0.2017824   0.06900277  0.1310357 ]\n","Placeofbirth_Morocco: [-0.13751562  0.05510911  0.12153345]\n","Placeofbirth_Palestine: [-0.05577089 -0.22518156  0.16702826]\n","Placeofbirth_Saudiarabia: [-0.21393673  0.6208781  -0.41673052]\n","Placeofbirth_Syria: [ 0.0073214  -0.07218084  0.14553963]\n","Placeofbirth_Tunis: [-0.02358603 -0.17814161  0.2502741 ]\n","Placeofbirth_Usa: [-0.15390687 -0.12422393  0.13833266]\n","Placeofbirth_Venzuela: [ 0.19649878  0.12229197 -0.19348207]\n","Stageid_HighSchool: [ 0.0438603   0.13521431 -0.20815246]\n","Stageid_MiddleSchool: [ 0.04322604 -0.06453667  0.17112914]\n","Stageid_PrimarySchool: [-0.5075589  -0.17782606  0.15718548]\n","Sectionid_A: [-0.02644989 -0.26142442  0.19169636]\n","Sectionid_B: [ 0.1678984   0.09201309 -0.16416979]\n","Sectionid_C: [ 0.21349695 -0.31242153 -0.10693504]\n","Topic_Arabic: [-0.04937652 -0.07467265  0.03127375]\n","Topic_Biology: [-0.16573547 -0.08126244  0.01443101]\n","Topic_Chemistry: [ 0.13817897 -0.01215856  0.19151253]\n","Topic_English: [-0.20137416  0.11278038 -0.05665009]\n","Topic_French: [0.24406262 0.14255705 0.00610801]\n","Topic_Geology: [-0.01850093  0.15694916 -0.02017596]\n","Topic_History: [-0.10442678  0.01455362 -0.22036801]\n","Topic_IT: [-0.1793268   0.09984735  0.17179286]\n","Topic_Math: [-0.01345515  0.02183389  0.08050002]\n","Topic_Quran: [-0.2758714  -0.00487432 -0.01544956]\n","Topic_Science: [-0.12644067  0.07983698 -0.23991677]\n","Topic_Spanish: [ 0.2638923  -0.0046404  -0.13603535]\n","Relation_Father: [ 0.10361884  0.26477414 -0.01868208]\n","Relation_Mum: [ 0.17465445 -0.20120354  0.19110781]\n","Studentabsencedays_High: [ 0.15278395 -0.08901002  0.04931809]\n","Studentabsencedays_Low: [ 0.16903718  0.20374086 -0.1660146 ]\n"]},{"output_type":"error","ename":"IndexError","evalue":"index 60 is out of bounds for axis 0 with size 60","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-10-50310e4ae5f9>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Weights:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumn_weight\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{column_names[j]}: {column_weight}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Biases:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbiases\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   5173\u001b[0m             \u001b[0;31m# GH#44051 exclude bool, which would return a 2d ndarray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5174\u001b[0m             \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast_scalar_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5175\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mgetitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5177\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mIndexError\u001b[0m: index 60 is out of bounds for axis 0 with size 60"]}]},{"cell_type":"code","source":[],"metadata":{"id":"Qmy1_9bAxzKf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Prediction"],"metadata":{"id":"KK9P40sM9IFo"}},{"cell_type":"code","source":["from keras.models import load_model\n","\n","import os\n","filepath = \"./saved_models/best_model.keras\"\n","\n","# Load the model\n","loaded_model = load_model(filepath)\n","\n","# Get input shape\n","input_shape = loaded_model.input_shape\n","\n","print(\"Input shape:\", input_shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"plf8vNrO-UAK","executionInfo":{"status":"ok","timestamp":1715313045259,"user_tz":-300,"elapsed":489,"user":{"displayName":"Sheikh Muhammad Talha BSSE 2021 FAST NU LHR","userId":"05044819345239191473"}},"outputId":"c429cadb-53e2-487f-8fe1-4536658e01c9"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Input shape: (None, 60)\n"]}]},{"cell_type":"code","source":["inpL1 = np.array([[4,1,10,7,0,30,0,0,0,1,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0,0,0,0,0,0,1,0,0,0,0,1,0,1,0]])\n","inpL2 = np.array([[4,1,30,25,5,35,0,0,0,1,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0,0,0,0,0,0,1,0,0,0,0,1,0,1,0]])\n","\n","inpM1 = np.array([[4, 1, 15, 16, 2, 20, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0,0,0,0,0,0,1,0,0,0,0,1,0,0,1]])\n","\n","inpH1 = np.array([[7,1,50,88,30,80,1,1,0,1,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,1,0,0,1]])\n","inpH2 = np.array([[8,2,50,98,24,85,1,1,0,1,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,1,0,0,1]])\n","\n","def givePrediction(encodedArray):\n","  prediction = loaded_model.predict(encodedArray)\n","  marks = \"High\" if np.argmax(prediction) == 0 else \"Low\" if np.argmax(prediction) == 1 else \"Medium\"\n","  print(f\"Input {i+1}: Prediction: {prediction[0]} \\n Marks: {marks}\")\n","\n","# Make prediction\n","inp_values=[inpL1,inpL2,inpM1,inpH1,inpH2]\n","\n","for i, inp_value in enumerate(inp_values):\n","  givePrediction(inp_value)\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IcCwX7Df9MnT","executionInfo":{"status":"ok","timestamp":1715313049156,"user_tz":-300,"elapsed":969,"user":{"displayName":"Sheikh Muhammad Talha BSSE 2021 FAST NU LHR","userId":"05044819345239191473"}},"outputId":"aa604b62-288d-4523-b888-a8190d1d66c7"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 88ms/step\n","Input 1: Prediction: [5.8091020e-05 9.7932225e-01 2.0619633e-02] \n"," Marks: Low\n","1/1 [==============================] - 0s 22ms/step\n","Input 2: Prediction: [0.00227862 0.6918228  0.30589855] \n"," Marks: Low\n","1/1 [==============================] - 0s 21ms/step\n","Input 3: Prediction: [0.01870509 0.13279098 0.8485039 ] \n"," Marks: Medium\n","1/1 [==============================] - 0s 23ms/step\n","Input 4: Prediction: [8.45888615e-01 1.07973916e-04 1.54003412e-01] \n"," Marks: High\n","1/1 [==============================] - 0s 25ms/step\n","Input 5: Prediction: [9.3992239e-01 4.6832405e-04 5.9609294e-02] \n"," Marks: High\n"]}]},{"cell_type":"code","source":["import numpy as np\n","\n","\n","def givePrediction(encodedArray):\n","  prediction = loaded_model.predict(encodedArray)\n","  marks = \"High\" if np.argmax(prediction) == 0 else \"Low\" if np.argmax(prediction) == 1 else \"Medium\"\n","  print(f\"Input {i+1}: Prediction: {prediction[0]} \\n Marks: {marks}\")\n","\n","\n","# Define the expected columns\n","expected_columns = [\n","    'Gradeid', 'Semester', 'Raisedhands', 'Visitedresources', 'Announcementsview',\n","    'Discussion', 'Parentansweringsurvey', 'Parentschoolsatisfaction', 'Gender_F',\n","    'Gender_M', 'Nationality_Egypt', 'Nationality_Iran', 'Nationality_Iraq',\n","    'Nationality_Jordan', 'Nationality_Kuwait', 'Nationality_Lebanon', 'Nationality_Lybia',\n","    'Nationality_Morocco', 'Nationality_Palestine', 'Nationality_Saudiarabia', 'Nationality_Syria',\n","    'Nationality_Tunis', 'Nationality_Usa', 'Nationality_Venezuela', 'Placeofbirth_Egypt',\n","    'Placeofbirth_Iran', 'Placeofbirth_Iraq', 'Placeofbirth_Jordan', 'Placeofbirth_Kuwait',\n","    'Placeofbirth_Lebanon', 'Placeofbirth_Lybia', 'Placeofbirth_Morocco', 'Placeofbirth_Palestine',\n","    'Placeofbirth_Saudiarabia', 'Placeofbirth_Syria', 'Placeofbirth_Tunis', 'Placeofbirth_Usa',\n","    'Placeofbirth_Venzuela', 'Stageid_HighSchool', 'Stageid_MiddleSchool', 'Stageid_PrimarySchool',\n","    'Sectionid_A', 'Sectionid_B', 'Sectionid_C', 'Topic_Arabic', 'Topic_Biology', 'Topic_Chemistry',\n","    'Topic_English', 'Topic_French', 'Topic_Geology', 'Topic_History', 'Topic_IT', 'Topic_Math',\n","    'Topic_Quran', 'Topic_Science', 'Topic_Spanish', 'Relation_Father', 'Relation_Mum',\n","    'Studentabsencedays_High', 'Studentabsencedays_Low'\n","]\n","\n","#Input data\n","input_data = {\n","    'Gender': 'M',\n","    'Nationality': 'Egypt',\n","    'Placeofbirth': 'Jordan',\n","    'Stageid': 'HighSchool',\n","    'Gradeid': 4,\n","    'Sectionid': 'A',\n","    'Topic': 'Math',\n","    'Semester': 1,\n","    'Relation': 'Mum',\n","    'Raisedhands': 15,\n","    'Visitedresources': 16,\n","    'Announcementsview': 2,\n","    'Discussion': 20,\n","    'Parentansweringsurvey': 1,\n","    'Parentschoolsatisfaction': 1,\n","    'Studentabsencedays': 'Low'\n","}\n","\n","# Map each categorical value to its own category\n","def map_categorical_value(category, value):\n","    return f\"{category}_{value}\"\n","\n","\n","mapped_input = []\n","for column in expected_columns:\n","    if column in input_data:\n","        if isinstance(input_data[column], str):  # Categorical variable\n","            if input_data[column] == column.split('_')[-1]:  # Check without splitting\n","                mapped_input.append(1)\n","            else:\n","                mapped_input.append(0)\n","        else:  # Numerical variable\n","            mapped_input.append(input_data[column])\n","    else:\n","        # Handle missing details\n","        base_column_name = column.split('_')[0]\n","        value_column_name = column.split('_')[1]\n","\n","        if base_column_name in input_data:\n","            if(input_data[base_column_name] ==  value_column_name):\n","              mapped_input.append(1)\n","            else:\n","              mapped_input.append(0)  # Value missing for categorical variable, set to 0\n","        else:\n","            mapped_input.append(0)  # Missing detail 0 for numerical variable\n","\n","# Reshape mapped input into a 2D array\n","mapped_input = np.array([mapped_input])\n","\n","print(mapped_input)\n","\n","givePrediction(mapped_input)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"j9_XTVVadLCV","executionInfo":{"status":"ok","timestamp":1715313106364,"user_tz":-300,"elapsed":4,"user":{"displayName":"Sheikh Muhammad Talha BSSE 2021 FAST NU LHR","userId":"05044819345239191473"}},"outputId":"b9b80c12-bda8-4461-d117-fbed99642d38"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["[[ 4  1 25 16  2 20  1  1  0  1  1  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  1  0  0  0  0  0  0  0  0  0  0  1  0  0  1  0  0  0  0  0  0\n","   0  0  0  0  1  0  0  0  0  1  0  1]]\n","1/1 [==============================] - 0s 20ms/step\n","Input 5: Prediction: [0.35488605 0.5382648  0.10684916] \n"," Marks: Low\n"]}]},{"cell_type":"code","source":["import numpy as np\n","\n","\n","def givePrediction(encodedArray):\n","  prediction = loaded_model.predict(encodedArray)\n","  marks = \"High\" if np.argmax(prediction) == 0 else \"Low\" if np.argmax(prediction) == 1 else \"Medium\"\n","  print(f\"Input {i+1}: Prediction: {prediction[0]} \\n Marks: {marks}\")\n","\n","\n","# Define the expected columns\n","expected_columns = [\n","    'Gradeid', 'Semester', 'Raisedhands', 'Visitedresources', 'Announcementsview',\n","    'Discussion', 'Parentansweringsurvey', 'Parentschoolsatisfaction', 'Gender_F',\n","    'Gender_M', 'Nationality_Egypt', 'Nationality_Iran', 'Nationality_Iraq',\n","    'Nationality_Jordan', 'Nationality_Kuwait', 'Nationality_Lebanon', 'Nationality_Lybia',\n","    'Nationality_Morocco', 'Nationality_Palestine', 'Nationality_Saudiarabia', 'Nationality_Syria',\n","    'Nationality_Tunis', 'Nationality_Usa', 'Nationality_Venezuela', 'Placeofbirth_Egypt',\n","    'Placeofbirth_Iran', 'Placeofbirth_Iraq', 'Placeofbirth_Jordan', 'Placeofbirth_Kuwait',\n","    'Placeofbirth_Lebanon', 'Placeofbirth_Lybia', 'Placeofbirth_Morocco', 'Placeofbirth_Palestine',\n","    'Placeofbirth_Saudiarabia', 'Placeofbirth_Syria', 'Placeofbirth_Tunis', 'Placeofbirth_Usa',\n","    'Placeofbirth_Venzuela', 'Stageid_HighSchool', 'Stageid_MiddleSchool', 'Stageid_PrimarySchool',\n","    'Sectionid_A', 'Sectionid_B', 'Sectionid_C', 'Topic_Arabic', 'Topic_Biology', 'Topic_Chemistry',\n","    'Topic_English', 'Topic_French', 'Topic_Geology', 'Topic_History', 'Topic_IT', 'Topic_Math',\n","    'Topic_Quran', 'Topic_Science', 'Topic_Spanish', 'Relation_Father', 'Relation_Mum',\n","    'Studentabsencedays_High', 'Studentabsencedays_Low'\n","]\n","options = {\n","    'Gender': ['F', 'M'],\n","    'Nationality': ['Egypt', 'Iran', 'Iraq', 'Jordan', 'Kuwait', 'Lebanon', 'Lybia', 'Morocco', 'Palestine', 'Saudi Arabia', 'Syria', 'Tunis', 'USA', 'Venezuela'],\n","    'Placeofbirth': ['Egypt', 'Iran', 'Iraq', 'Jordan', 'Kuwait', 'Lebanon', 'Lybia', 'Morocco', 'Palestine', 'Saudi Arabia', 'Syria', 'Tunis', 'USA', 'Venezuela'],\n","    'Stageid': ['HighSchool', 'MiddleSchool', 'PrimarySchool'],\n","    'Sectionid': ['A', 'B', 'C'],\n","    'Topic': ['Arabic', 'Biology', 'Chemistry', 'English', 'French', 'Geology', 'History', 'IT', 'Math', 'Quran', 'Science', 'Spanish'],\n","    'Relation': ['Father', 'Mum'],\n","    'Studentabsencedays': ['High', 'Low']\n","}\n","\n","# Define numerical value ranges\n","numerical_ranges = {\n","    'Gradeid': (1, 12),\n","    'Semester': (1, 2),\n","    'Raisedhands': (0, 100),\n","    'Visitedresources': (0, 100),\n","    'Announcementsview': (0, 100),\n","    'Discussion': (0, 100),\n","    'Parentansweringsurvey': (0, 1),\n","    'Parentschoolsatisfaction': (0, 1)\n","}\n","\n","# Print options list for categorical variables\n","print(\"Options List:\")\n","for key, value in options.items():\n","    print(f\"{key}: {value}\")\n","\n","# Print numerical value ranges\n","print(\"\\nNumerical Value Ranges:\")\n","for key, value in numerical_ranges.items():\n","    print(f\"{key}: {value}\")\n","\n","\n","\n","# Map each categorical value to its own category\n","def map_categorical_value(category, value):\n","    return f\"{category}_{value}\"\n","\n","\n","print(\"\\nINPUT:\")\n","\n","# Ask user for input data\n","for key, value in input_data.items():\n","    if isinstance(value, str):\n","        input_data[key] = input(f\"Enter {key}: \")\n","    else:\n","        input_data[key] = int(input(f\"Enter {key}: \"))\n","\n","mapped_input = []\n","for column in expected_columns:\n","    if column in input_data:\n","        if isinstance(input_data[column], str):  # Categorical variable\n","            if input_data[column] == column.split('_')[-1]:\n","                mapped_input.append(1)\n","            else:\n","                mapped_input.append(0)\n","        else:  # Numerical variable\n","            mapped_input.append(input_data[column])\n","    else:\n","        # Handle missing details\n","        base_column_name = column.split('_')[0]\n","        value_column_name = column.split('_')[1]\n","\n","        if base_column_name in input_data:\n","            if(input_data[base_column_name] ==  value_column_name):\n","              mapped_input.append(1)\n","            else:\n","              mapped_input.append(0)  # Value missing for categorical variable, set to 0\n","        else:\n","            mapped_input.append(0)  # Missing detail 0 for numerical variable\n","\n","# Reshape mapped input into a 2D array\n","mapped_input = np.array([mapped_input])\n","\n","print(mapped_input)\n","\n","givePrediction(mapped_input)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dltom56yI7LF","executionInfo":{"status":"ok","timestamp":1715278539349,"user_tz":-300,"elapsed":56853,"user":{"displayName":"Sheikh Muhammad Talha BSSE 2021 FAST NU LHR","userId":"05044819345239191473"}},"outputId":"aa459f0d-85f7-48f6-8643-35b1e894a128"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Options List:\n","Gender: ['F', 'M']\n","Nationality: ['Egypt', 'Iran', 'Iraq', 'Jordan', 'Kuwait', 'Lebanon', 'Lybia', 'Morocco', 'Palestine', 'Saudi Arabia', 'Syria', 'Tunis', 'USA', 'Venezuela']\n","Placeofbirth: ['Egypt', 'Iran', 'Iraq', 'Jordan', 'Kuwait', 'Lebanon', 'Lybia', 'Morocco', 'Palestine', 'Saudi Arabia', 'Syria', 'Tunis', 'USA', 'Venezuela']\n","Stageid: ['HighSchool', 'MiddleSchool', 'PrimarySchool']\n","Sectionid: ['A', 'B', 'C']\n","Topic: ['Arabic', 'Biology', 'Chemistry', 'English', 'French', 'Geology', 'History', 'IT', 'Math', 'Quran', 'Science', 'Spanish']\n","Relation: ['Father', 'Mum']\n","Studentabsencedays: ['High', 'Low']\n","\n","Numerical Value Ranges:\n","Gradeid: (1, 12)\n","Semester: (1, 2)\n","Raisedhands: (0, 100)\n","Visitedresources: (0, 100)\n","Announcementsview: (0, 100)\n","Discussion: (0, 100)\n","Parentansweringsurvey: (0, 1)\n","Parentschoolsatisfaction: (0, 1)\n","\n","INPUT:\n","Enter Gender: F\n","Enter Nationality: Jordan\n","Enter Placeofbirth: Jordan\n","Enter Stageid: HighSchool\n","Enter Gradeid: 10\n","Enter Sectionid: A\n","Enter Topic: IT\n","Enter Semester: 1\n","Enter Relation: Father\n","Enter Raisedhands: 10\n","Enter Visitedresources: 20\n","Enter Announcementsview: 30\n","Enter Discussion: 10\n","Enter Parentansweringsurvey: 1\n","Enter Parentschoolsatisfaction: 1\n","Enter Studentabsencedays: High\n","[[10  1 10 20 30 10  1  1  1  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  1  0  0  0  0  0  0  0  0  0  0  1  0  0  1  0  0  0  0  0  0\n","   0  0  0  1  0  0  0  0  1  0  1  0]]\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n","Input 5: Prediction: [0.00078175 0.48045546 0.51876277] \n"," Marks: Medium\n"]}]}]}